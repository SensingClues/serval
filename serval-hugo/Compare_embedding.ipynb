{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code die checkt of wij wav-files correct wegschrijven naar tf-records.\n",
    "\n",
    "\n",
    "[link to original code](https://github.com/tensorflow/models/tree/master/research/audioset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "## Import packages\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import gfile\n",
    "from tensorflow import logging\n",
    "\n",
    "import vggish_input\n",
    "import vggish_postprocess\n",
    "import vggish_params\n",
    "import vggish_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'audio_embedding_feature_name', 'audio_embedding',\n",
    "    'Path to the VGGish checkpoint file.')\n",
    "\n",
    "## De volgende bestanden komen uit het eerdere mapje 'models'. Nu heb ik ze in yt8m gezet.\n",
    "## Deze zijn nodig om de embedding layer te maken\n",
    "flags.DEFINE_string( \n",
    "    'pca_params', 'models/vggish_pca_params.npz',\n",
    "    'Path to the VGGish PCA parameters file.')\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'checkpoint', 'models/vggish_model.ckpt',\n",
    "    'Path to the VGGish checkpoint file.')\n",
    "\n",
    "# flags.DEFINE_string(\n",
    "#     'yt_checkpoint', 'models/youtube_model.ckpt',\n",
    "#     'Path to the VGGish checkpoint file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test_embedding/_D.tfrecord'    \n",
    "record_iterator = tf.python_io.tf_record_iterator(filename)\n",
    "\n",
    "## Met break: check alleen het eerste geluidsfragment uit de tf-record\n",
    "embedding = None\n",
    "    \n",
    "for string_record in record_iterator:\n",
    "\n",
    "    ## Take one example\n",
    "    example = tf.train.SequenceExample()\n",
    "    example.ParseFromString(string_record)\n",
    "\n",
    "    embedding = example.feature_lists.feature_list['audio_embedding']\n",
    "\n",
    "    break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The youtube link to the first example\n",
    "\n",
    "https://www.youtube.com/watch?v=_DHMdtRRJzE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature {\n",
       "  bytes_list {\n",
       "    value: \"\\330w\\026\\201\\223rD\\325\\000U\\000\\234\\312u\\253\\223\\303\\210\\303\\036\\230/\\303\\356\\301nM:~\\205\\207}\\377\\265\\204~\\303S}\\247Wo`6@\\263\\333\\230\\227\\257g*\\237~z\\212*\\377~\\021\\201X\\207B\\335\\302\\324\\227\\213\\234^\\202O\\211c\\203<iZ\\247S\\202;\\371\\272}c\\022\\267k\\377\\207\\036m\\210\\206\\232\\324k\\000em\\266^\\2256X\\341\\201\\333dt>\\235d\\243\\365\\313\\346Z-\\305!\\262\\361\\346\\200\\345\"\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  bytes_list {\n",
       "    value: \"\\335vA\\200\\220nc\\274\\002l\\000\\262\\233\\335\\225\\207\\265\\212\\204:}V\\276\\340\\261f*MQ\\210\\264Y\\301\\247\\216\\223\\354\\177n\\251\\230\\203\\213}_n\\343\\203\\273\\314gi\\232V<\\254j\\343\\207[je\\240\\020\\377u\\201\\2076\\275.TX}{\\304a_\\221A\\231c-\\377\\266e\\234\\206\\242X\\354_5O{\\371\\301\\377\\2453T%\\276\\276\\301\\014\\177o\\\"\\260R3i\\207i\\263\\377\\331\\343}\\000\\302*^\\314\\3433\\276\"\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  bytes_list {\n",
       "    value: \"\\301p%`\\276~B\\261\\000\\200(\\272\\220q\\2325\\263G\\307d~\\223~\\340\\304oy\\207\\272\\270c0\\260f\\337\\221\\314\\300Y\\233^i_2d\\225\\257\\327\\325\\330\\212\\247s\\211A\\377m\\357\\3178U\\320\\r1\\277\\205\\231m\\225\\247\\257\\252?\\305\\237\\252F\\321\\232\\030\\275\\255\\000[\\345G\\204h\\254\\260\\312\\232\\270l\\241@S7\\232\\000\\273\\251\\377\\216\\201\\233_\\226b\\330[\\205\\216\\324\\227\\374CD\\332\\377\\\\\\317R\\204\\2140\\266\\030\"\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  bytes_list {\n",
       "    value: \"\\304hG}\\235\\\\@\\233\\000\\276\\000\\306\\243^\\271~\\234n\\260\\225h\\221\\256\\246\\227\\365=h\\211\\341\\000\\377\\332\\377b\\225\\301\\010:-O^K\\257\\243O\\2622\\000n_;b\\225\\342\\2649\\260\\034\\261~g{\\331h\\377\\377\\361wg\\207q>\\250\\224\\233m]Xq\\205\\206\\200\\243\\203\\253\\363\\236\\332r\\303\\2060\\215\\030\\207\\253\\207\\353\\000\\267\\202\\226\\240\\265\\240\\031Al\\325f\\350\\000o])\\213\\367\\223\\2727\\311p\\267\\323\\304)\\000\"\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  bytes_list {\n",
       "    value: \"\\313h2\\200\\242kP\\256\\032~\\000\\262Om\\227O\\267b\\2121\\212Y\\250\\270\\341\\261Zj\\216vQg\\226\\230\\361\\221\\263\\263\\223\\223\\235\\2250G\\251E\\265\\260\\334\\227B\\256\\013\\222l\\247X\\311\\314\\203A\\271f\\031\\234\\230\\211v\\253\\210O\\211J`won\\234xs\\221\\234B\\342\\357I{\\005y\\232\\321\\222q\\'\\032f\\313\\321\\220\\000\\211X\\274\\205\\212c\\256\\310\\024\\351`t\\247\\237p\\3468\\222\\312\\275\\212K\\\\C\\255<d\\205\"\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  bytes_list {\n",
       "    value: \"\\315u)r\\240t/\\307)\\231\\016\\252sd\\246Z\\256\\215\\3054\\304U\\311\\332\\323\\247S}\\224\\251Lp\\366\\275\\304\\203\\316jx\\270\\212H9.g\\304n\\225\\271\\205g\\211ZdH\\226`\\342p1ffx-\\345\\277\\177\\263\\240\\277\\177g\\024h\\212|D\\303\\256\\225\\200TY\\305\\2706u*\\205\\377\\377\\2275\\205W\\201\\226i\\227\\002\\327h\\305VNUh\\377u\\337\\2021waA\\265\\330\\237\\337\\261Q\\313\\'\\\\\\270h.\\377\"\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  bytes_list {\n",
       "    value: \"\\307]\\034\\200\\251mO\\323\\'Z\\000\\203\\274K\\243{\\271y\\307\\013|<\\243\\352\\330xLb\\216\\237\\252U\\330\\251\\255\\226\\211\\177fsptLJed\\306\\264\\303\\254t|\\205\\231\\214>U\\321\\226p\\274MS\\\\\\220\\276\\312A\\177\\235\\201\\321G\\347Fu$Jx\\217|\\265H\\242\\266jbT\\202]\\336\\233p\\224\\2411X\\234\\264\\035\\235t\\225T\\251\\221\\256\\214\\222\\245m/#w\\206\\374F\\306\\274\\363\\242N\\000\\023WMi\\307\"\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  bytes_list {\n",
       "    value: \"\\315XJx\\263tD\\250\\023\\250\\023\\251\\232q\\221^\\256R\\300Tz\\204\\233\\313\\270\\212o|\\220\\224WM\\341\\215\\254}\\306Wqn\\222\\227wM{\\275\\271\\213\\236\\322}\\223]\\243d\\257c\\262\\221[\\217\\207V>\\353\\310\\210\\213\\237\\264\\221pc\\241l\\231B\\274\\177kx~\\024\\274wJ\\235h\\201\\212\\310\\247.qj\\245\\204X~9\\266j\\314|`Sd\\367z\\313`\\215\\236\\212W\\250\\203\\325\\321\\316c\\334\\022X\\237t\\004\\351\"\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  bytes_list {\n",
       "    value: \"\\312f@s\\241\\201:\\271\\000\\233\\000\\320\\206\\211\\2140\\2427\\247Bt}\\260\\342\\312\\227lq\\200\\227bH\\314\\232\\324\\227\\324\\270]\\202\\303\\220\\2023\\237J\\352\\362\\262\\336@\\236J\\210%\\336)\\304\\323f8\\251f\\000\\274\\235\\201y8\\264`\\270\\034\\203X\\256k\\237\\207\\016\\233\\211\\000\\346\\377\\000\\317\\000\\214\\303\\365\\237vB/\\233\\227\\237\\363\\000\\211C\\363\\253\\342\\212\\214\\310\\000\\377V<\\227\\236\\262\\377R\\305\\321\\234\\032\\225#H\\2149\\036o\"\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  bytes_list {\n",
       "    value: \"\\323r>j\\214\\177G\\260*\\332\\000\\272[j\\240p\\223[\\260E\\211s\\320\\334\\346\\276r\\211\\217\\325\\024\\217\\262\\301\\332\\240\\3677\\220\\220\\205\\254C\\201\\243me\\235\\253\\215c\\243c\\254]\\324j\\377\\242|U\\250\\201\\016\\325\\362\\242\\306\\230\\321\\201n$&\\204|h\\231\\226Z\\204|A\\274\\255k\\357\\013\\224\\253\\336\\226\\033`D\\256t-\\316(\\265k\\365i\\261\\207\\032\\337\\035\\3363]\\312\\203s\\200\\301\\343\\377\\267\\250\\266D\\000\\203\\3240\\261\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[216 119  22 129 147 114  68 213   0  85   0 156 202 117 171 147 195 136\n",
      " 195  30 152  47 195 238 193 110  77  58 126 133 135 125 255 181 132 126\n",
      " 195  83 125 167  87 111  96  54  64 179 219 152 151 175 103  42 159 126\n",
      " 122 138  42 255 126  17 129  88 135  66 221 194 212 151 139 156  94 130\n",
      "  79 137  99 131  60 105  90 167  83 130  59 249 186 125  99  18 183 107\n",
      " 255 135  30 109 136 134 154 212 107   0 101 109 182  94 149  54  88 225\n",
      " 129 219 100 116  62 157 100 163 245 203 230  90  45 197  33 178 241 230\n",
      " 128 229]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#byte_array = b'\\xd8w\\x16\\x81\\x93rD\\xd5\\x00U\\x00\\x9c\\xcau\\xab\\x93\\xc3\\x88\\xc3\\x1e\\x98/\\xc3\\xee\\xc1nM:~\\x85\\x87}\\xff\\xb5\\x84~\\xc3S}\\xa7Wo`6@\\xb3\\xdb\\x98\\x97\\xafg*\\x9f~z\\x8a*\\xff~\\x11\\x81X\\x87B\\xdd\\xc2\\xd4\\x97\\x8b\\x9c^\\x82O\\x89c\\x83<iZ\\xa7S\\x82;\\xf9\\xba}c\\x12\\xb7k\\xff\\x87\\x1em\\x88\\x86\\x9a\\xd4k\\x00em\\xb6^\\x956X\\xe1\\x81\\xdbdt>\\x9dd\\xa3\\xf5\\xcb\\xe6Z-\\xc5!\\xb2\\xf1\\xe6\\x80\\xe5'\n",
    "byte_string = embedding.feature[0].bytes_list.value[0]\n",
    "\n",
    "bs = np.fromstring(byte_string, dtype=np.uint8)\n",
    "print(bs)\n",
    "len(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Haal nu het wav-bestandje op dat van Youtube is gehaald\n",
    "wavfile_path = 'test_embedding/youtube_D.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Deze code is van inference.py gehaald.\n",
    "## Op het einde wordt er een nieuwe sequence example gemaakt\n",
    "\n",
    "## Function that takes examples from wav-file as input and returns a sequence example\n",
    "def getSequenceExample(examples_batch, labels, video_id=[b'_DHMdtRRJzE']):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "\n",
    "        # Define the model: load the checkpoint and locate input and output tensors\n",
    "        # Input: [batch_size, num_frames, num_bands] \n",
    "        # where [num_frames, num_bands] represents log-mel-scale spectrogram\n",
    "        # Output: embeddings\n",
    "        vggish_slim.define_vggish_slim(training=False)\n",
    "        vggish_slim.load_vggish_slim_checkpoint(sess, FLAGS.checkpoint)\n",
    "\n",
    "#         pca_params = np.load(FLAGS.pca_params)\n",
    "#         pca_matrix = pca_params[vggish_params.PCA_EIGEN_VECTORS_NAME]\n",
    "#         pca_means = pca_params[vggish_params.PCA_MEANS_NAME].reshape(-1, 1)\n",
    "\n",
    "        features_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.VGGISH_INPUT_TENSOR_NAME)\n",
    "        embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.VGGISH_OUTPUT_TENSOR_NAME)\n",
    "        #vggish_slim.load_youtube_model(sess, FLAGS.yt_checkpoint)\n",
    "\n",
    "        # Run inference and postprocessing\n",
    "        [embedding_batch] = sess.run([embedding_tensor],\n",
    "                                     feed_dict={features_tensor: examples_batch})\n",
    "\n",
    "        # HK : Dit is echt anders\n",
    "        postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "#         np.dot(\n",
    "#                 pca_matrix, (embedding_batch.T - pca_means)\n",
    "#             ).T\n",
    "        #print(postprocessed_batch)\n",
    "\n",
    "#         num_frames = np.minimum(postprocessed_batch.shape[0], vggish_params.MAX_FRAMES)\n",
    "#         data = vggish_postprocess.resize(postprocessed_batch, 0, vggish_params.MAX_FRAMES)\n",
    "#         data = np.expand_dims(data, 0)\n",
    "#         num_frames = np.expand_dims(num_frames, 0)\n",
    "\n",
    "#         input_tensor = sess.graph.get_collection(\"input_batch_raw\")[0]\n",
    "#         num_frames_tensor = sess.graph.get_collection(\"num_frames\")[0]\n",
    "\n",
    "#         label_feat = tf.train.Feature(int64_list=tf.train.Int64List(value=labels))\n",
    "#         videoid_feat = tf.train.Feature(bytes_list=tf.train.BytesList(value=video_id))\n",
    " \n",
    "        seq_example = tf.train.SequenceExample(\n",
    "            #context = tf.train.Features(feature={\"labels\": label_feat, \"video_id\": videoid_feat}),\n",
    "            feature_lists = tf.train.FeatureLists(\n",
    "                feature_list={\n",
    "                    FLAGS.audio_embedding_feature_name:\n",
    "                        tf.train.FeatureList(\n",
    "                            feature=[\n",
    "                                tf.train.Feature(\n",
    "                                    bytes_list=tf.train.BytesList(\n",
    "                                        value=[embedding.tobytes()]))\n",
    "                                for embedding in postprocessed_batch\n",
    "                            ]\n",
    "                        )\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    return(seq_example,postprocessed_batch,embedding_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples shape: (10, 96, 64)\n",
      "INFO:tensorflow:Restoring parameters from models/vggish_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "## Maak eerst de examples\n",
    "examples_batch = vggish_input.wavfile_to_examples(wavfile_path)\n",
    "print(\"Examples shape: \" + str(examples_batch.shape))\n",
    "\n",
    "# Prepare a postprocessor to munge the model embeddings.\n",
    "pproc = vggish_postprocess.Postprocessor(FLAGS.pca_params)\n",
    "\n",
    "## Maak nu de embedding (met functie hierboven), pas PCA toe en maak er bytes van\n",
    "seq_example, ppbatch, ebatch = getSequenceExample(examples_batch, [161])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128)\n"
     ]
    }
   ],
   "source": [
    "#print(seq_example)\n",
    "#print(ppbatch)\n",
    "print(ebatch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "byte_string_2 = seq_example.feature_lists.feature_list['audio_embedding'].feature[0].bytes_list.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergelijk met de eerste:\n",
    "# print(embedding.feature[0].bytes_list.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[181  17 128 109 233  56  76 117  32 184  70  91 178 110 113  61 168  91\n",
      " 188 120  56 186 111 124 134 147 186 144 174 172 158  50 186 148 154 150\n",
      " 130  88  61  62 154 170  23  29 116 166 129 170  82 229 133 107  70 160\n",
      "  83 125 156  89 132 165 175 119  80 120 162 195  45  33 140 116 163 209\n",
      " 208 243  75 194  84 230 126 149 113 255 111 128 126  46 206 208  84 172\n",
      " 100 169  99 183  80  94  76  72 255  64 255  42 210  74 111 102 119 228\n",
      "  94 245 177  99  72 116 188  68  56 199   0 227 213 255  63   7 247  66\n",
      " 156 255]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = np.fromstring(byte_string_2, dtype=np.uint8)\n",
    "print(bs)\n",
    "len(bs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
