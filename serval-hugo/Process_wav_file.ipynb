{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions from wav file\n",
    "\n",
    "We use https://github.com/devicehive/devicehive-audio-analysis\n",
    "We need the code from th audio directory from above repo\n",
    "\n",
    "We need the vvgish models in the models directory\n",
    "\n",
    "We need our own trained model in teh models directory\n",
    "\n",
    "We need to point to our model and our class labels csv file\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research/audioset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import flags\n",
    "\n",
    "import vggish_input\n",
    "import vggish_postprocess\n",
    "import vggish_params\n",
    "import vggish_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# volgens mij heb ik dit niet nodig : alle parameters zitten in vggish_params\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# flags.DEFINE_string(\n",
    "#     'wav_file', 'wav_files/audio.wav',\n",
    "#     'Path to a wav file. Should contain signed 16-bit PCM samples.')\n",
    "\n",
    "# flags.DEFINE_string(\n",
    "#     'pca_params', 'models/vggish_pca_params.npz',\n",
    "#     'Path to the VGGish PCA parameters file.')\n",
    "\n",
    "# flags.DEFINE_string(\n",
    "#     'checkpoint', 'models/vggish_model.ckpt',\n",
    "#     'Path to the VGGish checkpoint file.')\n",
    "\n",
    "wav_file = 'wav_files/audio.wav'\n",
    "\n",
    "MODEL_CHECKPOINT_FILE = 'models/serval03/model.ckpt-13810'\n",
    "CLASS_LABELS_INDICES = 'audioset/class_labels_indices_amsterdam2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Ik verdeel het parsen van een wav-file naar embeddings in stappen:\n",
    "# Stap 1a: lezen van wav-file, input is array met samples die db aanduiden. Ook sample rate (per sec) wordt gelezen\n",
    "# Stap 1b: Bij 2d array (stereo, ipv mono) bereken gemiddelde, daarna normaliseren (delen door 32.768)\n",
    "# Stap 2: Bepaal examples in vorm [batch size, num frames, num bands].\n",
    "    # Hierbij worden voor verschillende batches (omdat alles tegelijk niet in 1x in NN kan),\n",
    "    # een log mel spectrogram gemaakt (in vorm [num_frames, num_bands])\n",
    "# Stap 3: Bepaal features: nu wordt de embedding laag gemaakt (PCA-components, discreet maken etc)\n",
    "    # Hiervoor worden model-parameters opgehaald die eerder zijn opgeslagen\n",
    "# Stap 4: Maken van predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 96, 64)\n"
     ]
    }
   ],
   "source": [
    "## Stap 1 en 2\n",
    "## This function reads the wav file and converts the samples into np arrays of [batch size, num frames, num bands]\n",
    "examples_batch = vggish_input.wavfile_to_examples(wav_file)\n",
    "print(examples_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'index,mid,display_name\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read csv-file with labels\n",
    "class_map = {}\n",
    "with open(CLASS_LABELS_INDICES) as f:\n",
    "    next(f)  # skip header\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        class_map[int(row[0])] = row[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'vggish/embedding:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/serval03/model.ckpt-13810\n"
     ]
    }
   ],
   "source": [
    "## Stap 3\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    # Define the model: load the checkpoint and locate input and output tensors\n",
    "    # Input: [batch_size, num_frames, num_bands] \n",
    "    # where [num_frames, num_bands] represents log-mel-scale spectrogram\n",
    "    # Output: embeddings\n",
    "    vggish_slim.define_vggish_slim(training=False)\n",
    "    vggish_slim.load_vggish_slim_checkpoint(sess, vggish_params.VGGISH_MODEL)\n",
    "    \n",
    "    pca_params = np.load(vggish_params.VGGISH_PCA_PARAMS)\n",
    "    pca_matrix = pca_params[vggish_params.PCA_EIGEN_VECTORS_NAME]\n",
    "    pca_means = pca_params[vggish_params.PCA_MEANS_NAME].reshape(-1, 1)\n",
    "    \n",
    "    features_tensor = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.VGGISH_INPUT_TENSOR_NAME)\n",
    "    embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.VGGISH_OUTPUT_TENSOR_NAME)\n",
    "    vggish_slim.load_youtube_model(sess, MODEL_CHECKPOINT_FILE) # HK vggish_params.YOUTUBE_CHECKPOINT_FILE\n",
    "    \n",
    "    # Run inference and postprocessing\n",
    "    [embedding_batch] = sess.run([embedding_tensor],\n",
    "                                 feed_dict={features_tensor: examples_batch})\n",
    "    \n",
    "    postprocessed_batches = np.dot(\n",
    "            pca_matrix, (embedding_batch.T - pca_means)\n",
    "        ).T\n",
    "    #print(postprocessed_batches)\n",
    "    pred_vals =  []\n",
    "    # we need to loop over batch size of 10\n",
    "    for i in range(10,postprocessed_batches.shape[0]):\n",
    "        # per 10 batches\n",
    "        postprocessed_batch = postprocessed_batches[i-10:i]\n",
    "\n",
    "        num_frames = np.minimum(postprocessed_batch.shape[0], vggish_params.MAX_FRAMES)\n",
    "        data = vggish_postprocess.resize(postprocessed_batch, 0, vggish_params.MAX_FRAMES)\n",
    "        data = np.expand_dims(data, 0)\n",
    "        num_frames = np.expand_dims(num_frames, 0)\n",
    "\n",
    "        input_tensor = sess.graph.get_collection(\"input_batch_raw\")[0]\n",
    "        num_frames_tensor = sess.graph.get_collection(\"num_frames\")[0]\n",
    "        predictions_tensor = sess.graph.get_collection(\"predictions\")[0]\n",
    "\n",
    "        predictions_tensors = sess.graph.get_collection(\"predictions\")\n",
    "\n",
    "        ## Stap 4\n",
    "        predictions_val, = sess.run(\n",
    "            [predictions_tensor],\n",
    "            feed_dict={\n",
    "                input_tensor: data,\n",
    "                num_frames_tensor: num_frames\n",
    "            })\n",
    "        pred_vals.append(predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Filter predictions (give top 20 where p>0.1)\n",
    "count = vggish_params.PREDICTIONS_COUNT_LIMIT\n",
    "hit = vggish_params.PREDICTIONS_HIT_LIMIT\n",
    "top_indices = np.argpartition(predictions_val[0], -count)[-count:]\n",
    "line = ((class_map[i], float(predictions_val[0][i])) for i in top_indices if predictions_val[0][i] > hit)\n",
    "predictions = sorted(line, key=lambda p: -p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Motor vehicle (road)', 0.274502158164978), ('Motorcycle', 0.21720299124717712), ('Dog', 0.19438397884368896), ('Aircraft', 0.18517421185970306), ('Boat, Water vehicle', 0.11269407719373703)]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Probabilities per increment\n",
    "preds=[]\n",
    "for p in pred_vals :\n",
    "    line = [(class_map[i], float(p[0][i])) for i in range(1,len(p[0]))]\n",
    "    preds.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "barh() missing 1 required positional argument: 'bottom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-46ead6b32c1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"aps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: barh() missing 1 required positional argument: 'bottom'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#type(preds[0][0])\n",
    "df = pd.DataFrame(preds[0], columns = ['label',\"aps\"])\n",
    "#df\n",
    "plt.barh(y=df.label, width=df.aps, align='center', alpha=0.5 )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "print(mpl.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
