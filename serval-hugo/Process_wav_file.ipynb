{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions from wav file\n",
    "\n",
    "We use https://github.com/devicehive/devicehive-audio-analysis\n",
    "We need the code from th audio directory from above repo\n",
    "\n",
    "We need the vvgish models in the models directory\n",
    "\n",
    "We need our own trained model in teh models directory\n",
    "\n",
    "We need to point to our model and our class labels csv file\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research/audioset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "## Import packages\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import flags\n",
    "\n",
    "import vggish_input\n",
    "import vggish_postprocess\n",
    "import vggish_params\n",
    "import vggish_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volgens mij heb ik dit niet nodig : alle parameters zitten in vggish_params\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# flags.DEFINE_string(\n",
    "#     'wav_file', 'wav_files/audio.wav',\n",
    "#     'Path to a wav file. Should contain signed 16-bit PCM samples.')\n",
    "\n",
    "# flags.DEFINE_string(\n",
    "#     'pca_params', 'models/vggish_pca_params.npz',\n",
    "#     'Path to the VGGish PCA parameters file.')\n",
    "\n",
    "# flags.DEFINE_string(\n",
    "#     'checkpoint', 'models/vggish_model.ckpt',\n",
    "#     'Path to the VGGish checkpoint file.')\n",
    "\n",
    "wav_file = 'wav_files/audio.wav'\n",
    "\n",
    "MODEL_CHECKPOINT_FILE = 'models/serval03/model.ckpt-13810'\n",
    "CLASS_LABELS_INDICES = 'audioset/class_labels_indices_amsterdam2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ik verdeel het parsen van een wav-file naar embeddings in stappen:\n",
    "# Stap 1a: lezen van wav-file, input is array met samples die db aanduiden. Ook sample rate (per sec) wordt gelezen\n",
    "# Stap 1b: Bij 2d array (stereo, ipv mono) bereken gemiddelde, daarna normaliseren (delen door 32.768)\n",
    "# Stap 2: Bepaal examples in vorm [batch size, num frames, num bands].\n",
    "    # Hierbij worden voor verschillende batches (omdat alles tegelijk niet in 1x in NN kan),\n",
    "    # een log mel spectrogram gemaakt (in vorm [num_frames, num_bands])\n",
    "# Stap 3: Bepaal features: nu wordt de embedding laag gemaakt (PCA-components, discreet maken etc)\n",
    "    # Hiervoor worden model-parameters opgehaald die eerder zijn opgeslagen\n",
    "# Stap 4: Maken van predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 96, 64)\n"
     ]
    }
   ],
   "source": [
    "## Stap 1 en 2\n",
    "## This function reads the wav file and converts the samples into np arrays of [batch size, num frames, num bands]\n",
    "examples_batch = vggish_input.wavfile_to_examples(wav_file)\n",
    "print(examples_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read csv-file with labels\n",
    "class_map = {}\n",
    "with open(CLASS_LABELS_INDICES) as f:\n",
    "    next(f)  # skip header\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        class_map[int(row[0])] = row[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/serval03/model.ckpt-13810\n"
     ]
    }
   ],
   "source": [
    "## Stap 3\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    # Define the model: load the checkpoint and locate input and output tensors\n",
    "    # Input: [batch_size, num_frames, num_bands] \n",
    "    # where [num_frames, num_bands] represents log-mel-scale spectrogram\n",
    "    # Output: embeddings\n",
    "    vggish_slim.define_vggish_slim(training=False)\n",
    "    vggish_slim.load_vggish_slim_checkpoint(sess, vggish_params.VGGISH_MODEL)\n",
    "    \n",
    "    pca_params = np.load(vggish_params.VGGISH_PCA_PARAMS)\n",
    "    pca_matrix = pca_params[vggish_params.PCA_EIGEN_VECTORS_NAME]\n",
    "    pca_means = pca_params[vggish_params.PCA_MEANS_NAME].reshape(-1, 1)\n",
    "    \n",
    "    features_tensor = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.VGGISH_INPUT_TENSOR_NAME)\n",
    "    embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.VGGISH_OUTPUT_TENSOR_NAME)\n",
    "    vggish_slim.load_youtube_model(sess, MODEL_CHECKPOINT_FILE) # HK vggish_params.YOUTUBE_CHECKPOINT_FILE\n",
    "    \n",
    "    # Run inference and postprocessing\n",
    "    [embedding_batch] = sess.run([embedding_tensor],\n",
    "                                 feed_dict={features_tensor: examples_batch})\n",
    "    \n",
    "    postprocessed_batches = np.dot(\n",
    "            pca_matrix, (embedding_batch.T - pca_means)\n",
    "        ).T\n",
    "    #print(postprocessed_batches)\n",
    "    pred_vals =  []\n",
    "    # we need to loop over batch size of 10\n",
    "    for i in range(10,postprocessed_batches.shape[0]):\n",
    "        # per 10 batches\n",
    "        postprocessed_batch = postprocessed_batches[i-3:i]\n",
    "\n",
    "        num_frames = np.minimum(postprocessed_batch.shape[0], vggish_params.MAX_FRAMES)\n",
    "        data = vggish_postprocess.resize(postprocessed_batch, 0, vggish_params.MAX_FRAMES)\n",
    "        data = np.expand_dims(data, 0)\n",
    "        num_frames = np.expand_dims(num_frames, 0)\n",
    "\n",
    "        input_tensor = sess.graph.get_collection(\"input_batch_raw\")[0]\n",
    "        num_frames_tensor = sess.graph.get_collection(\"num_frames\")[0]\n",
    "        predictions_tensor = sess.graph.get_collection(\"predictions\")[0]\n",
    "\n",
    "        ## Stap 4\n",
    "        predictions_val, = sess.run(\n",
    "            [predictions_tensor],\n",
    "            feed_dict={\n",
    "                input_tensor: data,\n",
    "                num_frames_tensor: num_frames\n",
    "            })\n",
    "        pred_vals.append(predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Filter predictions (give top 20 where p>0.1)\n",
    "# count = vggish_params.PREDICTIONS_COUNT_LIMIT\n",
    "# hit = vggish_params.PREDICTIONS_HIT_LIMIT\n",
    "# top_indices = np.argpartition(predictions_val[0], -count)[-count:]\n",
    "# line = ((class_map[i], float(predictions_val[0][i])) for i in top_indices if predictions_val[0][i] > hit)\n",
    "# predictions = sorted(line, key=lambda p: -p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Motor vehicle (road)', 0.2745019793510437), ('Motorcycle', 0.2172030806541443), ('Dog', 0.19438408315181732), ('Aircraft', 0.1851743906736374), ('Boat, Water vehicle', 0.11269421875476837)]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Probabilities per increment\n",
    "preds=[]\n",
    "for p in pred_vals :\n",
    "    line = [(class_map[i], float(p[0][i])) for i in range(1,len(p[0]))]\n",
    "    # skip dog\n",
    "    l = [i for i in line if i[0] != 'Dog']\n",
    "    preds.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec33b20b19ef49a29ee7f660005028a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=241)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# progres log\n",
    "from log_progress import log_progress\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# dark style\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "#type(preds[0][0])\n",
    "for i in log_progress(range(len(preds)),every = 10): # len(preds)\n",
    "    df = pd.DataFrame(preds[i], columns = ['label',\"aps\"])\n",
    "    # find bar with prob > cutoff\n",
    "    threshold = 0.25\n",
    "\n",
    "    # split it up\n",
    "    above_threshold = np.maximum(df.aps - threshold, 0)\n",
    "    below_threshold = np.minimum(df.aps, threshold)\n",
    "    \n",
    "    # and plot it\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.barh(y = df.label, width = below_threshold, align='center', alpha=0.5, color=\"grey\")\n",
    "    ax.barh(y = df.label, width = above_threshold, align='center', alpha=0.8, color=\"r\",\n",
    "            left =  threshold)\n",
    "    # vertical line indicating the threshold\n",
    "    ax.axvline(x = threshold, ls='dashed')\n",
    "    \n",
    "    plt.title('SERVAL Listening Results',fontsize=20)\n",
    "    plt.xlabel('Probability', fontsize=15)\n",
    "    plt.ylabel('Sound Class',fontsize=15)\n",
    "    plt.xlim(0,1)\n",
    "    ax.set_xticklabels([])\n",
    "    #plt.show()\n",
    "    plt.savefig(format(i, '03d')+'.png', bbox_inches=\"tight\")\n",
    "    f.close()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.060041\n",
       "1     0.045945\n",
       "2     0.074987\n",
       "3     0.000098\n",
       "4     0.013608\n",
       "5     0.000029\n",
       "6     0.000573\n",
       "7     0.023603\n",
       "8     0.049275\n",
       "9     0.090158\n",
       "10    0.054579\n",
       "11    0.005466\n",
       "12    0.010920\n",
       "13    0.154569\n",
       "14    0.000841\n",
       "15    0.007009\n",
       "16    0.002714\n",
       "17    0.022402\n",
       "18    0.026849\n",
       "19    0.200000\n",
       "20    0.001916\n",
       "21    0.001973\n",
       "Name: aps, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "below_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 10)\n",
      "range(1, 11)\n",
      "range(2, 12)\n",
      "range(3, 13)\n",
      "range(4, 14)\n",
      "range(5, 15)\n",
      "range(6, 16)\n",
      "range(7, 17)\n",
      "range(8, 18)\n",
      "range(9, 19)\n",
      "range(10, 20)\n",
      "range(11, 21)\n",
      "range(12, 22)\n",
      "range(13, 23)\n",
      "range(14, 24)\n"
     ]
    }
   ],
   "source": [
    "a = range(25)\n",
    "for i in range(10,len(a)):\n",
    "    print(a[i-10:i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
