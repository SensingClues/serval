{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to download features from youtube8m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Downloads YouTube8M Dataset files for a specific partition from a mirror.\n",
    "\n",
    "This download script will be served from http://data.yt8m.org/download.py. The\n",
    "partitions are 1/{frame_level,video_level}/{train,validate,test}\n",
    "\n",
    "To run locally, do:\n",
    "  cat download.py | partition=2/video/train mirror=us python\n",
    "\n",
    "Or to download just 1/1000th of the data:\n",
    "  cat download.py | shard=1,1000 partition=2/video/train mirror=us python\n",
    "\"\"\"\n",
    "\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def md5sum(filename):\n",
    "    \"\"\"Computes the MD5 Hash for the contents of `filename`.\"\"\"\n",
    "    md5 = hashlib.md5()\n",
    "    with open(filename, 'rb') as fin:\n",
    "        for chunk in iter(lambda: fin.read(128 * md5.block_size), b''):\n",
    "            md5.update(chunk)\n",
    "    return md5.hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "def dwnld(partition, shard, mirror):\n",
    "    \"\"\"download tr records we need partition, shards and mirror\"\"\"\n",
    "\n",
    "    partition_parts = partition.split('/')\n",
    "\n",
    "    assert mirror in {'us', 'eu', 'asia'}\n",
    "    assert len(partition_parts) == 3\n",
    "    assert partition_parts[1] in {'video_level', 'frame_level', 'video', 'frame'}\n",
    "    assert partition_parts[2] in {'train', 'test', 'validate'}\n",
    "\n",
    "    plan_url = 'http://data.yt8m.org/{}/download_plans/{}_{}.json'.format(partition_parts[0], partition_parts[1], partition_parts[2])\n",
    "\n",
    "    num_shards = 1\n",
    "    shard_id = 1\n",
    "    \n",
    "    #shard_id, num_shards = os.environ['shard'].split(',')\n",
    "    shard_id, num_shards = shard.split(',')\n",
    "    shard_id = int(shard_id)\n",
    "    num_shards = int(num_shards)\n",
    "    assert shard_id >= 1\n",
    "    assert shard_id <= num_shards\n",
    "\n",
    "    plan_filename = '%s_download_plan.json' % partition.replace('/', '_')\n",
    "\n",
    "    if os.path.exists(plan_filename):\n",
    "        print ('Resuming Download ...')\n",
    "    else:\n",
    "        print ('Starting fresh download in this directory. Please make sure you '\n",
    "               'have >2TB of free disk space!')\n",
    "        os.system('curl %s > %s' % (plan_url, plan_filename))\n",
    "\n",
    "    download_plan = json.loads(open(plan_filename).read())\n",
    "\n",
    "    files = [f for f in download_plan['files'].keys()\n",
    "           if int(hashlib.md5(f.encode('utf-8')).hexdigest(), 16) % num_shards == shard_id - 1]\n",
    "\n",
    "    print ('Files remaining %i' % len(files))\n",
    "    for f in files:\n",
    "        print ('Downloading: %s' % f)\n",
    "        if os.path.exists(f) and md5sum(f) == download_plan['files'][f]:\n",
    "            print ('Skipping already downloaded file %s' % f)\n",
    "            continue\n",
    "\n",
    "        download_url = 'http://%s.data.yt8m.org/%s/%s' % (mirror, partition, f)\n",
    "        os.system('curl %s > %s' % (download_url, f))\n",
    "        if md5sum(f) == download_plan['files'][f]:\n",
    "            print ('Successfully downloaded %s\\n\\n' % f)\n",
    "            del download_plan['files'][f]\n",
    "            open(plan_filename, 'w').write(json.dumps(download_plan))\n",
    "        else:\n",
    "            print ('Error downloading %s. MD5 does not match!\\n\\n' % f)\n",
    "\n",
    "    print ('All done. No more files to download.')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming Download ...\n",
      "Files remaining 6\n",
      "Downloading: trainON.tfrecord\n",
      "Error downloading trainON.tfrecord. MD5 does not match!\n",
      "\n",
      "\n",
      "Downloading: trainpj.tfrecord\n",
      "Error downloading trainpj.tfrecord. MD5 does not match!\n",
      "\n",
      "\n",
      "Downloading: trainSA.tfrecord\n",
      "Error downloading trainSA.tfrecord. MD5 does not match!\n",
      "\n",
      "\n",
      "Downloading: trainpI.tfrecord\n",
      "Error downloading trainpI.tfrecord. MD5 does not match!\n",
      "\n",
      "\n",
      "Downloading: train8C.tfrecord\n",
      "Error downloading train8C.tfrecord. MD5 does not match!\n",
      "\n",
      "\n",
      "Downloading: trainCc.tfrecord\n",
      "Error downloading trainCc.tfrecord. MD5 does not match!\n",
      "\n",
      "\n",
      "All done. No more files to download.\n"
     ]
    }
   ],
   "source": [
    "partition = '1/video_level/train'\n",
    "mirror = 'eu'\n",
    "shard = '10,1000'\n",
    "\n",
    "os.chdir(\"./dataset/features\")\n",
    "\n",
    "dwnld(partition, shard, mirror)\n",
    "\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hugo/git/serval/serval'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"./serval\")\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
