{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import ntpath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import gfile\n",
    "from tensorflow import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project name (this is the folder name where the output files will be stored)\n",
    "custom_data_folder = 'amsterdam_custom_samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of TFRecords in a single file\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serval_data_folder = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_selected_classes_filepath = serval_data_folder + '/' + custom_data_folder + '/csv_files/input_selected_classes.csv'\n",
    "output_class_mapping_filepath   = serval_data_folder + '/' + custom_data_folder + '/csv_files/output_class_mapping.csv' \n",
    "output_tfrecords_train_path     = serval_data_folder + '/' + custom_data_folder + '/tfrecords_model_input/train'\n",
    "output_tfrecords_eval_path      = serval_data_folder + '/' + custom_data_folder + '/tfrecords_model_input/eval'\n",
    "\n",
    "tfrecords_train_search_string   = serval_data_folder + '/' + custom_data_folder + '/tfrecords_all/train_*.tfrecord'\n",
    "tfrecords_eval_search_string    = serval_data_folder + '/' + custom_data_folder + '/tfrecords_all/eval_*.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_selected_classes = pd.read_csv(input_selected_classes_filepath, sep=\";\")\n",
    "print('[INFO]: df_input_selected_classes')\n",
    "print(df_input_selected_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create class mapping to 1:20\n",
    "\n",
    "## First validate that there are no duplicates in the input file\n",
    "assert(not any(df_input_selected_classes.label.duplicated())) ##, \"df_input_selected_classes.label is expected to have unique labels!\")\n",
    "\n",
    "## Create class mapping\n",
    "df_output_class_mapping = df_input_selected_classes.loc[df_input_selected_classes.enable == 1].copy(deep=True)\n",
    "\n",
    "del df_output_class_mapping['enable']\n",
    "df_output_class_mapping['old_label'] = df_output_class_mapping['label']\n",
    "df_output_class_mapping['label'] = list(range(0, len(df_output_class_mapping)))\n",
    "df_output_class_mapping['count_train'] = 0\n",
    "df_output_class_mapping['count_eval'] = 0\n",
    "\n",
    "print('[INFO]: df_output_class_mapping')\n",
    "print(df_output_class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTFRecord(example_old, new_labels):\n",
    "    \n",
    "    ## Bouw structuur van tf-record met video-id, labels en features\n",
    "    \n",
    "    audio_embedding = example_old.feature_lists.feature_list['audio_embedding']\n",
    "    feature_lists = tf.train.FeatureLists(feature_list={\"audio_embedding\": audio_embedding})\n",
    "    #print(\"New labels: \" + str(new_labels))\n",
    "    \n",
    "    label_feat = tf.train.Feature(int64_list=tf.train.Int64List(value=new_labels))\n",
    "    video_id = example_old.context.feature['video_id'].bytes_list.value\n",
    "    videoid_feat = tf.train.Feature(bytes_list=tf.train.BytesList(value=video_id)) \n",
    "\n",
    "    context_feats = tf.train.Features(feature={\"labels\": label_feat, \"video_id\": videoid_feat})\n",
    "\n",
    "    sequence_example = tf.train.SequenceExample(context=context_feats, feature_lists=feature_lists)\n",
    "    \n",
    "    return sequence_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewLabels(df_label_mapping, old_labels):\n",
    "    return(df_label_mapping.loc[df_label_mapping.old_label.isin(old_labels)].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllTFRecords(tfrecords_search_string, df_class_mapping, count_type):\n",
    "    tfrecords = {}\n",
    "    \n",
    "    ## Get files\n",
    "    files = gfile.Glob(tfrecords_search_string)\n",
    "    print('[INFO]: Processing ', len(list(files)), ' files from directory: ', tfrecords_search_string, sep='')\n",
    "    \n",
    "    for file in files:\n",
    "        records = list(tf.python_io.tf_record_iterator(path = file))\n",
    "        print('[INFO]: Processing: ', len(records), ' tfrecords from file: ', file, sep='')\n",
    "\n",
    "        for string_record in records:\n",
    "            old_tfrecord = tf.train.SequenceExample()\n",
    "            old_tfrecord.ParseFromString(string_record)\n",
    "\n",
    "            ## Get labels and find for each label the m-code in class_label_indices_old\n",
    "            old_labels = old_tfrecord.context.feature['labels'].int64_list.value\n",
    "            new_labels = getNewLabels(df_class_mapping, old_labels)\n",
    "            if len(new_labels) == 0:\n",
    "                ## Skip files without valid labels\n",
    "                continue\n",
    "                \n",
    "            new_tfrecord = createTFRecord(old_tfrecord, new_labels)\n",
    "\n",
    "            ## Update count of found labels\n",
    "            df_class_mapping[count_type] = df_class_mapping[count_type] + np.where(df_class_mapping.old_label.isin(old_labels), 1, 0)\n",
    "\n",
    "            ## Store new record in dict\n",
    "            tfrecords[len(tfrecords)] = new_tfrecord\n",
    "            \n",
    "    return({'tfrecords':tfrecords, 'df_class_mapping':df_class_mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTFRecordsInBatches(tfrecords, batch_size, output_directory):\n",
    "    ## Generate random permutation without replace\n",
    "    permutation = random.sample(range(0, len(tfrecords)), len(tfrecords))\n",
    "    \n",
    "    batch_index = 0\n",
    "    tfrecords_remain_in_batch = -1\n",
    "    for index in permutation:\n",
    "        if tfrecords_remain_in_batch == 0:\n",
    "            batch_writer.close()\n",
    "\n",
    "        if tfrecords_remain_in_batch <= 0:\n",
    "            ## Create new batch file\n",
    "            tfrecords_remain_in_batch = batch_size\n",
    "            batch_index = batch_index + 1\n",
    "            batch_file_name = str(output_directory + '/sample_' + str(batch_index) + '.tfrecord')\n",
    "            batch_writer = tf.python_io.TFRecordWriter(batch_file_name)\n",
    "\n",
    "        ## Write to file\n",
    "        batch_writer.write(tfrecords[index].SerializeToString())\n",
    "        tfrecords_remain_in_batch = tfrecords_remain_in_batch - 1\n",
    "        \n",
    "    batch_writer.close()\n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read all train records\n",
    "tfrecords_train = getAllTFRecords(tfrecords_train_search_string, df_output_class_mapping.copy(deep=True), 'count_train')\n",
    "\n",
    "## Write batches\n",
    "writeTFRecordsInBatches(tfrecords_train['tfrecords'], batch_size, output_tfrecords_train_path)\n",
    "\n",
    "## Create ouput\n",
    "df_output_class_mapping = tfrecords_train['df_class_mapping']\n",
    "print(df_output_class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read all eval records\n",
    "tfrecords_eval = getAllTFRecords(tfrecords_eval_search_string, df_output_class_mapping.copy(deep=True), 'count_eval')\n",
    "\n",
    "## Write batches\n",
    "writeTFRecordsInBatches(tfrecords_eval['tfrecords'], batch_size, output_tfrecords_eval_path)\n",
    "\n",
    "## Create ouput\n",
    "df_output_class_mapping = tfrecords_eval['df_class_mapping']\n",
    "print(df_output_class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write new labels and descriptions back to csv_file\n",
    "df_output_class_mapping['display_name'] = df_output_class_mapping.description\n",
    "df_output_class_mapping['index'] = df_output_class_mapping.label\n",
    "df_output_class_mapping.to_csv(output_class_mapping_filepath, sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
