{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import ntpath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import gfile\n",
    "from tensorflow import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./vggish')\n",
    "\n",
    "import vggish_input\n",
    "import vggish_postprocess\n",
    "import vggish_params\n",
    "import vggish_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "serval_data_folder = \"../data/\"\n",
    "\n",
    "# we process train and eval files seperatly\n",
    "# wav file that are in a '*_trn' folder land in the _trn folder\n",
    "# wav file that are in a '*_eval' folder land in the _eval folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete flags if needed\n",
    "delattr(flags.FLAGS, 'f')\n",
    "delattr(flags.FLAGS, 'audio_embedding_feature_name')\n",
    "delattr(flags.FLAGS, 'pca_params')\n",
    "delattr(flags.FLAGS, 'checkpoint')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_string(\n",
    "    'audio_embedding_feature_name', 'audio_embedding',\n",
    "    'Path to the VGGish checkpoint file.')\n",
    "\n",
    "## locatie (handmatig downloaden)\n",
    "## https://github.com/tensorflow/models/tree/master/research/audioset/vggish\n",
    "pca_params_vggish_model_folder = serval_data_folder + \"vggish_model/models/\"\n",
    "print('Files in vggish model directory: (Expecting vggish_..., youtube_...)')\n",
    "print(os.listdir(pca_params_vggish_model_folder))\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'pca_params', pca_params_vggish_model_folder + 'vggish_pca_params.npz',\n",
    "    'Path to the VGGish PCA parameters file.')\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'checkpoint', pca_params_vggish_model_folder + 'vggish_model.ckpt',\n",
    "    'Path to the VGGish checkpoint file.')\n",
    "\n",
    "# flags.DEFINE_string(\n",
    "#    'yt_checkpoint', 'models/youtube_model.ckpt',\n",
    "#    'Path to the VGGish checkpoint file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO map to new directory structure in amsterdam_custom_samples\n",
    "wav_samples_custom_path = serval_data_folder + \"wav_samples_custom/\"\n",
    "wav_samples_custom_labels_csv = wav_samples_custom_path + \"wav_samples_custom_labels.csv\"\n",
    "target_wav_samples_custom_all_enumerated_csv = wav_samples_custom_path + \"wav_samples_custom_all_enumerated_and_labeled.csv\"\n",
    "\n",
    "# setup the locations for the tensorflow records\n",
    "target_folder_tfrecords = serval_data_folder + \"tf_records_samples/\"\n",
    "# folder extensions\n",
    "trn_ext = '_trn'\n",
    "eval_ext = '_eval'\n",
    "target_folder_tfrecords_trn = target_folder_tfrecords + trn_ext + '/'\n",
    "target_folder_tfrecords_eval = target_folder_tfrecords + eval_ext + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read class labels\n",
    "wav_samples_class_labels = pd.read_csv(wav_samples_custom_labels_csv, sep=\";\")\n",
    "#print(wav_samples_class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate all the available wav files, label them and store a data-frame of the result\n",
    "def collectAndLabelSamples(full_path_name, label, description, class_name):\n",
    "    ## Read and rewrite all test files\n",
    "    files = gfile.Glob(str(full_path_name + \"*.wav\"))\n",
    "    \n",
    "    df = pd.DataFrame(columns=['index', 'label', 'description', 'file_path', 'filename', 'class_name'])\n",
    "    count = 1\n",
    "    for file in files:\n",
    "        df_row = pd.DataFrame({'index':count, 'label':[label], 'description':[description], 'file_path':[file], 'filename':[ntpath.basename(file)], 'class_name':[class_name]})\n",
    "        df = df.append(df_row, ignore_index = True)\n",
    "        count = count + 1\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Enumerate all the available wav files, label them and store a data-frame of the result\n",
    "# we have '_trn' and '_eval' folders now\n",
    "# we do '_trn' first\n",
    "folder_ext = eval_ext\n",
    "\n",
    "df_all_wav_samples = pd.DataFrame(columns=['index', 'label', 'description', 'file_path', 'filename', 'class_name'])\n",
    "for index, row in wav_samples_class_labels.iterrows():\n",
    "    if row['enable'] == 1:\n",
    "        print('Processing record ', index, '; label=', row.label, ', description=', row.description, ', path=', row.folder_name, sep='')\n",
    "        df_row = collectAndLabelSamples(wav_samples_custom_path + row.folder_name + folder_ext + '/', row.label, row.description, row.folder_name )\n",
    "        df_all_wav_samples = df_all_wav_samples.append(df_row, ignore_index = True)\n",
    "    else:\n",
    "        print('Skipping record ', index, '; label=', row.label, ', description=', row.description, ', path=', row.folder_name, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write df_all_wav_samples to csv\n",
    "print(df_all_wav_samples.head())\n",
    "df_all_wav_samples.to_csv(target_wav_samples_custom_all_enumerated_csv, sep=';')\n",
    "\n",
    "df_all_wav_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read all samples from disk in case you would like to change some by hand.\n",
    "df_all_wav_samples = []\n",
    "df_all_wav_samples = pd.read_csv(target_wav_samples_custom_all_enumerated_csv, sep=\";\")\n",
    "print(df_all_wav_samples.head().loc[:,'file_path'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Voor alle wav-files in een map, gebeurt het volgende:\n",
    "\n",
    "## Eerst wordt het wav-file ingelezen en de bijbehorende label(s) opgezocht in een csv-bestand\n",
    "## Als video-id wordt een willekeurig id'tje gegeven (in dit geval allemaal dezelfde)\n",
    "\n",
    "## Dan parsen we wav-file naar embeddings: \n",
    "# (dit gebeurt door vggish_input.wavfile_to_example aan te roepen)\n",
    "# Stap 1a: lezen van wav-file, input is array met samples die db aanduiden. Ook sample rate (per sec) wordt gelezen\n",
    "# Stap 1b: Bij 2d array (stereo, ipv mono) bereken gemiddelde, daarna normaliseren (delen door 32.768)\n",
    "# Stap 2: Bepaal examples in vorm [batch size, num frames, num bands].\n",
    "    # Hierbij worden voor verschillende batches (omdat alles tegelijk niet in 1x in NN kan),\n",
    "    # een log mel spectrogram gemaakt (in vorm [num_frames, num_bands])\n",
    "# Stap 3: Bepaal features: nu wordt de embedding laag gemaakt (PCA-components, discreet maken etc)\n",
    "    # Hiervoor worden model-parameters opgehaald die eerder zijn opgeslagen\n",
    "    \n",
    "## Daarna wordt een sequence example gemaakt (in getSequenceExample) en het als tf-records weggeschreven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Function that takes examples from wav-file as input and returns a sequence example\n",
    "\n",
    "def getSequenceExample(examples_batch, labels, video_id=[b'-1LrH01Ei1w']):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "\n",
    "        # Prepare a postprocessor to munge the model embeddings.\n",
    "        pproc = vggish_postprocess.Postprocessor(FLAGS.pca_params)\n",
    "    \n",
    "        # Define the model: load the checkpoint and locate input and output tensors\n",
    "        # Input: [batch_size, num_frames, num_bands] \n",
    "        # where [num_frames, num_bands] represents log-mel-scale spectrogram\n",
    "        # Output: embeddings\n",
    "        vggish_slim.define_vggish_slim(training=False)\n",
    "        vggish_slim.load_vggish_slim_checkpoint(sess, FLAGS.checkpoint)\n",
    "\n",
    "        features_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.VGGISH_INPUT_TENSOR_NAME)\n",
    "        embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.VGGISH_OUTPUT_TENSOR_NAME)\n",
    "\n",
    "        # Run inference and postprocessing.\n",
    "        [embedding_batch] = sess.run([embedding_tensor],\n",
    "                                     feed_dict={features_tensor: examples_batch})\n",
    "        print(embedding_batch.shape)\n",
    "        if(embedding_batch.shape!=10):\n",
    "            print(\"*****************************************************************\")\n",
    "\n",
    "        postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "        #print(postprocessed_batch)\n",
    "\n",
    "\n",
    "        ## Maak labels en video-id voor in de example\n",
    "        label_feat = tf.train.Feature(int64_list=tf.train.Int64List(value=labels))\n",
    "        videoid_feat = tf.train.Feature(bytes_list=tf.train.BytesList(value=video_id))\n",
    "\n",
    "        ## Maak sequence example\n",
    "        seq_example = tf.train.SequenceExample(\n",
    "            context = tf.train.Features(feature={\"labels\": label_feat, \"video_id\": videoid_feat}),\n",
    "            feature_lists = tf.train.FeatureLists(\n",
    "                feature_list={\n",
    "                    FLAGS.audio_embedding_feature_name:\n",
    "                        tf.train.FeatureList(\n",
    "                            feature=[\n",
    "                                tf.train.Feature(\n",
    "                                    bytes_list=tf.train.BytesList(\n",
    "                                        value=[embedding.tobytes()]))\n",
    "                                for embedding in postprocessed_batch\n",
    "                            ]\n",
    "                        )\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return(seq_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def encode_wav_files(wav_files, df_labels, output_directory, class_name):\n",
    "    # setup a writer\n",
    "    tf_record_writer = tf.python_io.TFRecordWriter(str(output_directory + class_name + '.tfrecord'))\n",
    "    \n",
    "    start = time.time()\n",
    "    count = 0\n",
    "    for file in wav_files:\n",
    "        print(\"[INFO]: Count=\", count, \"/\", len(wav_files), \"; Time=\", round((time.time() - start)), sep='')\n",
    "        print(\"Filename: \" + file, sep='')\n",
    "\n",
    "        ## Fetch labels\n",
    "        df_sample_labels = df_labels.loc[df_labels.filename == ntpath.basename(file)]\n",
    "        if len(df_sample_labels) == 0:\n",
    "            print('[ERROR]: Found sample without labels; filename=', file, sep='')\n",
    "        else:\n",
    "            ## .. encode - Part 1\n",
    "            examples_batch = vggish_input.wavfile_to_examples(file)\n",
    "            \n",
    "            if(examples_batch.shape[0]>10):\n",
    "                nr_sec = examples_batch.shape[0]\n",
    "                print(nr_sec)\n",
    "                start = int(math.floor((nr_sec-10)/2))\n",
    "                print(\"start: \" + str(start))\n",
    "                end = int(nr_sec-math.ceil((nr_sec-10)/2))\n",
    "                print(\"end: \" + str(end))\n",
    "                examples_batch = examples_batch[start:end, :, :]\n",
    "                print(examples_batch.shape)\n",
    "            \n",
    "            ## .. encode - Part 2\n",
    "            seq_example = getSequenceExample(examples_batch, df_sample_labels.label.unique())\n",
    "            \n",
    "            ## .. write to file\n",
    "            tf_record_writer.write(seq_example.SerializeToString())\n",
    "            \n",
    "            ## .. done\n",
    "            count = count + 1\n",
    "\n",
    "    tf_record_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  actual tf encoding\n",
    "start = time.time()\n",
    "for class_name in df_all_wav_samples.class_name.unique():\n",
    "    df_class_wav_samples = df_all_wav_samples.loc[df_all_wav_samples.class_name == class_name]\n",
    "    \n",
    "    print('Processing: ', class_name, '; sample_count=', len(df_class_wav_samples), sep='')\n",
    "    #print(\"[INFO]: Start time: \", round((time.time() - start)))\n",
    "    # we add the folder extension here\n",
    "    encode_wav_files(df_class_wav_samples.file_path, df_all_wav_samples, target_folder_tfrecords_eval , class_name)\n",
    "    #print(\"[INFO]: End time: \", round((time.time() - start)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Lees stuk voor stuk alle wav-files in\n",
    "## Zoek het bijbehorende label op in een csv-bestand\n",
    "## Bepaal de embeddings\n",
    "\n",
    "# Prepare a record writer to store the postprocessed embeddings.\n",
    "## Trainset\n",
    "if(label == \"gunshots\"):\n",
    "    train_tfrecord = str(tfrecord_path + 'gun_train.tfrecord')\n",
    "    test_tfrecord = str(tfrecord_path + 'gun_test.tfrecord')\n",
    "elif(label == \"elephants_angela\"):\n",
    "    train_tfrecord = str(tfrecord_path + 'elephant_angela_train.tfrecord')\n",
    "    test_tfrecord = str(tfrecord_path + 'elephant_angela_test.tfrecord')\n",
    "elif(label == \"background_angela\"):\n",
    "    train_tfrecord = str(tfrecord_path + 'background_angela_train.tfrecord')\n",
    "    test_tfrecord = str(tfrecord_path + 'background_angela_test.tfrecord')\n",
    "elif(label == \"elephants_wenger\"):\n",
    "    train_tfrecord = str(tfrecord_path + 'elephant_wenger_train.tfrecord')\n",
    "    test_tfrecord = str(tfrecord_path + 'elephant_wenger_test.tfrecord')\n",
    "elif(label == \"bush_wenger\"):\n",
    "    train_tfrecord = str(tfrecord_path + 'bush_wenger_train.tfrecord')\n",
    "    test_tfrecord = str(tfrecord_path + 'bush_wenger_test.tfrecord')\n",
    "\n",
    "    \n",
    "    \n",
    "train_writer = tf.python_io.TFRecordWriter(train_tfrecord)\n",
    "test_writer = tf.python_io.TFRecordWriter(test_tfrecord)\n",
    "\n",
    "## Read and rewrite all test files\n",
    "files = gfile.Glob(str(wavfile_path + \"*.wav\"))\n",
    "\n",
    "count = 1\n",
    "for file in files:\n",
    "    \n",
    "    print(\"file nr: \" + str(count))\n",
    "    print(\"Filename: \" + file)\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    #print(\"Filename: \" + str(file))\n",
    "   \n",
    "    ## Find labels belonging to wav-file\n",
    "    if(label==\"gunshots\"):\n",
    "        labels = getLabels(file)\n",
    "        if(labels[0]==11):\n",
    "            nr_9mm += 1\n",
    "        elif(labels[0]==12):\n",
    "            nr_556 += 1\n",
    "    elif(label == \"elephants_wenger\"):\n",
    "        labels = [13]\n",
    "        elephants += 1\n",
    "    elif(label == \"bush_wenger\"):\n",
    "        labels = [14]\n",
    "        bush += 1\n",
    "    elif(label == \"elephants_angela\"):\n",
    "        labels = [15]\n",
    "        elephants_angela += 1\n",
    "    elif(label == \"background_angela\"):\n",
    "        labels = [16]\n",
    "        elephants_angela += 1\n",
    "    \n",
    "    ## This function reads the wav file and converts the samples into np arrays of [batch size, num frames, num bands]\n",
    "    #examples_batch = vggish_input.wavfile_to_examples(str(FLAGS.wavfile_path + wav_file))\n",
    "    examples_batch = vggish_input.wavfile_to_examples(file)\n",
    "    \n",
    "    if(examples_batch.shape[0]>10):\n",
    "        nr_sec = examples_batch.shape[0]\n",
    "        print(nr_sec)\n",
    "        start = int(math.floor((nr_sec-10)/2))\n",
    "        print(\"start: \" + str(start))\n",
    "        end = int(nr_sec-math.ceil((nr_sec-10)/2))\n",
    "        print(\"end: \" + str(end))\n",
    "        examples_batch = examples_batch[start:end, :, :]\n",
    "        print(examples_batch.shape)\n",
    "    \n",
    "    #print(\"Examples shape: \" + str(examples_batch.shape))\n",
    "   \n",
    "    seq_example = getSequenceExample(examples_batch, labels)\n",
    "    \n",
    "    rand = random.random()\n",
    "    if rand <= pct_train:\n",
    "        train_writer.write(seq_example.SerializeToString())\n",
    "    else:\n",
    "        test_writer.write(seq_example.SerializeToString())\n",
    "    \n",
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"nr 9mm: \" + str(nr_9mm))\n",
    "print(\"nr 556: \" + str(nr_556))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"nr elephants: \" + str(elephants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"nr bush: \" + str(bush))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"nr gun google: \" + str(gun_google))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
