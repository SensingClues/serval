{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## De functie die tf-records leest en ze uiteindelijk weer wegschrijft (maar dan met minder labels) heet readTfRecord\n",
    "## Deze functie roept andere functies aan: getLabels en getLabelIndices\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"hugo\" # \"urban\" \"amsterdam\" \"jungle\" \n",
    "# if we make a new location / or project we need to do the following:\n",
    "# create a csv labels file\n",
    "# create a csv labels prop file\n",
    "# create the new directories that hold the new train and eval samples\n",
    "#\n",
    "# for example the new project `hugo`\n",
    "# in ..serval/dataset/classlabels/csv_files we need \n",
    "# class_labels_indices_hugo.csv\n",
    "# class_labels_indices_hugo_prop.csv (copy of class_labels_indices_hugo.csv)\n",
    "# in this csv we need to add a column `target_ind` and put all zeros, this is a placeholder of the propertions per class\n",
    "# train_hugo_new and eval_hugo_new in serval/dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inside docker goto right place \n",
    "os.chdir(\"/tf/serval/serval\")\n",
    "# set relvant full paths\n",
    "# /tf is the tensorflow jupyter container mapping\n",
    "path_original_tf_records = \"dataset/audioset_v1_embeddings/\"\n",
    "path_new_tf_records = \"dataset/\"\n",
    "path_class_labels = \"dataset/classlabels/csv_files/\"\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paden naar originele tf-records: bal_train, unbal_train en eval\n",
    "bal_train_data_pattern = path_original_tf_records + \"bal_train/*.tfrecord\"\n",
    "unbal_train_data_pattern = path_original_tf_records + \"unbal_train/*.tfrecord\"\n",
    "eval_data_pattern = path_original_tf_records + \"eval/*.tfrecord\"\n",
    "\n",
    "## Paden voor nieuwe tf-records (train en test)\n",
    "train_pattern_new = path_new_tf_records + \"train_\" + location + \"_new\"\n",
    "eval_pattern_new = path_new_tf_records + \"eval_\" + location + \"_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boolean die aangeeft of alle examples worden geschreven naar een tf-record\n",
    "## Bij false: upsamplen/downsamplen adhv proporties\n",
    "write_all_examples = True\n",
    "## proportie train/test\n",
    "pct_train = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lijst van alle labels (nieuwe) en alle combi's\n",
    "all_labels = []\n",
    "label_combinations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open csv-bestanden met class labels\n",
    "## Oorspronkelijke csv-file google audioset class labels\n",
    "mid_to_label_old = pd.read_csv(path_class_labels + \"class_labels_indices_original_audioset.csv\", sep=\",\")\n",
    "\n",
    "## csv-file met labels (urban/jungle/amsterdam)\n",
    "new_label_file = \"class_labels_indices_\" + location + \".csv\"\n",
    "mid_to_label_new = pd.read_csv(path_class_labels + new_label_file, sep=\";\")\n",
    "## mid_to_label_new = pd.read_csv('csv_files/class_labels_indices_urban.csv', sep=\";\")\n",
    "\n",
    "## Naam bestand om proporties naartoe te schrijven (of om te gebruiken bij sampelen)\n",
    "## Als deze nog niet bestaat: maak een kopietje van mid_to_labels_new met de naam die hieronder staat\n",
    "name_label_prop_file = \"class_labels_indices_\" + location + \"_prop.csv\"\n",
    "label_proportions = pd.read_csv(path_class_labels + name_label_prop_file, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mid_to_label_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deze functie checkt of een example wordt gemaakt (downsamplen)\n",
    "def checkIfNewExample(labels):\n",
    "    \n",
    "    ## Alleen bij 1 label worden er examples overgeslagen (of bij write_all_examples)\n",
    "    if(len(labels)>1 or write_all_examples):\n",
    "        return True\n",
    "    else:\n",
    "        label = list(labels)[0]\n",
    "        prop = label_proportions.loc[label_proportions['index']==np.int(label), \"target_ind\"].values[0]\n",
    "        rand = random.random()\n",
    "        ## Als random niet proportie overschrijdt, return true\n",
    "        if rand <= prop:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deze functie checkt of er nog een example moet worden gemaakt (upsamplen)\n",
    "## Momenteel kan het aantal enkel verdubbeld worden\n",
    "\n",
    "def checkIfExtraExample(labels):\n",
    "    \n",
    "    ## Alleen bij 1 label worden er examples gekopieerd (of als er niet (up)gesampled wordt)\n",
    "    if(len(labels)>1 or write_all_examples):\n",
    "        return False\n",
    "    else:\n",
    "        label = list(labels)[0]\n",
    "        prop = label_proportions.loc[label_proportions['index']==np.int(label), \"target_ind\"].values[0]-1\n",
    "        rand = random.random()\n",
    "        ## Als random niet proportie overschrijdt, return true\n",
    "        if rand <= prop:    \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Find new label for each of old label (527 -> x)\n",
    "\n",
    "def getNewLabel(label_old):\n",
    "    \n",
    "    ## Get m-id that matches with index\n",
    "    mid = mid_to_label_old.loc[mid_to_label_old['index']==label_old, 'mid']\n",
    "\n",
    "    ## Find the new label belonging to this m-id\n",
    "    label_new = mid_to_label_new.loc[mid_to_label_new['mid']==str(mid.values[0]), 'index']\n",
    "    \n",
    "    return label_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createExample(example_old, new_labels):\n",
    "    \n",
    "    ## Bouw structuur van tf-record met video-id, labels en features\n",
    "    \n",
    "    audio_embedding = example_old.feature_lists.feature_list['audio_embedding']\n",
    "    feature_lists = tf.train.FeatureLists(feature_list={\"audio_embedding\": audio_embedding})\n",
    "    #print(\"New labels: \" + str(new_labels))\n",
    "    \n",
    "    label_feat = tf.train.Feature(int64_list=tf.train.Int64List(value=new_labels))\n",
    "    video_id = example_old.context.feature['video_id'].bytes_list.value\n",
    "    videoid_feat = tf.train.Feature(bytes_list=tf.train.BytesList(value=video_id)) \n",
    "\n",
    "    context_feats = tf.train.Features(feature={\"labels\": label_feat, \"video_id\": videoid_feat})\n",
    "\n",
    "    sequence_example = tf.train.SequenceExample(context=context_feats, feature_lists=feature_lists)\n",
    "    \n",
    "    return sequence_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deze code haalt voor een label alle (grand)parents op\n",
    "## Momenteel worden deze functies niet meer gebruikt.\n",
    "## Maar schroom je niet om eens te kijken hoe deze prachtige recursieve functie werkt!\n",
    "\n",
    "def getParents(label, parents):\n",
    "    \n",
    "    parent = int(mid_to_label_new.loc[mid_to_label_new['index']==label, 'parent'])\n",
    "    \n",
    "    if parent==999:\n",
    "        return parents\n",
    "    else:\n",
    "        parents.append(parent)\n",
    "        return getParents(parent, parents)\n",
    "    return parent\n",
    "\n",
    "def getLabelsWithParents(labels):\n",
    "    total_labels = labels\n",
    "    for label in labels:\n",
    "        parents = getParents(label, [])\n",
    "        total_labels.extend(parents)\n",
    "    return(set(total_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Lees tf-records en iterate over de examples#### Lee \n",
    "#### Voor elk example wordt de video-id gepakt en de bijbehorende lijst m-id's gezocht (in balanced_segment.csv)\n",
    "\n",
    "## 1 tf-record heeft meerdere examples\n",
    "## Deze functie checkt voor elk example of het een label heeft uit onze labelset\n",
    "\n",
    "## Input: filename van tf-record (pad) en prefix (vanwege dubbele filenames)\n",
    "## Result: schrijven van nieuw tf-record\n",
    "\n",
    "## Geef prefix mee (om dubbele namen te voorkomen)\n",
    "def readWriteTfRecord(tfrecords_filename, prefix):\n",
    "    \n",
    "    ## Maak 2 writers (train en test) die nieuw tf-records schrijft\n",
    "    \n",
    "    # windows \n",
    "    #record_name = tfrecords_filename.split('\\\\')[-1]\n",
    "    # linux\n",
    "    record_name = tfrecords_filename.split('/')[-1]\n",
    "    ## Let op: hij doet moeilijk over AUX.tfrecord. Dus prefix A bij UX mag niet\n",
    "    #if(str(prefix+record_name_==\"AUX.tfrecord\"):\n",
    "    #    record_name=\"UXx.tfrecord\"\n",
    "        \n",
    "    ## Nieuwe filenames: 1 voor train en 1 voor eval\n",
    "    train_file_new = str(train_pattern_new + '/' + prefix + record_name)\n",
    "    eval_file_new = str(eval_pattern_new + '/' + prefix + record_name)\n",
    "\n",
    "    train_writer = tf.python_io.TFRecordWriter(train_file_new)\n",
    "    eval_writer = tf.python_io.TFRecordWriter(eval_file_new)\n",
    "    nr_new_examples = 0\n",
    "    \n",
    "    ## Iterator that goes through all examples of tf-record\n",
    "    record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)\n",
    "\n",
    "    \n",
    "    for string_record in record_iterator:\n",
    "        \n",
    "        ## Take one example\n",
    "        example = tf.train.SequenceExample()\n",
    "        example.ParseFromString(string_record)\n",
    " \n",
    "        ## Get labels and find for each label the m-code in class_label_indices_old\n",
    "        labels = example.context.feature['labels'].int64_list.value\n",
    "        \n",
    "        new_labels = []\n",
    "        for label in labels:\n",
    "            ## Hij returnt een set van cellen (of leeg of van 1 rij)\n",
    "            label_new = getNewLabel(label)\n",
    "            \n",
    "            if(label_new.shape[0]>0):\n",
    "                new_labels.append(label_new.values[0])\n",
    "        \n",
    "        ## Als enkele (grand)parents ontbreken, voeg ze toe\n",
    "        #new_labels = getLabelsWithParents(new_labels)\n",
    "        ## If any of the labels left (for our model), write new tf-record\n",
    "        \n",
    "        if (len(new_labels) > 0 and checkIfNewExample(new_labels)):\n",
    "        #if(len(new_labels) > 0):\n",
    "            ## Add to all labels\n",
    "            all_labels.extend(new_labels)\n",
    "            label_combinations.append(new_labels)\n",
    "   \n",
    "            sequence_example = createExample(example, new_labels)\n",
    "            nr_new_examples += 1\n",
    "            \n",
    "            ## Write the example\n",
    "            rand = random.random()\n",
    "            if rand <= pct_train:\n",
    "                train_writer.write(sequence_example.SerializeToString())\n",
    "            else:\n",
    "                eval_writer.write(sequence_example.SerializeToString())\n",
    "        \n",
    "            ## Check of er nog een example moet worden gemaakt (upsamplen)\n",
    "            if(checkIfExtraExample(new_labels)):\n",
    "                rand = random.random()\n",
    "                if rand <= pct_train:\n",
    "                    train_writer.write(sequence_example.SerializeToString())\n",
    "                else:\n",
    "                    eval_writer.write(sequence_example.SerializeToString())\n",
    "        \n",
    "                all_labels.extend(new_labels)\n",
    "                label_combinations.append(new_labels)\n",
    "            print('Example gemaakt! Video-id: ' + str(example.context.feature['video_id'].bytes_list.value)\n",
    "                  + ' labels : ' + str(new_labels))\n",
    "\n",
    "    #print(\"nr new examples: \" + str(nr_new_examples))\n",
    "    \n",
    "    # Only write if any examples created\n",
    "\n",
    "    if nr_new_examples > 0:\n",
    "        train_writer.close()\n",
    "        eval_writer.close()\n",
    "        #print(\"tfrecord written\")\n",
    "    else:\n",
    "        #print(\"empty file.. remove: \" + path_tfrecord_new)\n",
    "        os.remove(train_file_new)\n",
    "        os.remove(eval_file_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Maak nieuwe tf-records van bal_train\n",
    "# make sure the new directory location exists train_amsterdam_new\n",
    "# ISSUE amsterdam has new labels? csv not ; separated\n",
    "\n",
    "files = gfile.Glob(bal_train_data_pattern)\n",
    "\n",
    "for file in files:\n",
    "    ## Read a file and rewrite it\n",
    "    readWriteTfRecord(file, 'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Maak nieuwe tf-records van unbal_train\n",
    "# LETOP deze is groot en duurt lang, voor tests niet nodig\n",
    "\n",
    "files = gfile.Glob(unbal_train_data_pattern)\n",
    "\n",
    "for file in files:\n",
    "    ## Read a file and rewrite it\n",
    "    readWriteTfRecord(file, 'U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Maak nieuwe tf-records van eval\n",
    "\n",
    "files = gfile.Glob(eval_data_pattern)\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    ## Read a file and rewrite it\n",
    "    readWriteTfRecord(file, 'E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print voor alle labels het aantal voorkomens in de nieuwe tf-records\n",
    "\n",
    "sum_occur = 0\n",
    "cnt_labels = Counter(all_labels)\n",
    "\n",
    "for i in cnt_labels.most_common(100):\n",
    "    sum_occur = sum_occur + i[1]\n",
    "    print(label_proportions.loc[label_proportions['index']==i[0]]['display_name'].values[0], ' : ', str(i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tellen van lijsten in lijsten is lastig, vandaar dat ik er strings van maak: [0,4] wordt [\"0_4\"]\n",
    "str_combis = []\n",
    "\n",
    "for combi in label_combinations:\n",
    "    str_combi = [str(i) for i in combi]\n",
    "    str_combi = \"_\".join(str_combi)\n",
    "    str_combis.append(str_combi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Houd individuele voorkomens bij (dus aantal keer dat label voorkomt zonder andere labels)\n",
    "ind_occur = [0 for x in range(label_proportions.shape[0])] \n",
    "\n",
    "## Geef meest voorkomende combinaties\n",
    "cnt_label_combinations = Counter(str_combis)\n",
    "for label_combination in cnt_label_combinations.most_common(20):\n",
    "    label_names = []\n",
    "    \n",
    "    ## Maak van string weer een lijst (zie vorige cel)\n",
    "    label_list = label_combination[0].split(\"_\")\n",
    "    \n",
    "    ## Code die alleen individuele labels telt\n",
    "    if(len(label_list)==1):\n",
    "        ind_occur[int(label_list[0])] = label_combination[1]\n",
    "    \n",
    "    for i in label_list:\n",
    "        label_names.append(str(label_proportions.loc[label_proportions['index']==i]['display_name']))\n",
    "    label_names = ', '.join(label_names)\n",
    "    print(label_names,': ', label_combination[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"sum occurences: \" + str(sum_occur))\n",
    "print(\"ind occ: \")\n",
    "print(ind_occur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UP-/DOWN-SAMPLEN\n",
    "\n",
    "## Alle code hierna is alleen om uit te rekenen wat de proporties zijn\n",
    "## Het werkt als volgt:\n",
    "## Van het totale aantal voorkomens van een label (bv 11.000), wordt het gewenste afgetrokken:\n",
    "## bv 11.000-2.000 = 9.000\n",
    "## Dit aantal examples moet geskipt worden, maar dan alleen als het label alleen voorkomt\n",
    "## Daarom wordt de target proportie van het totale individuutjes (target_ind) als volgt berekend:\n",
    "## Stel ind_occ (aantal keer alleen voorkomend) is 10.000, waarvan we er 9.000 niet willen hebben.\n",
    "## (10.000-9.000)/10.000 = 0.1 is dan de kans dat een example wordt geschreven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code die kolom toevoegt aan label-csv (proportion) en deze in de forloop vult\n",
    "\n",
    "## Aantal gewenste samples per label: 2500\n",
    "target = 2500\n",
    "\n",
    "## Aantal voorkomens en aantal voorkomens alleen\n",
    "label_proportions[\"total\"] = 0\n",
    "label_proportions[\"ind_total\"] = 0\n",
    "label_proportions[\"proportion\"] = 0\n",
    "label_proportions[\"target_ind\"] = 0\n",
    "\n",
    "for i in range(mid_to_label_new.shape[0]):\n",
    "    label_proportions.loc[i,\"total\"] = cnt_labels[i]\n",
    "    label_proportions.loc[i,\"ind_total\"] = ind_occur[i]   \n",
    "    label_proportions.loc[i,\"proportion\"] = cnt_labels[i]/sum_occur\n",
    "    label_proportions.loc[i,\"target_ind\"] = (ind_occur[i]-(cnt_labels[i]-target))/ind_occur[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Schrijf bestandje weg\n",
    "label_proportions.to_csv(name_label_prop_file, sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Lees tf-records en iterate over de examples#### Lee \n",
    "#### Voor elk example wordt de video-id gepakt en de bijbehorende lijst m-id's gezocht (in balanced_segment.csv)\n",
    "\n",
    "## 1 tf-record heeft meerdere examples\n",
    "## Deze functie checkt voor elk example of het een label heeft uit onze labelset\n",
    "\n",
    "## Input: filename van tf-record (pad) en prefix (vanwege dubbele filenames)\n",
    "## Result: schrijven van nieuw tf-record\n",
    "\n",
    "## Geef prefix mee (om dubbele namen te voorkomen)\n",
    "def readTfRecord(tfrecords_filename):\n",
    "    \n",
    "    ## Iterator that goes through all examples of tf-record\n",
    "    record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)\n",
    "\n",
    "    \n",
    "    for string_record in record_iterator:\n",
    "        \n",
    "        ## Take one example\n",
    "        example = tf.train.SequenceExample()\n",
    "        example.ParseFromString(string_record)\n",
    " \n",
    "        print(example)\n",
    "        ## Get labels and find for each label the m-code in class_label_indices_old\n",
    "        labels = example.context.feature['labels'].int64_list.value\n",
    "       \n",
    "        #if(labels[0]!=11):\n",
    "        #    print(labels)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'tfrecords/train_jungle_new/gun_train.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readTfRecord(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
