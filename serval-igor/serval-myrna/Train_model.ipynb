{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import get_youtube8m_features as yt_features\n",
    "import frame_level_models\n",
    "import video_level_models\n",
    "import readers\n",
    "import utils\n",
    "import eval_util\n",
    "import export_model\n",
    "import losses\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow import app\n",
    "from tensorflow import gfile\n",
    "from tensorflow import logging\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"jungle\" # \"urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"models/models_\" + location\n",
    "train_data_pattern = \"tfrecords/train_\" + location + \"_new/*.tfrecord\"\n",
    "num_classes = 16\n",
    "\n",
    "if(location==\"jungle\"):\n",
    "    num_classes = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Maak alle flags aan\n",
    "\n",
    "# Dataset flags\n",
    "flags.DEFINE_string(\"feature_names\", \"audio_embedding\", \"Name of the feature \"\n",
    "                  \"to use for training.\")\n",
    "flags.DEFINE_string(\"feature_sizes\", \"128\", \"Length of the feature vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model flags\n",
    "flags.DEFINE_bool(\n",
    "  \"frame_features\", True,\n",
    "  \"If set, then --train_data_pattern must be frame-level features. \"\n",
    "  \"Otherwise, --train_data_pattern must be aggregated video-level \"\n",
    "  \"features. The model must also be set appropriately (i.e. to read 3D \"\n",
    "  \"batches VS 4D batches.\")\n",
    "flags.DEFINE_string(\n",
    "  \"model\", \"FrameLevelLogisticModel\",\n",
    "  \"Which architecture to use for the model. Models are defined \"\n",
    "  \"in models.py.\")\n",
    "flags.DEFINE_bool(\n",
    "  \"start_new_model\", True,\n",
    "  \"If set, this will not resume from a checkpoint and will instead create a\"\n",
    "  \" new model instance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training flags\n",
    "flags.DEFINE_integer(\"batch_size\", 2048,\n",
    "                   \"How many examples to process per batch for training.\")\n",
    "flags.DEFINE_string(\"label_loss\", \"CrossEntropyLoss\",\n",
    "                  \"Which loss function to use for training the model.\")\n",
    "flags.DEFINE_float(\"regularization_penalty\", 1.0,\n",
    "                  \"How much weight to give to the regularization loss (the label loss has \"\n",
    "                  \"a weight of 1).\")\n",
    "flags.DEFINE_float(\"base_learning_rate\", 0.01,\n",
    "                 \"Which learning rate to start with.\")\n",
    "flags.DEFINE_float(\"learning_rate_decay\", 0.95,\n",
    "                 \"Learning rate decay factor to be applied every \"\n",
    "                 \"learning_rate_decay_examples.\")\n",
    "flags.DEFINE_float(\"learning_rate_decay_examples\", 4000000,\n",
    "                 \"Multiply current learning rate by learning_rate_decay \"\n",
    "                 \"every learning_rate_decay_examples.\")\n",
    "flags.DEFINE_integer(\"num_epochs\", 1000,\n",
    "                   \"How many passes to make over the dataset before \"\n",
    "                   \"halting training.\")\n",
    "flags.DEFINE_integer(\"max_steps\", None,\n",
    "                   \"The maximum number of iterations of the training loop.\")\n",
    "flags.DEFINE_integer(\"export_model_steps\", 100,\n",
    "                   \"The period, in number of steps, with which the model \"\n",
    "                   \"is exported for batch prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Other flags\n",
    "flags.DEFINE_integer(\"num_readers\", 16,\n",
    "                   \"How many threads to use for reading input files.\")\n",
    "flags.DEFINE_string(\"optimizer\", \"AdamOptimizer\",\n",
    "                  \"What optimizer class to use.\")\n",
    "flags.DEFINE_float(\"clip_gradient_norm\", 1.0, \"Norm to clip gradients to.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment.\n",
    "env = json.loads(os.environ.get(\"TF_CONFIG\", \"{}\"))\n",
    "\n",
    "os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"]=\"3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cluster data from the environment.\n",
    "cluster_data = env.get(\"cluster\", None)\n",
    "cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the task data from the environment.\n",
    "task_data = env.get(\"task\", None) or {\"type\": \"master\", \"index\": 0}\n",
    "task = type(\"TaskSpec\", (object,), task_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/job:master/task:0: Tensorflow version: 1.8.0.\n"
     ]
    }
   ],
   "source": [
    "def task_as_string(task):\n",
    "  return \"/job:%s/task:%s\" % (task.type, task.index)\n",
    "\n",
    "# Logging the version.\n",
    "logging.set_verbosity(tf.logging.INFO)\n",
    "logging.info(\"%s: Tensorflow version: %s.\",\n",
    "           task_as_string(task), tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functie die elke keer wordt aangeroepen\n",
    "def find_class_by_name(name, modules):\n",
    "  \"\"\"Searches the provided modules for the named class and returns it.\"\"\"\n",
    "  modules = [getattr(module, name, None) for module in modules]\n",
    "  return next(a for a in modules if a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define model\n",
    "model = find_class_by_name(FLAGS.model,\n",
    "    [frame_level_models, video_level_models])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert feature_names and feature_sizes to lists of values.\n",
    "feature_names, feature_sizes = utils.GetListOfFeatureNamesAndSizes(\n",
    "    FLAGS.feature_names, FLAGS.feature_sizes)\n",
    "\n",
    "# Create reader\n",
    "if FLAGS.frame_features:\n",
    "    reader = readers.YT8MFrameFeatureReader(\n",
    "        num_classes=num_classes,\n",
    "        feature_names=feature_names, feature_sizes=feature_sizes)\n",
    "else:\n",
    "    reader = readers.YT8MAggregatedFeatureReader(\n",
    "        num_classes=num_classes,\n",
    "        feature_names=feature_names, feature_sizes=feature_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exporter = export_model.ModelExporter(\n",
    "    frame_features=FLAGS.frame_features,\n",
    "    model=model,\n",
    "    reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "is_master = (task.type == \"master\" and task.index == 0)\n",
    "last_model_export_step = 0\n",
    "max_steps_reached = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/job:master/task:0: Removing existing train directory.\n"
     ]
    }
   ],
   "source": [
    "# Remove old model, if starting new model\n",
    "if is_master and FLAGS.start_new_model:\n",
    "    try:\n",
    "      logging.info(\n",
    "          \"%s: Removing existing train directory.\",\n",
    "          task_as_string(task))\n",
    "      gfile.DeleteRecursively(train_dir)\n",
    "    except:\n",
    "      logging.error(\n",
    "          \"%s: Failed to delete directory \" + train_dir +\n",
    "          \" when starting a new model. Please delete it manually and\" +\n",
    "          \" try again.\", task_as_string(task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Starts a server if the execution is distributed.\"\"\"\n",
    "if cluster:\n",
    "    logging.info(\"%s: Starting trainer within cluster %s.\",\n",
    "               task_as_string(task), cluster.as_dict())\n",
    "    server = start_server(cluster, task)\n",
    "    target = server.target\n",
    "    device_fn = tf.train.replica_device_setter(\n",
    "        ps_device=\"/job:ps\",\n",
    "        worker_device=\"/job:%s/task:%d\" % (task.type, task.index),\n",
    "        cluster=cluster)\n",
    "else:\n",
    "    target = \"\"\n",
    "    device_fn = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/job:master/task:0: Flag 'start_new_model' is set. Building a new model.\n"
     ]
    }
   ],
   "source": [
    "def get_meta_filename(start_new_model, train_dir, task):\n",
    "    if start_new_model:\n",
    "      logging.info(\"%s: Flag 'start_new_model' is set. Building a new model.\",\n",
    "                   task_as_string(task))\n",
    "      return None\n",
    "\n",
    "    latest_checkpoint = tf.train.latest_checkpoint(train_dir)\n",
    "    if not latest_checkpoint:\n",
    "      logging.info(\"%s: No checkpoint file found. Building a new model.\",\n",
    "                   task_as_string(task))\n",
    "      return None\n",
    "\n",
    "    meta_filename = latest_checkpoint + \".meta\"\n",
    "    if not gfile.Exists(meta_filename):\n",
    "      logging.info(\"%s: No meta graph file found. Building a new model.\",\n",
    "                     task_as_string(task))\n",
    "      return None\n",
    "    else:\n",
    "      return meta_filename\n",
    "\n",
    "meta_filename = get_meta_filename(FLAGS.start_new_model, train_dir, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functie die wordt aangeroepen door build_graph\n",
    "\n",
    "def get_input_data_tensors(reader,\n",
    "                           data_pattern,\n",
    "                           batch_size=1000,\n",
    "                           num_epochs=None,\n",
    "                           num_readers=1):\n",
    "  \"\"\"Creates the section of the graph which reads the training data.\n",
    "\n",
    "  Args:\n",
    "    reader: A class which parses the training data.\n",
    "    data_pattern: A 'glob' style path to the data files.\n",
    "    batch_size: How many examples to process at a time.\n",
    "    num_epochs: How many passes to make over the training data. Set to 'None'\n",
    "                to run indefinitely.\n",
    "    num_readers: How many I/O threads to use.\n",
    "\n",
    "  Returns:\n",
    "    A tuple containing the features tensor, labels tensor, and optionally a\n",
    "    tensor containing the number of frames per video. The exact dimensions\n",
    "    depend on the reader being used.\n",
    "\n",
    "  Raises:\n",
    "    IOError: If no files matching the given pattern were found.\n",
    "  \"\"\"\n",
    "  logging.info(\"Using batch size of \" + str(batch_size) + \" for training.\")\n",
    "  with tf.name_scope(\"train_input\"):\n",
    "    files = gfile.Glob(data_pattern)\n",
    "    if not files:\n",
    "      raise IOError(\"Unable to find training files. data_pattern='\" +\n",
    "                    data_pattern + \"'.\")\n",
    "    logging.info(\"Number of training files: %s.\", str(len(files)))\n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "        files, num_epochs=num_epochs, shuffle=True)\n",
    "    training_data = [\n",
    "        reader.prepare_reader(filename_queue) for _ in range(num_readers)\n",
    "    ]\n",
    "\n",
    "    print(training_data)\n",
    "    \n",
    "    ## Create batches by randomly shuffling tensors\n",
    "    return tf.train.shuffle_batch_join(\n",
    "        training_data,\n",
    "        batch_size=batch_size,\n",
    "        capacity=batch_size * 5,\n",
    "        min_after_dequeue=batch_size,\n",
    "        allow_smaller_final_batch=True,\n",
    "        enqueue_many=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deze functie wordt aangeroepen om de Tensorflow-graph te bouwen\n",
    "\n",
    "def build_graph(reader,\n",
    "                model,\n",
    "                train_data_pattern,\n",
    "                label_loss_fn=losses.CrossEntropyLoss(),\n",
    "                batch_size=1000,\n",
    "                base_learning_rate=0.01,\n",
    "                learning_rate_decay_examples=1000000,\n",
    "                learning_rate_decay=0.95,\n",
    "                optimizer_class=tf.train.AdamOptimizer,\n",
    "                clip_gradient_norm=1.0,\n",
    "                regularization_penalty=1,\n",
    "                num_readers=1,\n",
    "                num_epochs=None):\n",
    "  \"\"\"Creates the Tensorflow graph.\n",
    "\n",
    "  This will only be called once in the life of\n",
    "  a training model, because after the graph is created the model will be\n",
    "  restored from a meta graph file rather than being recreated.\n",
    "\n",
    "  Args:\n",
    "    reader: The data file reader. It should inherit from BaseReader.\n",
    "    model: The core model (e.g. logistic or neural net). It should inherit\n",
    "           from BaseModel.\n",
    "    train_data_pattern: glob path to the training data files.\n",
    "    label_loss_fn: What kind of loss to apply to the model. It should inherit\n",
    "                from BaseLoss.\n",
    "    batch_size: How many examples to process at a time.\n",
    "    base_learning_rate: What learning rate to initialize the optimizer with.\n",
    "    optimizer_class: Which optimization algorithm to use.\n",
    "    clip_gradient_norm: Magnitude of the gradient to clip to.\n",
    "    regularization_penalty: How much weight to give the regularization loss\n",
    "                            compared to the label loss.\n",
    "    num_readers: How many threads to use for I/O operations.\n",
    "    num_epochs: How many passes to make over the data. 'None' means an\n",
    "                unlimited number of passes.\n",
    "  \"\"\"\n",
    "\n",
    "  global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "  print(global_step)\n",
    "  local_device_protos = device_lib.list_local_devices()\n",
    "  gpus = [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "  num_gpus = len(gpus)\n",
    "  logging.info(\"Number of GPUs: %s.\", str(num_gpus))\n",
    "\n",
    "  if num_gpus > 0:\n",
    "    logging.info(\"Using the following GPUs to train: \" + str(gpus))\n",
    "    num_towers = num_gpus\n",
    "    device_string = '/gpu:%d'\n",
    "  else:\n",
    "    logging.info(\"No GPUs found. Training on CPU.\")\n",
    "    num_towers = 1\n",
    "    device_string = '/cpu:%d'\n",
    "\n",
    "  learning_rate = tf.train.exponential_decay(\n",
    "      base_learning_rate,\n",
    "      global_step * batch_size * num_towers,\n",
    "      learning_rate_decay_examples,\n",
    "      learning_rate_decay,\n",
    "      staircase=True)\n",
    "  tf.summary.scalar('learning_rate', learning_rate)\n",
    "\n",
    "  optimizer = optimizer_class(learning_rate)\n",
    "\n",
    "  ## Read input files\n",
    "  unused_video_id, model_input_raw, labels_batch, num_frames = (\n",
    "      get_input_data_tensors(\n",
    "          reader,\n",
    "          train_data_pattern,\n",
    "          batch_size=batch_size * num_towers,\n",
    "          num_readers=num_readers,\n",
    "          num_epochs=num_epochs))\n",
    "  tf.summary.histogram(\"model/input_raw\", model_input_raw)\n",
    " \n",
    "  feature_dim = len(model_input_raw.get_shape()) - 1\n",
    "\n",
    "  model_input = tf.nn.l2_normalize(model_input_raw, feature_dim)\n",
    "\n",
    "  tower_inputs = tf.split(model_input, num_towers)\n",
    "  tower_labels = tf.split(labels_batch, num_towers)\n",
    "  tower_num_frames = tf.split(num_frames, num_towers)\n",
    "  tower_gradients = []\n",
    "  tower_predictions = []\n",
    "  tower_label_losses = []\n",
    "  tower_reg_losses = []\n",
    "  for i in range(num_towers):\n",
    "    # For some reason these 'with' statements can't be combined onto the same\n",
    "    # line. They have to be nested.\n",
    "    with tf.device(device_string % i):\n",
    "      with (tf.variable_scope((\"tower\"), reuse=True if i > 0 else None)):\n",
    "        with (slim.arg_scope([slim.model_variable, slim.variable], device=\"/cpu:0\" if num_gpus!=1 else \"/gpu:0\")):\n",
    "          result = model.create_model(\n",
    "            tower_inputs[i],\n",
    "            num_frames=tower_num_frames[i],\n",
    "            vocab_size=reader.num_classes,\n",
    "            labels=tower_labels[i])\n",
    "          #print(tower_labels[i])\n",
    "          for variable in slim.get_model_variables():\n",
    "            tf.summary.histogram(variable.op.name, variable)\n",
    "\n",
    "          predictions = result[\"predictions\"]\n",
    "          tower_predictions.append(predictions)\n",
    "\n",
    "          if \"loss\" in result.keys():\n",
    "            label_loss = result[\"loss\"]\n",
    "          else:\n",
    "            label_loss = label_loss_fn.calculate_loss(predictions, tower_labels[i])\n",
    "\n",
    "          if \"regularization_loss\" in result.keys():\n",
    "            reg_loss = result[\"regularization_loss\"]\n",
    "          else:\n",
    "            reg_loss = tf.constant(0.0)\n",
    "\n",
    "          reg_losses = tf.losses.get_regularization_losses()\n",
    "          if reg_losses:\n",
    "            reg_loss += tf.add_n(reg_losses)\n",
    "\n",
    "          tower_reg_losses.append(reg_loss)\n",
    "\n",
    "          # Adds update_ops (e.g., moving average updates in batch normalization) as\n",
    "          # a dependency to the train_op.\n",
    "          update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "          if \"update_ops\" in result.keys():\n",
    "            update_ops += result[\"update_ops\"]\n",
    "          if update_ops:\n",
    "            with tf.control_dependencies(update_ops):\n",
    "              barrier = tf.no_op(name=\"gradient_barrier\")\n",
    "              with tf.control_dependencies([barrier]):\n",
    "                label_loss = tf.identity(label_loss)\n",
    "\n",
    "          tower_label_losses.append(label_loss)\n",
    "\n",
    "          # Incorporate the L2 weight penalties etc.\n",
    "          final_loss = regularization_penalty * reg_loss + label_loss\n",
    "          gradients = optimizer.compute_gradients(final_loss,\n",
    "              colocate_gradients_with_ops=False)\n",
    "          tower_gradients.append(gradients)\n",
    "  label_loss = tf.reduce_mean(tf.stack(tower_label_losses))\n",
    "  tf.summary.scalar(\"label_loss\", label_loss)\n",
    "  if regularization_penalty != 0:\n",
    "    reg_loss = tf.reduce_mean(tf.stack(tower_reg_losses))\n",
    "    tf.summary.scalar(\"reg_loss\", reg_loss)\n",
    "  merged_gradients = utils.combine_gradients(tower_gradients)\n",
    "\n",
    "  if clip_gradient_norm > 0:\n",
    "    with tf.name_scope('clip_grads'):\n",
    "      merged_gradients = utils.clip_gradient_norms(merged_gradients, clip_gradient_norm)\n",
    "\n",
    "  train_op = optimizer.apply_gradients(merged_gradients, global_step=global_step)\n",
    "\n",
    "  tf.add_to_collection(\"global_step\", global_step)\n",
    "  tf.add_to_collection(\"loss\", label_loss)\n",
    "  tf.add_to_collection(\"predictions\", tf.concat(tower_predictions, 0))\n",
    "  tf.add_to_collection(\"input_batch_raw\", model_input_raw)\n",
    "  tf.add_to_collection(\"input_batch\", model_input)\n",
    "  tf.add_to_collection(\"num_frames\", num_frames)\n",
    "  tf.add_to_collection(\"labels\", tf.cast(labels_batch, tf.float32))\n",
    "  tf.add_to_collection(\"train_op\", train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "INFO:tensorflow:Number of GPUs: 1.\n",
      "INFO:tensorflow:Using the following GPUs to train: ['/device:GPU:0']\n",
      "INFO:tensorflow:Using batch size of 2048 for training.\n",
      "INFO:tensorflow:Number of training files: 5115.\n",
      "[(<tf.Tensor 'train_input/ExpandDims:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_1:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_2:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_3:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_4:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_5:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_6:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_7:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_8:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_9:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_10:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_11:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_12:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_13:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_14:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_15:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_16:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_17:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_18:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_19:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_20:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_21:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_22:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_23:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_24:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_25:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_26:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_27:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_28:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_29:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_30:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_31:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_32:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_33:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_34:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_35:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_36:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_37:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_38:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_39:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_40:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_41:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_42:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_43:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_44:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_45:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_46:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_47:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_48:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_49:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_50:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_51:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_52:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_53:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_54:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_55:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_56:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_57:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_58:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_59:0' shape=(1,) dtype=int32>), (<tf.Tensor 'train_input/ExpandDims_60:0' shape=(1,) dtype=string>, <tf.Tensor 'train_input/ExpandDims_61:0' shape=(1, 300, 128) dtype=float32>, <tf.Tensor 'train_input/ExpandDims_62:0' shape=(1, 14) dtype=bool>, <tf.Tensor 'train_input/ExpandDims_63:0' shape=(1,) dtype=int32>)]\n",
      "WARNING:tensorflow:From <ipython-input-24-7b6b15c1f19d>:47: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as graph:\n",
    "    \n",
    "    if meta_filename:\n",
    "        logging.info(\"%s: Restoring from meta graph file %s\",\n",
    "            task_as_string(task), meta_filename)\n",
    "        saver = tf.train.import_meta_graph(meta_filename)\n",
    "    \n",
    "    with tf.device(device_fn):\n",
    "\n",
    "        if not meta_filename:\n",
    "            \"\"\"Find the model and build the graph.\"\"\"\n",
    "\n",
    "            label_loss_fn = find_class_by_name(FLAGS.label_loss, [losses])()\n",
    "            optimizer_class = find_class_by_name(FLAGS.optimizer, [tf.train])\n",
    "\n",
    "            build_graph(reader=reader,\n",
    "                         model=model,\n",
    "                         optimizer_class=optimizer_class,\n",
    "                         clip_gradient_norm=FLAGS.clip_gradient_norm,\n",
    "                         train_data_pattern=train_data_pattern,\n",
    "                         label_loss_fn=label_loss_fn,\n",
    "                         base_learning_rate=FLAGS.base_learning_rate,\n",
    "                         learning_rate_decay=FLAGS.learning_rate_decay,\n",
    "                         learning_rate_decay_examples=FLAGS.learning_rate_decay_examples,\n",
    "                         regularization_penalty=FLAGS.regularization_penalty,\n",
    "                         num_readers=FLAGS.num_readers,\n",
    "                         batch_size=FLAGS.batch_size,\n",
    "                         num_epochs=FLAGS.num_epochs)\n",
    "\n",
    "        saver = tf.train.Saver(max_to_keep=0, keep_checkpoint_every_n_hours=0.25)\n",
    "    \n",
    "        global_step = tf.get_collection(\"global_step\")[0]\n",
    "        loss = tf.get_collection(\"loss\")[0]\n",
    "        predictions = tf.get_collection(\"predictions\")[0]\n",
    "        labels = tf.get_collection(\"labels\")[0]\n",
    "        train_op = tf.get_collection(\"train_op\")[0]\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        \n",
    "    sv = tf.train.Supervisor(\n",
    "        graph,\n",
    "        logdir=train_dir,\n",
    "        init_op=init_op,\n",
    "        is_chief=is_master,\n",
    "        global_step=global_step,\n",
    "        save_model_secs=15 * 60,\n",
    "        save_summaries_secs=120,\n",
    "        saver=saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(global_step_val, saver, save_path, session):\n",
    "\n",
    "    # If the model has already been exported at this step, return.\n",
    "    if global_step_val == last_model_export_step:\n",
    "      return\n",
    "\n",
    "    last_checkpoint = saver.save(session, save_path, global_step_val)\n",
    "\n",
    "    model_dir = \"{0}/export/step_{1}\".format(train_dir, global_step_val)\n",
    "    logging.info(\"%s: Exporting the model at step %s to %s.\",\n",
    "                 task_as_string(task), global_step_val, model_dir)\n",
    "\n",
    "    model_exporter.export_model(\n",
    "        model_dir=model_dir,\n",
    "        global_step_val=global_step_val,\n",
    "        last_checkpoint=last_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/job:master/task:0: Starting managed session.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path models/models_jungle\\model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:/job:master/task:0: Entering training loop.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:models/models_jungle\\model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:training step 1 | Loss: 9.74 Examples/sec: 565.79\n",
      "INFO:tensorflow:training step 2 | Loss: 9.61 Examples/sec: 1918.12\n",
      "INFO:tensorflow:training step 3 | Loss: 9.50 Examples/sec: 1905.85\n",
      "INFO:tensorflow:training step 4 | Loss: 9.38 Examples/sec: 1977.80\n",
      "INFO:tensorflow:Recording summary at step 4.\n",
      "INFO:tensorflow:training step 5 | Loss: 9.26 Examples/sec: 1855.60\n",
      "INFO:tensorflow:training step 6 | Loss: 9.13 Examples/sec: 1903.40\n",
      "INFO:tensorflow:training step 7 | Loss: 9.01 Examples/sec: 2733.37\n",
      "INFO:tensorflow:training step 8 | Loss: 8.89 Examples/sec: 2624.83\n",
      "INFO:tensorflow:training step 9 | Loss: 8.79 Examples/sec: 2723.54\n",
      "INFO:tensorflow:training step 10 | Loss: 8.67 Examples/sec: 2598.02 | Hit@1: 0.32 PERR: 0.31 GAP: 0.20\n",
      "INFO:tensorflow:models/models_jungle\\model.ckpt-10 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:/job:master/task:0: Exporting the model at step 10 to models/models_jungle/export/step_10.\n",
      "INFO:tensorflow:Restoring parameters from models/models_jungle\\model.ckpt-10\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'models/models_jungle/export/step_10\\\\saved_model.pb'\n",
      "INFO:tensorflow:training step 11 | Loss: 8.58 Examples/sec: 4373.07\n",
      "INFO:tensorflow:training step 12 | Loss: 8.48 Examples/sec: 2680.10\n",
      "INFO:tensorflow:training step 13 | Loss: 8.35 Examples/sec: 2649.39\n",
      "INFO:tensorflow:training step 14 | Loss: 8.27 Examples/sec: 2677.73\n",
      "INFO:tensorflow:training step 15 | Loss: 8.19 Examples/sec: 2396.30\n",
      "INFO:tensorflow:training step 16 | Loss: 8.07 Examples/sec: 2594.42\n",
      "INFO:tensorflow:training step 17 | Loss: 7.98 Examples/sec: 2618.87\n",
      "INFO:tensorflow:training step 18 | Loss: 7.85 Examples/sec: 2613.05\n",
      "INFO:tensorflow:training step 19 | Loss: 7.76 Examples/sec: 2753.10\n",
      "INFO:tensorflow:training step 20 | Loss: 7.68 Examples/sec: 2561.59 | Hit@1: 0.45 PERR: 0.45 GAP: 0.33\n",
      "INFO:tensorflow:training step 21 | Loss: 7.61 Examples/sec: 3015.47\n",
      "INFO:tensorflow:training step 22 | Loss: 7.50 Examples/sec: 2728.31\n",
      "INFO:tensorflow:training step 23 | Loss: 7.42 Examples/sec: 2334.38\n",
      "INFO:tensorflow:training step 24 | Loss: 7.38 Examples/sec: 2495.06\n",
      "INFO:tensorflow:training step 25 | Loss: 7.26 Examples/sec: 2649.65\n",
      "INFO:tensorflow:training step 26 | Loss: 7.17 Examples/sec: 2662.30\n",
      "INFO:tensorflow:training step 27 | Loss: 7.07 Examples/sec: 2660.65\n",
      "INFO:tensorflow:training step 28 | Loss: 6.94 Examples/sec: 2684.37\n",
      "INFO:tensorflow:training step 29 | Loss: 6.87 Examples/sec: 2630.74\n",
      "INFO:tensorflow:training step 30 | Loss: 6.81 Examples/sec: 2582.65 | Hit@1: 0.55 PERR: 0.55 GAP: 0.41\n",
      "INFO:tensorflow:training step 31 | Loss: 6.76 Examples/sec: 2329.60\n",
      "INFO:tensorflow:training step 32 | Loss: 6.69 Examples/sec: 2676.69\n",
      "INFO:tensorflow:training step 33 | Loss: 6.58 Examples/sec: 2697.51\n",
      "INFO:tensorflow:training step 34 | Loss: 6.48 Examples/sec: 2717.89\n",
      "INFO:tensorflow:training step 35 | Loss: 6.40 Examples/sec: 2700.38\n",
      "INFO:tensorflow:training step 36 | Loss: 6.45 Examples/sec: 2773.50\n",
      "INFO:tensorflow:training step 37 | Loss: 6.32 Examples/sec: 2678.26\n",
      "INFO:tensorflow:training step 38 | Loss: 6.30 Examples/sec: 2683.45\n",
      "INFO:tensorflow:training step 39 | Loss: 6.19 Examples/sec: 2511.98\n",
      "INFO:tensorflow:training step 40 | Loss: 6.13 Examples/sec: 2614.68 | Hit@1: 0.59 PERR: 0.58 GAP: 0.44\n",
      "INFO:tensorflow:training step 41 | Loss: 6.06 Examples/sec: 2955.71\n",
      "INFO:tensorflow:training step 42 | Loss: 5.95 Examples/sec: 2695.07\n",
      "INFO:tensorflow:training step 43 | Loss: 5.92 Examples/sec: 2553.66\n",
      "INFO:tensorflow:training step 44 | Loss: 5.94 Examples/sec: 2721.63\n",
      "INFO:tensorflow:training step 45 | Loss: 5.87 Examples/sec: 2328.69\n",
      "INFO:tensorflow:training step 46 | Loss: 5.74 Examples/sec: 2668.44\n",
      "INFO:tensorflow:training step 47 | Loss: 5.62 Examples/sec: 2509.64\n",
      "INFO:tensorflow:training step 48 | Loss: 5.61 Examples/sec: 2725.72\n",
      "INFO:tensorflow:training step 49 | Loss: 5.55 Examples/sec: 2718.33\n",
      "INFO:tensorflow:training step 50 | Loss: 5.44 Examples/sec: 2662.75 | Hit@1: 0.65 PERR: 0.65 GAP: 0.52\n",
      "INFO:tensorflow:training step 51 | Loss: 5.49 Examples/sec: 2938.45\n",
      "INFO:tensorflow:training step 52 | Loss: 5.44 Examples/sec: 2720.12\n",
      "INFO:tensorflow:training step 53 | Loss: 5.42 Examples/sec: 2711.14\n",
      "INFO:tensorflow:training step 54 | Loss: 5.34 Examples/sec: 2709.13\n",
      "INFO:tensorflow:training step 55 | Loss: 5.29 Examples/sec: 2721.30\n",
      "INFO:tensorflow:training step 56 | Loss: 5.23 Examples/sec: 2742.12\n",
      "INFO:tensorflow:training step 57 | Loss: 5.18 Examples/sec: 2711.58\n",
      "INFO:tensorflow:training step 58 | Loss: 5.13 Examples/sec: 2294.44\n",
      "INFO:tensorflow:training step 59 | Loss: 5.01 Examples/sec: 2151.21\n",
      "INFO:tensorflow:training step 60 | Loss: 5.06 Examples/sec: 2224.32 | Hit@1: 0.64 PERR: 0.63 GAP: 0.52\n",
      "INFO:tensorflow:training step 61 | Loss: 5.04 Examples/sec: 2960.37\n",
      "INFO:tensorflow:training step 62 | Loss: 4.91 Examples/sec: 2620.33\n",
      "INFO:tensorflow:training step 63 | Loss: 4.81 Examples/sec: 1873.17\n",
      "INFO:tensorflow:training step 64 | Loss: 4.80 Examples/sec: 2170.44\n",
      "INFO:tensorflow:training step 65 | Loss: 4.79 Examples/sec: 2045.95\n",
      "INFO:tensorflow:training step 66 | Loss: 4.79 Examples/sec: 2369.33\n",
      "INFO:tensorflow:training step 67 | Loss: 4.76 Examples/sec: 2409.15\n",
      "INFO:tensorflow:training step 68 | Loss: 4.73 Examples/sec: 2397.48\n",
      "INFO:tensorflow:training step 69 | Loss: 4.69 Examples/sec: 2308.29\n",
      "INFO:tensorflow:training step 70 | Loss: 4.67 Examples/sec: 2107.10 | Hit@1: 0.64 PERR: 0.64 GAP: 0.55\n",
      "INFO:tensorflow:training step 71 | Loss: 4.60 Examples/sec: 2922.99\n",
      "INFO:tensorflow:training step 72 | Loss: 4.47 Examples/sec: 2179.64\n",
      "INFO:tensorflow:training step 73 | Loss: 4.50 Examples/sec: 2403.27\n",
      "INFO:tensorflow:training step 74 | Loss: 4.43 Examples/sec: 2428.30\n",
      "INFO:tensorflow:training step 75 | Loss: 4.43 Examples/sec: 2433.07\n",
      "INFO:tensorflow:training step 76 | Loss: 4.47 Examples/sec: 2399.93\n",
      "INFO:tensorflow:training step 77 | Loss: 4.46 Examples/sec: 2442.91\n",
      "INFO:tensorflow:training step 78 | Loss: 4.37 Examples/sec: 2460.87\n",
      "INFO:tensorflow:training step 79 | Loss: 4.30 Examples/sec: 2460.15\n",
      "INFO:tensorflow:training step 80 | Loss: 4.31 Examples/sec: 2461.39 | Hit@1: 0.68 PERR: 0.68 GAP: 0.61\n",
      "INFO:tensorflow:training step 81 | Loss: 4.28 Examples/sec: 2870.62\n",
      "INFO:tensorflow:training step 82 | Loss: 4.23 Examples/sec: 2348.71\n",
      "INFO:tensorflow:training step 83 | Loss: 4.20 Examples/sec: 2361.50\n",
      "INFO:tensorflow:training step 84 | Loss: 4.21 Examples/sec: 2445.88\n",
      "INFO:tensorflow:training step 85 | Loss: 4.11 Examples/sec: 2362.52\n",
      "INFO:tensorflow:training step 86 | Loss: 4.11 Examples/sec: 2353.53\n",
      "INFO:tensorflow:training step 87 | Loss: 4.03 Examples/sec: 2387.78\n",
      "INFO:tensorflow:training step 88 | Loss: 4.13 Examples/sec: 2444.11\n",
      "INFO:tensorflow:training step 89 | Loss: 4.06 Examples/sec: 2430.02\n",
      "INFO:tensorflow:training step 90 | Loss: 4.06 Examples/sec: 2381.76 | Hit@1: 0.69 PERR: 0.68 GAP: 0.61\n",
      "INFO:tensorflow:training step 91 | Loss: 3.99 Examples/sec: 2883.36\n",
      "INFO:tensorflow:training step 92 | Loss: 4.00 Examples/sec: 2406.81\n",
      "INFO:tensorflow:training step 93 | Loss: 3.89 Examples/sec: 2410.91\n",
      "INFO:tensorflow:training step 94 | Loss: 3.87 Examples/sec: 2395.28\n",
      "INFO:tensorflow:training step 95 | Loss: 3.85 Examples/sec: 2433.91\n",
      "INFO:tensorflow:training step 96 | Loss: 3.86 Examples/sec: 2384.72\n",
      "INFO:tensorflow:training step 97 | Loss: 3.81 Examples/sec: 2420.66\n",
      "INFO:tensorflow:training step 98 | Loss: 3.80 Examples/sec: 2419.28\n",
      "INFO:tensorflow:training step 99 | Loss: 3.76 Examples/sec: 2419.85\n",
      "INFO:tensorflow:training step 100 | Loss: 3.78 Examples/sec: 2405.08 | Hit@1: 0.68 PERR: 0.68 GAP: 0.63\n",
      "INFO:tensorflow:training step 101 | Loss: 3.78 Examples/sec: 2779.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:training step 102 | Loss: 3.77 Examples/sec: 2451.22\n",
      "INFO:tensorflow:training step 103 | Loss: 3.71 Examples/sec: 2426.30\n",
      "INFO:tensorflow:training step 104 | Loss: 3.71 Examples/sec: 2466.46\n",
      "INFO:tensorflow:training step 105 | Loss: 3.69 Examples/sec: 2431.46\n",
      "INFO:tensorflow:training step 106 | Loss: 3.69 Examples/sec: 2457.74\n",
      "INFO:tensorflow:training step 107 | Loss: 3.59 Examples/sec: 2439.00\n",
      "INFO:tensorflow:training step 108 | Loss: 3.60 Examples/sec: 2411.30\n",
      "INFO:tensorflow:training step 109 | Loss: 3.58 Examples/sec: 2469.72\n",
      "INFO:tensorflow:training step 110 | Loss: 3.56 Examples/sec: 2433.71 | Hit@1: 0.69 PERR: 0.69 GAP: 0.65\n",
      "INFO:tensorflow:models/models_jungle\\model.ckpt-110 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:/job:master/task:0: Exporting the model at step 110 to models/models_jungle/export/step_110.\n",
      "INFO:tensorflow:Restoring parameters from models/models_jungle\\model.ckpt-110\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'models/models_jungle/export/step_110\\\\saved_model.pb'\n",
      "INFO:tensorflow:training step 111 | Loss: 3.55 Examples/sec: 4092.72\n",
      "INFO:tensorflow:training step 112 | Loss: 3.54 Examples/sec: 2417.57\n",
      "INFO:tensorflow:training step 113 | Loss: 3.51 Examples/sec: 2437.25\n",
      "INFO:tensorflow:training step 114 | Loss: 3.46 Examples/sec: 2421.35\n",
      "INFO:tensorflow:training step 115 | Loss: 3.55 Examples/sec: 2451.63\n",
      "INFO:tensorflow:training step 116 | Loss: 3.47 Examples/sec: 2429.70\n",
      "INFO:tensorflow:training step 117 | Loss: 3.48 Examples/sec: 2438.60\n",
      "INFO:tensorflow:training step 118 | Loss: 3.42 Examples/sec: 2437.15\n",
      "INFO:tensorflow:training step 119 | Loss: 3.40 Examples/sec: 2426.18\n",
      "INFO:tensorflow:training step 120 | Loss: 3.41 Examples/sec: 2443.88 | Hit@1: 0.70 PERR: 0.70 GAP: 0.68\n",
      "INFO:tensorflow:training step 121 | Loss: 3.41 Examples/sec: 2739.59\n",
      "INFO:tensorflow:training step 122 | Loss: 3.39 Examples/sec: 2416.42\n",
      "INFO:tensorflow:training step 123 | Loss: 3.35 Examples/sec: 2414.51\n",
      "INFO:tensorflow:training step 124 | Loss: 3.35 Examples/sec: 2432.37\n",
      "INFO:tensorflow:training step 125 | Loss: 3.30 Examples/sec: 2158.96\n",
      "INFO:tensorflow:training step 126 | Loss: 3.26 Examples/sec: 2420.25\n",
      "INFO:tensorflow:training step 127 | Loss: 3.26 Examples/sec: 2315.43\n",
      "INFO:tensorflow:training step 128 | Loss: 3.20 Examples/sec: 2345.30\n",
      "INFO:tensorflow:training step 129 | Loss: 3.17 Examples/sec: 2351.28\n",
      "INFO:tensorflow:training step 130 | Loss: 3.25 Examples/sec: 2362.56 | Hit@1: 0.71 PERR: 0.71 GAP: 0.68\n",
      "INFO:tensorflow:training step 131 | Loss: 3.23 Examples/sec: 2635.34\n",
      "INFO:tensorflow:training step 132 | Loss: 3.24 Examples/sec: 2381.75\n",
      "INFO:tensorflow:training step 133 | Loss: 3.18 Examples/sec: 2403.25\n",
      "INFO:tensorflow:training step 134 | Loss: 3.21 Examples/sec: 2397.55\n",
      "INFO:tensorflow:training step 135 | Loss: 3.18 Examples/sec: 2407.61\n",
      "INFO:tensorflow:training step 136 | Loss: 3.18 Examples/sec: 2416.19\n",
      "INFO:tensorflow:global_step/sec: 1.1356\n",
      "INFO:tensorflow:training step 137 | Loss: 3.13 Examples/sec: 2363.61\n",
      "INFO:tensorflow:training step 138 | Loss: 3.12 Examples/sec: 1182.36\n",
      "INFO:tensorflow:training step 139 | Loss: 3.13 Examples/sec: 2277.01\n",
      "INFO:tensorflow:training step 140 | Loss: 3.07 Examples/sec: 2222.34 | Hit@1: 0.70 PERR: 0.70 GAP: 0.70\n",
      "INFO:tensorflow:Recording summary at step 140.\n",
      "INFO:tensorflow:training step 141 | Loss: 3.05 Examples/sec: 2534.10\n",
      "INFO:tensorflow:training step 142 | Loss: 3.10 Examples/sec: 2287.29\n",
      "INFO:tensorflow:training step 143 | Loss: 3.14 Examples/sec: 2289.70\n",
      "INFO:tensorflow:training step 144 | Loss: 3.01 Examples/sec: 2392.83\n",
      "INFO:tensorflow:training step 145 | Loss: 3.07 Examples/sec: 2412.49\n",
      "INFO:tensorflow:training step 146 | Loss: 3.02 Examples/sec: 2272.41\n",
      "INFO:tensorflow:training step 147 | Loss: 2.97 Examples/sec: 2333.28\n",
      "INFO:tensorflow:training step 148 | Loss: 3.03 Examples/sec: 2210.94\n",
      "INFO:tensorflow:training step 149 | Loss: 3.02 Examples/sec: 2286.12\n",
      "INFO:tensorflow:training step 150 | Loss: 3.00 Examples/sec: 2265.95 | Hit@1: 0.71 PERR: 0.71 GAP: 0.71\n",
      "INFO:tensorflow:training step 151 | Loss: 2.97 Examples/sec: 2380.75\n",
      "INFO:tensorflow:training step 152 | Loss: 2.97 Examples/sec: 2059.62\n",
      "INFO:tensorflow:training step 153 | Loss: 2.95 Examples/sec: 2217.64\n",
      "INFO:tensorflow:training step 154 | Loss: 2.92 Examples/sec: 2026.62\n",
      "INFO:tensorflow:training step 155 | Loss: 2.93 Examples/sec: 2090.38\n",
      "INFO:tensorflow:training step 156 | Loss: 2.94 Examples/sec: 2318.16\n",
      "INFO:tensorflow:training step 157 | Loss: 2.90 Examples/sec: 2230.49\n",
      "INFO:tensorflow:training step 158 | Loss: 2.99 Examples/sec: 2009.22\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"%s: Starting managed session.\", task_as_string(task))\n",
    "\n",
    "with sv.managed_session(target, config=config) as sess:\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"%s: Entering training loop.\", task_as_string(task))\n",
    "        while (not sv.should_stop()) and (not max_steps_reached):\n",
    "            batch_start_time = time.time()\n",
    "            \n",
    "            _, global_step_val, loss_val, predictions_val, labels_val = sess.run(\n",
    "                [train_op, global_step, loss, predictions, labels])\n",
    "            \n",
    "            seconds_per_batch = time.time() - batch_start_time\n",
    "            examples_per_second = labels_val.shape[0] / seconds_per_batch\n",
    "            \n",
    "            if FLAGS.max_steps and FLAGS.max_steps <= global_step_val:\n",
    "                max_steps_reached = True\n",
    "\n",
    "            if is_master and global_step_val % 10 == 0 and train_dir:\n",
    "                eval_start_time = time.time()\n",
    "                hit_at_one = eval_util.calculate_hit_at_one(predictions_val, labels_val)\n",
    "                perr = eval_util.calculate_precision_at_equal_recall_rate(predictions_val,\n",
    "                                                                  labels_val)\n",
    "                gap = eval_util.calculate_gap(predictions_val, labels_val)\n",
    "                eval_end_time = time.time()\n",
    "                eval_time = eval_end_time - eval_start_time\n",
    "\n",
    "                logging.info(\"training step \" + str(global_step_val) + \" | Loss: \" + (\"%.2f\" % loss_val) +\n",
    "                             \" Examples/sec: \" + (\"%.2f\" % examples_per_second) + \" | Hit@1: \" +\n",
    "                            (\"%.2f\" % hit_at_one) + \" PERR: \" + (\"%.2f\" % perr) +\n",
    "                             \" GAP: \" + (\"%.2f\" % gap))\n",
    "\n",
    "                sv.summary_writer.add_summary(\n",
    "                    utils.MakeSummary(\"model/Training_Hit@1\", hit_at_one),\n",
    "                    global_step_val)\n",
    "                sv.summary_writer.add_summary(\n",
    "                    utils.MakeSummary(\"model/Training_Perr\", perr), global_step_val)\n",
    "                sv.summary_writer.add_summary(\n",
    "                    utils.MakeSummary(\"model/Training_GAP\", gap), global_step_val)\n",
    "                sv.summary_writer.add_summary(\n",
    "                    utils.MakeSummary(\"global_step/Examples/Second\",\n",
    "                                      examples_per_second), global_step_val)\n",
    "                sv.summary_writer.flush()\n",
    "\n",
    "                # Exporting the model every x steps\n",
    "                time_to_export = ((last_model_export_step == 0) or\n",
    "                    (global_step_val - last_model_export_step\n",
    "                     >= FLAGS.export_model_steps))\n",
    "\n",
    "                if is_master and time_to_export:\n",
    "                    export_model(global_step_val, sv.saver, sv.save_path, sess)\n",
    "                    last_model_export_step = global_step_val\n",
    "            else:\n",
    "                logging.info(\"training step \" + str(global_step_val) + \" | Loss: \" +\n",
    "                            (\"%.2f\" % loss_val) + \" Examples/sec: \" + (\"%.2f\" % examples_per_second))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        logging.info(\"%s: Done training -- epoch limit reached\")\n",
    "\n",
    "logging.info(\"%s: Exited training loop.\", task_as_string(task))\n",
    "sv.Stop()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \" + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
