{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import frame_level_models\n",
    "import video_level_models\n",
    "import readers\n",
    "import utils\n",
    "import export_model\n",
    "import trainer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import logging\n",
    "from tensorflow import flags\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Maak alle flags aan\n",
    "\n",
    "# Dataset flags\n",
    "flags.DEFINE_string(\"train_dir\", \"models/youtube_model.ckpt\",\n",
    "                  \"The directory to save the model files in.\")\n",
    "flags.DEFINE_string(\n",
    "  \"train_data_pattern\", \"models/youtube_model.ckpt\",\n",
    "  \"File glob for the training dataset. If the files refer to Frame Level \"\n",
    "  \"features (i.e. tensorflow.SequenceExample), then set --reader_type \"\n",
    "  \"format. The (Sequence)Examples are expected to have 'rgb' byte array \"\n",
    "  \"sequence feature as well as a 'labels' int64 context feature.\")\n",
    "flags.DEFINE_string(\"feature_names\", \"mean_audio\", \"Name of the feature \"\n",
    "                  \"to use for training.\")\n",
    "flags.DEFINE_string(\"feature_sizes\", \"128\", \"Length of the feature vectors.\")\n",
    "flags.DEFINE_integer(\"num_classes\", 8192, \"Number of classes in dataset.\")\n",
    "\n",
    "# Model flags.\n",
    "flags.DEFINE_bool(\n",
    "  \"frame_features\", True,\n",
    "  \"If set, then --train_data_pattern must be frame-level features. \"\n",
    "  \"Otherwise, --train_data_pattern must be aggregated video-level \"\n",
    "  \"features. The model must also be set appropriately (i.e. to read 3D \"\n",
    "  \"batches VS 4D batches.\")\n",
    "flags.DEFINE_string(\n",
    "  \"model\", \"LogisticModel\",\n",
    "  \"Which architecture to use for the model. Models are defined \"\n",
    "  \"in models.py.\")\n",
    "flags.DEFINE_bool(\n",
    "  \"start_new_model\", True,\n",
    "  \"If set, this will not resume from a checkpoint and will instead create a\"\n",
    "  \" new model instance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training flags\n",
    "flags.DEFINE_integer(\"batch_size\", 1024,\n",
    "                   \"How many examples to process per batch for training.\")\n",
    "flags.DEFINE_string(\"label_loss\", \"CrossEntropyLoss\",\n",
    "                  \"Which loss function to use for training the model.\")\n",
    "flags.DEFINE_float(\n",
    "  \"regularization_penalty\", 1.0,\n",
    "  \"How much weight to give to the regularization loss (the label loss has \"\n",
    "  \"a weight of 1).\")\n",
    "flags.DEFINE_float(\"base_learning_rate\", 0.01,\n",
    "                 \"Which learning rate to start with.\")\n",
    "flags.DEFINE_float(\"learning_rate_decay\", 0.95,\n",
    "                 \"Learning rate decay factor to be applied every \"\n",
    "                 \"learning_rate_decay_examples.\")\n",
    "flags.DEFINE_float(\"learning_rate_decay_examples\", 4000000,\n",
    "                 \"Multiply current learning rate by learning_rate_decay \"\n",
    "                 \"every learning_rate_decay_examples.\")\n",
    "flags.DEFINE_integer(\"num_epochs\", 5,\n",
    "                   \"How many passes to make over the dataset before \"\n",
    "                   \"halting training.\")\n",
    "flags.DEFINE_integer(\"max_steps\", 10,\n",
    "                   \"The maximum number of iterations of the training loop.\")\n",
    "flags.DEFINE_integer(\"export_model_steps\", 1000,\n",
    "                   \"The period, in number of steps, with which the model \"\n",
    "                   \"is exported for batch prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Other flags\n",
    "flags.DEFINE_integer(\"num_readers\", 8,\n",
    "                   \"How many threads to use for reading input files.\")\n",
    "flags.DEFINE_string(\"optimizer\", \"AdamOptimizer\",\n",
    "                  \"What optimizer class to use.\")\n",
    "flags.DEFINE_float(\"clip_gradient_norm\", 1.0, \"Norm to clip gradients to.\")\n",
    "flags.DEFINE_bool(\n",
    "  \"log_device_placement\", False,\n",
    "  \"Whether to write the device on which every op will run into the \"\n",
    "  \"logs on startup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Functies die straks wordt aangeroepen\n",
    "\n",
    "def find_class_by_name(name, modules):\n",
    "  \"\"\"Searches the provided modules for the named class and returns it.\"\"\"\n",
    "  modules = [getattr(module, name, None) for module in modules]\n",
    "  return next(a for a in modules if a)\n",
    "\n",
    "def task_as_string(task):\n",
    "  return \"/job:%s/task:%s\" % (task.type, task.index)\n",
    "\n",
    "def get_reader():\n",
    "  # Convert feature_names and feature_sizes to lists of values.\n",
    "  feature_names, feature_sizes = utils.GetListOfFeatureNamesAndSizes(\n",
    "      FLAGS.feature_names, FLAGS.feature_sizes)\n",
    "  num_classes = FLAGS.num_classes\n",
    "\n",
    "  if FLAGS.frame_features:\n",
    "    reader = readers.YT8MFrameFeatureReader(\n",
    "        num_classes=num_classes,\n",
    "        feature_names=feature_names, feature_sizes=feature_sizes)\n",
    "  else:\n",
    "    reader = readers.YT8MAggregatedFeatureReader(\n",
    "        num_classes=num_classes,\n",
    "        feature_names=feature_names, feature_sizes=feature_sizes)\n",
    "\n",
    "  return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/job:master/task:0: Tensorflow version: 1.3.0.\n"
     ]
    }
   ],
   "source": [
    "## Onderstaande regels komen vanuit 'main'-functie onderaan\n",
    "\n",
    "# Load the environment.\n",
    "env = json.loads(os.environ.get(\"TF_CONFIG\", \"{}\"))\n",
    "\n",
    "# Load the cluster data from the environment.\n",
    "cluster_data = env.get(\"cluster\", None)\n",
    "cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None\n",
    "\n",
    "# Load the task data from the environment.\n",
    "task_data = env.get(\"task\", None) or {\"type\": \"master\", \"index\": 0}\n",
    "task = type(\"TaskSpec\", (object,), task_data)\n",
    "\n",
    "# Logging the version.\n",
    "logging.set_verbosity(tf.logging.INFO)\n",
    "logging.info(\"%s: Tensorflow version: %s.\",\n",
    "           task_as_string(task), tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispatch to a master, a worker, or a parameter server.\n",
    "if not cluster or task.type == \"master\" or task.type == \"worker\":\n",
    "    model = find_class_by_name(FLAGS.model,\n",
    "                               [frame_level_models, video_level_models])()\n",
    "\n",
    "    reader = get_reader()\n",
    "\n",
    "    model_exporter = export_model.ModelExporter(\n",
    "        frame_features=FLAGS.frame_features,\n",
    "        model=model,\n",
    "        reader=reader)\n",
    "\n",
    "#    trainer = trainer.Trainer(cluster, task, FLAGS.train_dir, model, reader, model_exporter,\n",
    "#            FLAGS.log_device_placement, FLAGS.max_steps,\n",
    "#            FLAGS.export_model_steps).run(start_new_model=FLAGS.start_new_model)\n",
    "\n",
    "#elif task.type == \"ps\":\n",
    "#ParameterServer(cluster, task).run()\n",
    "#else:\n",
    "#raise ValueError(\"%s: Invalid task_type: %s.\" %\n",
    "#                 (task_as_string(task), task.type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
