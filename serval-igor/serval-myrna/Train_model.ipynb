{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import get_youtube8m_features as yt_features\n",
    "import frame_level_models\n",
    "import video_level_models\n",
    "import readers\n",
    "import utils\n",
    "import eval_util\n",
    "import export_model\n",
    "import losses\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow import app\n",
    "from tensorflow import gfile\n",
    "from tensorflow import logging\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Maak alle flags aan\n",
    "\n",
    "# Dataset flags\n",
    "flags.DEFINE_string(\"train_dir\", \"models\",\n",
    "                  \"The directory to save the model files in.\")\n",
    "flags.DEFINE_string(\n",
    "  \"train_data_pattern\", \"train_data/*.tfrecord\",\n",
    "  \"File glob for the training dataset. If the files refer to Frame Level \"\n",
    "  \"features (i.e. tensorflow.SequenceExample), then set --reader_type \"\n",
    "  \"format. The (Sequence)Examples are expected to have 'rgb' byte array \"\n",
    "  \"sequence feature as well as a 'labels' int64 context feature.\")\n",
    "flags.DEFINE_string(\"feature_names\", \"mean_rgb\", \"Name of the feature \"\n",
    "                  \"to use for training.\")\n",
    "flags.DEFINE_string(\"feature_sizes\", \"1024\", \"Length of the feature vectors.\")\n",
    "flags.DEFINE_integer(\"num_classes\", 37, \"Number of classes in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model flags\n",
    "flags.DEFINE_bool(\n",
    "  \"frame_features\", False,\n",
    "  \"If set, then --train_data_pattern must be frame-level features. \"\n",
    "  \"Otherwise, --train_data_pattern must be aggregated video-level \"\n",
    "  \"features. The model must also be set appropriately (i.e. to read 3D \"\n",
    "  \"batches VS 4D batches.\")\n",
    "flags.DEFINE_string(\n",
    "  \"model\", \"LogisticModel\",\n",
    "  \"Which architecture to use for the model. Models are defined \"\n",
    "  \"in models.py.\")\n",
    "flags.DEFINE_bool(\n",
    "  \"start_new_model\", True,\n",
    "  \"If set, this will not resume from a checkpoint and will instead create a\"\n",
    "  \" new model instance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training flags\n",
    "flags.DEFINE_integer(\"batch_size\", 1024,\n",
    "                   \"How many examples to process per batch for training.\")\n",
    "flags.DEFINE_string(\"label_loss\", \"CrossEntropyLoss\",\n",
    "                  \"Which loss function to use for training the model.\")\n",
    "flags.DEFINE_float(\"regularization_penalty\", 1.0,\n",
    "                  \"How much weight to give to the regularization loss (the label loss has \"\n",
    "                  \"a weight of 1).\")\n",
    "flags.DEFINE_float(\"base_learning_rate\", 0.01,\n",
    "                 \"Which learning rate to start with.\")\n",
    "flags.DEFINE_float(\"learning_rate_decay\", 0.95,\n",
    "                 \"Learning rate decay factor to be applied every \"\n",
    "                 \"learning_rate_decay_examples.\")\n",
    "flags.DEFINE_float(\"learning_rate_decay_examples\", 4000000,\n",
    "                 \"Multiply current learning rate by learning_rate_decay \"\n",
    "                 \"every learning_rate_decay_examples.\")\n",
    "flags.DEFINE_integer(\"num_epochs\", 10,\n",
    "                   \"How many passes to make over the dataset before \"\n",
    "                   \"halting training.\")\n",
    "flags.DEFINE_integer(\"max_steps\", None,\n",
    "                   \"The maximum number of iterations of the training loop.\")\n",
    "flags.DEFINE_integer(\"export_model_steps\", 1000,\n",
    "                   \"The period, in number of steps, with which the model \"\n",
    "                   \"is exported for batch prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Other flags\n",
    "flags.DEFINE_integer(\"num_readers\", 8,\n",
    "                   \"How many threads to use for reading input files.\")\n",
    "flags.DEFINE_string(\"optimizer\", \"AdamOptimizer\",\n",
    "                  \"What optimizer class to use.\")\n",
    "flags.DEFINE_float(\"clip_gradient_norm\", 1.0, \"Norm to clip gradients to.\")\n",
    "flags.DEFINE_bool(\n",
    "  \"log_device_placement\", False,\n",
    "  \"Whether to write the device on which every op will run into the \"\n",
    "  \"logs on startup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Go to train data folder \n",
    "if os.getcwd().split('\\\\')[-1]!='train_data':\n",
    "    os.chdir(\"./train_data\")\n",
    "\n",
    "## Download 1/1000th of the data (if not downloaded yet)\n",
    "# yt_features.dwnld('2/video/train', 'eu', '1,100')\n",
    "#yt_features.dwnld('1/video_level/train', 'us', '1,100')\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment.\n",
    "env = json.loads(os.environ.get(\"TF_CONFIG\", \"{}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cluster data from the environment.\n",
    "cluster_data = env.get(\"cluster\", None)\n",
    "cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the task data from the environment.\n",
    "task_data = env.get(\"task\", None) or {\"type\": \"master\", \"index\": 0}\n",
    "task = type(\"TaskSpec\", (object,), task_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/job:master/task:0: Tensorflow version: 1.8.0.\n"
     ]
    }
   ],
   "source": [
    "def task_as_string(task):\n",
    "  return \"/job:%s/task:%s\" % (task.type, task.index)\n",
    "\n",
    "# Logging the version.\n",
    "logging.set_verbosity(tf.logging.INFO)\n",
    "logging.info(\"%s: Tensorflow version: %s.\",\n",
    "           task_as_string(task), tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functie die elke keer wordt aangeroepen\n",
    "def find_class_by_name(name, modules):\n",
    "  \"\"\"Searches the provided modules for the named class and returns it.\"\"\"\n",
    "  modules = [getattr(module, name, None) for module in modules]\n",
    "  return next(a for a in modules if a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define model\n",
    "model = find_class_by_name(FLAGS.model,\n",
    "    [frame_level_models, video_level_models])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert feature_names and feature_sizes to lists of values.\n",
    "feature_names, feature_sizes = utils.GetListOfFeatureNamesAndSizes(\n",
    "    FLAGS.feature_names, FLAGS.feature_sizes)\n",
    "num_classes = FLAGS.num_classes\n",
    "\n",
    "# Create reader\n",
    "if FLAGS.frame_features:\n",
    "    reader = readers.YT8MFrameFeatureReader(\n",
    "        num_classes=num_classes,\n",
    "        feature_names=feature_names, feature_sizes=feature_sizes)\n",
    "else:\n",
    "    reader = readers.YT8MAggregatedFeatureReader(\n",
    "        num_classes=num_classes,\n",
    "        feature_names=feature_names, feature_sizes=feature_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exporter = export_model.ModelExporter(\n",
    "    frame_features=FLAGS.frame_features,\n",
    "    model=model,\n",
    "    reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_master = (task.type == \"master\" and task.index == 0)\n",
    "config = tf.ConfigProto(\n",
    "    allow_soft_placement=True,log_device_placement=FLAGS.log_device_placement)\n",
    "max_steps_reached = False\n",
    "last_model_export_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/job:master/task:0: Removing existing train directory.\n",
      "ERROR:tensorflow:/job:master/task:0: Failed to delete directory models when starting a new model. Please delete it manually and try again.\n"
     ]
    }
   ],
   "source": [
    "# Remove old model, if starting new model\n",
    "if is_master and FLAGS.start_new_model:\n",
    "    try:\n",
    "      logging.info(\n",
    "          \"%s: Removing existing train directory.\",\n",
    "          task_as_string(task))\n",
    "      gfile.DeleteRecursively(FLAGS.train_dir)\n",
    "    except:\n",
    "      logging.error(\n",
    "          \"%s: Failed to delete directory \" + FLAGS.train_dir +\n",
    "          \" when starting a new model. Please delete it manually and\" +\n",
    "          \" try again.\", task_as_string(task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Starts a server if the execution is distributed.\"\"\"\n",
    "if cluster:\n",
    "    logging.info(\"%s: Starting trainer within cluster %s.\",\n",
    "               task_as_string(task), cluster.as_dict())\n",
    "    server = start_server(cluster, task)\n",
    "    target = server.target\n",
    "    device_fn = tf.train.replica_device_setter(\n",
    "        ps_device=\"/job:ps\",\n",
    "        worker_device=\"/job:%s/task:%d\" % (task.type, task.index),\n",
    "        cluster=cluster)\n",
    "else:\n",
    "    target = \"\"\n",
    "    device_fn = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/job:master/task:0: Flag 'start_new_model' is set. Building a new model.\n"
     ]
    }
   ],
   "source": [
    "def get_meta_filename(start_new_model, train_dir, task):\n",
    "    if start_new_model:\n",
    "      logging.info(\"%s: Flag 'start_new_model' is set. Building a new model.\",\n",
    "                   task_as_string(task))\n",
    "      return None\n",
    "\n",
    "    latest_checkpoint = tf.train.latest_checkpoint(train_dir)\n",
    "    if not latest_checkpoint:\n",
    "      logging.info(\"%s: No checkpoint file found. Building a new model.\",\n",
    "                   task_as_string(task))\n",
    "      return None\n",
    "\n",
    "    meta_filename = latest_checkpoint + \".meta\"\n",
    "    if not gfile.Exists(meta_filename):\n",
    "      logging.info(\"%s: No meta graph file found. Building a new model.\",\n",
    "                     task_as_string(task))\n",
    "      return None\n",
    "    else:\n",
    "      return meta_filename\n",
    "\n",
    "meta_filename = get_meta_filename(FLAGS.start_new_model, FLAGS.train_dir, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functie die wordt aangeroepen door build_graph\n",
    "\n",
    "def get_input_data_tensors(reader,\n",
    "                           data_pattern,\n",
    "                           batch_size=1000,\n",
    "                           num_epochs=None,\n",
    "                           num_readers=1):\n",
    "  \"\"\"Creates the section of the graph which reads the training data.\n",
    "\n",
    "  Args:\n",
    "    reader: A class which parses the training data.\n",
    "    data_pattern: A 'glob' style path to the data files.\n",
    "    batch_size: How many examples to process at a time.\n",
    "    num_epochs: How many passes to make over the training data. Set to 'None'\n",
    "                to run indefinitely.\n",
    "    num_readers: How many I/O threads to use.\n",
    "\n",
    "  Returns:\n",
    "    A tuple containing the features tensor, labels tensor, and optionally a\n",
    "    tensor containing the number of frames per video. The exact dimensions\n",
    "    depend on the reader being used.\n",
    "\n",
    "  Raises:\n",
    "    IOError: If no files matching the given pattern were found.\n",
    "  \"\"\"\n",
    "  logging.info(\"Using batch size of \" + str(batch_size) + \" for training.\")\n",
    "  with tf.name_scope(\"train_input\"):\n",
    "    files = gfile.Glob(data_pattern)\n",
    "    if not files:\n",
    "      raise IOError(\"Unable to find training files. data_pattern='\" +\n",
    "                    data_pattern + \"'.\")\n",
    "    logging.info(\"Number of training files: %s.\", str(len(files)))\n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "        files, num_epochs=num_epochs, shuffle=True)\n",
    "    training_data = [\n",
    "        reader.prepare_reader(filename_queue) for _ in range(num_readers)\n",
    "    ]\n",
    "\n",
    "    print(training_data)\n",
    "    \n",
    "    ## Create batches by randomly shuffling tensors\n",
    "    return tf.train.shuffle_batch_join(\n",
    "        training_data,\n",
    "        batch_size=batch_size,\n",
    "        capacity=batch_size * 5,\n",
    "        min_after_dequeue=batch_size,\n",
    "        allow_smaller_final_batch=True,\n",
    "        enqueue_many=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deze functie wordt aangeroepen om de Tensorflow-graph te bouwen\n",
    "\n",
    "def build_graph(reader,\n",
    "                model,\n",
    "                train_data_pattern,\n",
    "                label_loss_fn=losses.CrossEntropyLoss(),\n",
    "                batch_size=1000,\n",
    "                base_learning_rate=0.01,\n",
    "                learning_rate_decay_examples=1000000,\n",
    "                learning_rate_decay=0.95,\n",
    "                optimizer_class=tf.train.AdamOptimizer,\n",
    "                clip_gradient_norm=1.0,\n",
    "                regularization_penalty=1,\n",
    "                num_readers=1,\n",
    "                num_epochs=None):\n",
    "  \"\"\"Creates the Tensorflow graph.\n",
    "\n",
    "  This will only be called once in the life of\n",
    "  a training model, because after the graph is created the model will be\n",
    "  restored from a meta graph file rather than being recreated.\n",
    "\n",
    "  Args:\n",
    "    reader: The data file reader. It should inherit from BaseReader.\n",
    "    model: The core model (e.g. logistic or neural net). It should inherit\n",
    "           from BaseModel.\n",
    "    train_data_pattern: glob path to the training data files.\n",
    "    label_loss_fn: What kind of loss to apply to the model. It should inherit\n",
    "                from BaseLoss.\n",
    "    batch_size: How many examples to process at a time.\n",
    "    base_learning_rate: What learning rate to initialize the optimizer with.\n",
    "    optimizer_class: Which optimization algorithm to use.\n",
    "    clip_gradient_norm: Magnitude of the gradient to clip to.\n",
    "    regularization_penalty: How much weight to give the regularization loss\n",
    "                            compared to the label loss.\n",
    "    num_readers: How many threads to use for I/O operations.\n",
    "    num_epochs: How many passes to make over the data. 'None' means an\n",
    "                unlimited number of passes.\n",
    "  \"\"\"\n",
    "\n",
    "  global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "  print(global_step)\n",
    "  local_device_protos = device_lib.list_local_devices()\n",
    "  gpus = [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "  num_gpus = len(gpus)\n",
    "  logging.info(\"Number of GPUs: %s.\", str(num_gpus))\n",
    "\n",
    "  if num_gpus > 0:\n",
    "    logging.info(\"Using the following GPUs to train: \" + str(gpus))\n",
    "    num_towers = num_gpus\n",
    "    device_string = '/gpu:%d'\n",
    "  else:\n",
    "    logging.info(\"No GPUs found. Training on CPU.\")\n",
    "    num_towers = 1\n",
    "    device_string = '/cpu:%d'\n",
    "\n",
    "  learning_rate = tf.train.exponential_decay(\n",
    "      base_learning_rate,\n",
    "      global_step * batch_size * num_towers,\n",
    "      learning_rate_decay_examples,\n",
    "      learning_rate_decay,\n",
    "      staircase=True)\n",
    "  tf.summary.scalar('learning_rate', learning_rate)\n",
    "\n",
    "  optimizer = optimizer_class(learning_rate)\n",
    "\n",
    "  ## Read input files\n",
    "  unused_video_id, model_input_raw, labels_batch, num_frames = (\n",
    "      get_input_data_tensors(\n",
    "          reader,\n",
    "          train_data_pattern,\n",
    "          batch_size=batch_size * num_towers,\n",
    "          num_readers=num_readers,\n",
    "          num_epochs=num_epochs))\n",
    "  tf.summary.histogram(\"model/input_raw\", model_input_raw)\n",
    " \n",
    "  feature_dim = len(model_input_raw.get_shape()) - 1\n",
    "\n",
    "  model_input = tf.nn.l2_normalize(model_input_raw, feature_dim)\n",
    "\n",
    "  tower_inputs = tf.split(model_input, num_towers)\n",
    "  tower_labels = tf.split(labels_batch, num_towers)\n",
    "  tower_num_frames = tf.split(num_frames, num_towers)\n",
    "  tower_gradients = []\n",
    "  tower_predictions = []\n",
    "  tower_label_losses = []\n",
    "  tower_reg_losses = []\n",
    "  for i in range(num_towers):\n",
    "    # For some reason these 'with' statements can't be combined onto the same\n",
    "    # line. They have to be nested.\n",
    "    with tf.device(device_string % i):\n",
    "      with (tf.variable_scope((\"tower\"), reuse=True if i > 0 else None)):\n",
    "        with (slim.arg_scope([slim.model_variable, slim.variable], device=\"/cpu:0\" if num_gpus!=1 else \"/gpu:0\")):\n",
    "          result = model.create_model(\n",
    "            tower_inputs[i],\n",
    "            num_frames=tower_num_frames[i],\n",
    "            vocab_size=reader.num_classes,\n",
    "            labels=tower_labels[i])\n",
    "          #print(tower_labels[i])\n",
    "          for variable in slim.get_model_variables():\n",
    "            tf.summary.histogram(variable.op.name, variable)\n",
    "\n",
    "          predictions = result[\"predictions\"]\n",
    "          tower_predictions.append(predictions)\n",
    "\n",
    "          if \"loss\" in result.keys():\n",
    "            label_loss = result[\"loss\"]\n",
    "          else:\n",
    "            label_loss = label_loss_fn.calculate_loss(predictions, tower_labels[i])\n",
    "\n",
    "          if \"regularization_loss\" in result.keys():\n",
    "            reg_loss = result[\"regularization_loss\"]\n",
    "          else:\n",
    "            reg_loss = tf.constant(0.0)\n",
    "\n",
    "          reg_losses = tf.losses.get_regularization_losses()\n",
    "          if reg_losses:\n",
    "            reg_loss += tf.add_n(reg_losses)\n",
    "\n",
    "          tower_reg_losses.append(reg_loss)\n",
    "\n",
    "          # Adds update_ops (e.g., moving average updates in batch normalization) as\n",
    "          # a dependency to the train_op.\n",
    "          update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "          if \"update_ops\" in result.keys():\n",
    "            update_ops += result[\"update_ops\"]\n",
    "          if update_ops:\n",
    "            with tf.control_dependencies(update_ops):\n",
    "              barrier = tf.no_op(name=\"gradient_barrier\")\n",
    "              with tf.control_dependencies([barrier]):\n",
    "                label_loss = tf.identity(label_loss)\n",
    "\n",
    "          tower_label_losses.append(label_loss)\n",
    "\n",
    "          # Incorporate the L2 weight penalties etc.\n",
    "          final_loss = regularization_penalty * reg_loss + label_loss\n",
    "          gradients = optimizer.compute_gradients(final_loss,\n",
    "              colocate_gradients_with_ops=False)\n",
    "          tower_gradients.append(gradients)\n",
    "  label_loss = tf.reduce_mean(tf.stack(tower_label_losses))\n",
    "  tf.summary.scalar(\"label_loss\", label_loss)\n",
    "  if regularization_penalty != 0:\n",
    "    reg_loss = tf.reduce_mean(tf.stack(tower_reg_losses))\n",
    "    tf.summary.scalar(\"reg_loss\", reg_loss)\n",
    "  merged_gradients = utils.combine_gradients(tower_gradients)\n",
    "\n",
    "  if clip_gradient_norm > 0:\n",
    "    with tf.name_scope('clip_grads'):\n",
    "      merged_gradients = utils.clip_gradient_norms(merged_gradients, clip_gradient_norm)\n",
    "\n",
    "  train_op = optimizer.apply_gradients(merged_gradients, global_step=global_step)\n",
    "\n",
    "  tf.add_to_collection(\"global_step\", global_step)\n",
    "  tf.add_to_collection(\"loss\", label_loss)\n",
    "  tf.add_to_collection(\"predictions\", tf.concat(tower_predictions, 0))\n",
    "  tf.add_to_collection(\"input_batch_raw\", model_input_raw)\n",
    "  tf.add_to_collection(\"input_batch\", model_input)\n",
    "  tf.add_to_collection(\"num_frames\", num_frames)\n",
    "  tf.add_to_collection(\"labels\", tf.cast(labels_batch, tf.float32))\n",
    "  tf.add_to_collection(\"train_op\", train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "INFO:tensorflow:Number of GPUs: 1.\n",
      "INFO:tensorflow:Using the following GPUs to train: ['/device:GPU:0']\n",
      "INFO:tensorflow:Using batch size of 1024 for training.\n",
      "INFO:tensorflow:Number of training files: 41.\n",
      "[(<tf.Tensor 'train_input/ParseExample/ParseExample:4' shape=(?,) dtype=string>, <tf.Tensor 'train_input/concat:0' shape=(?, 1024) dtype=float32>, <tf.Tensor 'train_input/SparseToIndicator:0' shape=(?, 4716) dtype=bool>, <tf.Tensor 'train_input/ones:0' shape=(?,) dtype=float32>), (<tf.Tensor 'train_input/ParseExample_1/ParseExample:4' shape=(?,) dtype=string>, <tf.Tensor 'train_input/concat_1:0' shape=(?, 1024) dtype=float32>, <tf.Tensor 'train_input/SparseToIndicator_1:0' shape=(?, 4716) dtype=bool>, <tf.Tensor 'train_input/ones_1:0' shape=(?,) dtype=float32>), (<tf.Tensor 'train_input/ParseExample_2/ParseExample:4' shape=(?,) dtype=string>, <tf.Tensor 'train_input/concat_2:0' shape=(?, 1024) dtype=float32>, <tf.Tensor 'train_input/SparseToIndicator_2:0' shape=(?, 4716) dtype=bool>, <tf.Tensor 'train_input/ones_2:0' shape=(?,) dtype=float32>), (<tf.Tensor 'train_input/ParseExample_3/ParseExample:4' shape=(?,) dtype=string>, <tf.Tensor 'train_input/concat_3:0' shape=(?, 1024) dtype=float32>, <tf.Tensor 'train_input/SparseToIndicator_3:0' shape=(?, 4716) dtype=bool>, <tf.Tensor 'train_input/ones_3:0' shape=(?,) dtype=float32>), (<tf.Tensor 'train_input/ParseExample_4/ParseExample:4' shape=(?,) dtype=string>, <tf.Tensor 'train_input/concat_4:0' shape=(?, 1024) dtype=float32>, <tf.Tensor 'train_input/SparseToIndicator_4:0' shape=(?, 4716) dtype=bool>, <tf.Tensor 'train_input/ones_4:0' shape=(?,) dtype=float32>), (<tf.Tensor 'train_input/ParseExample_5/ParseExample:4' shape=(?,) dtype=string>, <tf.Tensor 'train_input/concat_5:0' shape=(?, 1024) dtype=float32>, <tf.Tensor 'train_input/SparseToIndicator_5:0' shape=(?, 4716) dtype=bool>, <tf.Tensor 'train_input/ones_5:0' shape=(?,) dtype=float32>), (<tf.Tensor 'train_input/ParseExample_6/ParseExample:4' shape=(?,) dtype=string>, <tf.Tensor 'train_input/concat_6:0' shape=(?, 1024) dtype=float32>, <tf.Tensor 'train_input/SparseToIndicator_6:0' shape=(?, 4716) dtype=bool>, <tf.Tensor 'train_input/ones_6:0' shape=(?,) dtype=float32>), (<tf.Tensor 'train_input/ParseExample_7/ParseExample:4' shape=(?,) dtype=string>, <tf.Tensor 'train_input/concat_7:0' shape=(?, 1024) dtype=float32>, <tf.Tensor 'train_input/SparseToIndicator_7:0' shape=(?, 4716) dtype=bool>, <tf.Tensor 'train_input/ones_7:0' shape=(?,) dtype=float32>)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as graph:\n",
    "    \n",
    "    if meta_filename:\n",
    "        logging.info(\"%s: Restoring from meta graph file %s\",\n",
    "            task_as_string(task), meta_filename)\n",
    "        saver = tf.train.import_meta_graph(meta_filename)\n",
    "    \n",
    "    with tf.device(device_fn):\n",
    "\n",
    "        if not meta_filename:\n",
    "            \"\"\"Find the model and build the graph.\"\"\"\n",
    "\n",
    "            label_loss_fn = find_class_by_name(FLAGS.label_loss, [losses])()\n",
    "            optimizer_class = find_class_by_name(FLAGS.optimizer, [tf.train])\n",
    "\n",
    "            build_graph(reader=reader,\n",
    "                         model=model,\n",
    "                         optimizer_class=optimizer_class,\n",
    "                         clip_gradient_norm=FLAGS.clip_gradient_norm,\n",
    "                         train_data_pattern=FLAGS.train_data_pattern,\n",
    "                         label_loss_fn=label_loss_fn,\n",
    "                         base_learning_rate=FLAGS.base_learning_rate,\n",
    "                         learning_rate_decay=FLAGS.learning_rate_decay,\n",
    "                         learning_rate_decay_examples=FLAGS.learning_rate_decay_examples,\n",
    "                         regularization_penalty=FLAGS.regularization_penalty,\n",
    "                         num_readers=FLAGS.num_readers,\n",
    "                         batch_size=FLAGS.batch_size,\n",
    "                         num_epochs=FLAGS.num_epochs)\n",
    "\n",
    "        saver = tf.train.Saver(max_to_keep=0, keep_checkpoint_every_n_hours=0.25)\n",
    "    \n",
    "        global_step = tf.get_collection(\"global_step\")[0]\n",
    "        loss = tf.get_collection(\"loss\")[0]\n",
    "        predictions = tf.get_collection(\"predictions\")[0]\n",
    "        labels = tf.get_collection(\"labels\")[0]\n",
    "        train_op = tf.get_collection(\"train_op\")[0]\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        \n",
    "    sv = tf.train.Supervisor(\n",
    "        graph,\n",
    "        logdir=FLAGS.train_dir,\n",
    "        init_op=init_op,\n",
    "        is_chief=is_master,\n",
    "        global_step=global_step,\n",
    "        save_model_secs=15 * 60,\n",
    "        save_summaries_secs=120,\n",
    "        saver=saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(global_step_val, saver, save_path, session):\n",
    "\n",
    "    # If the model has already been exported at this step, return.\n",
    "    if global_step_val == last_model_export_step:\n",
    "      return\n",
    "\n",
    "    last_checkpoint = saver.save(session, save_path, global_step_val)\n",
    "\n",
    "    model_dir = \"{0}/export/step_{1}\".format(FLAGS.train_dir, global_step_val)\n",
    "    logging.info(\"%s: Exporting the model at step %s to %s.\",\n",
    "                 task_as_string(task), global_step_val, model_dir)\n",
    "\n",
    "    model_exporter.export_model(\n",
    "        model_dir=model_dir,\n",
    "        global_step_val=global_step_val,\n",
    "        last_checkpoint=last_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "        allow_soft_placement=True,log_device_placement=FLAGS.log_device_placement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/job:master/task:0: Starting managed session.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path models\\model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:/job:master/task:0: Entering training loop.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:training step 1 | Loss: 3269.02 Examples/sec: 1807.95\n",
      "INFO:tensorflow:models\\model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:training step 2 | Loss: 3243.53 Examples/sec: 8015.47\n",
      "INFO:tensorflow:Recording summary at step 2.\n",
      "INFO:tensorflow:training step 3 | Loss: 3217.62 Examples/sec: 8415.93\n",
      "INFO:tensorflow:training step 4 | Loss: 3192.51 Examples/sec: 9333.88\n",
      "INFO:tensorflow:training step 5 | Loss: 3164.59 Examples/sec: 10807.45\n",
      "INFO:tensorflow:training step 6 | Loss: 3141.75 Examples/sec: 10695.31\n",
      "INFO:tensorflow:training step 7 | Loss: 3114.57 Examples/sec: 9086.15\n",
      "INFO:tensorflow:training step 8 | Loss: 3092.61 Examples/sec: 9968.04\n",
      "INFO:tensorflow:training step 9 | Loss: 3061.52 Examples/sec: 9803.29\n",
      "INFO:tensorflow:training step 10 | Loss: 3044.77 Examples/sec: 10065.99 | Hit@1: 0.56 PERR: 0.37 GAP: 0.25\n",
      "INFO:tensorflow:models\\model.ckpt-10 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:/job:master/task:0: Exporting the model at step 10 to models/export/step_10.\n",
      "INFO:tensorflow:Restoring parameters from models\\model.ckpt-10\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'models/export/step_10\\\\saved_model.pb'\n",
      "INFO:tensorflow:training step 11 | Loss: 3015.53 Examples/sec: 9968.31\n",
      "INFO:tensorflow:training step 12 | Loss: 2992.50 Examples/sec: 10165.84\n",
      "INFO:tensorflow:training step 13 | Loss: 2976.88 Examples/sec: 9419.70\n",
      "INFO:tensorflow:training step 14 | Loss: 2942.08 Examples/sec: 8084.55\n",
      "INFO:tensorflow:training step 15 | Loss: 2920.64 Examples/sec: 7719.85\n",
      "INFO:tensorflow:training step 16 | Loss: 2894.56 Examples/sec: 8347.54\n",
      "INFO:tensorflow:training step 17 | Loss: 2870.16 Examples/sec: 9686.11\n",
      "INFO:tensorflow:training step 18 | Loss: 2850.21 Examples/sec: 9249.96\n",
      "INFO:tensorflow:training step 19 | Loss: 2823.13 Examples/sec: 9506.94\n",
      "INFO:tensorflow:training step 20 | Loss: 2799.22 Examples/sec: 10065.78 | Hit@1: 0.62 PERR: 0.46 GAP: 0.34\n",
      "INFO:tensorflow:training step 21 | Loss: 2780.38 Examples/sec: 9780.67\n",
      "INFO:tensorflow:training step 22 | Loss: 2761.84 Examples/sec: 10667.81\n",
      "INFO:tensorflow:training step 23 | Loss: 2740.72 Examples/sec: 9768.06\n",
      "INFO:tensorflow:training step 24 | Loss: 2714.12 Examples/sec: 10477.11\n",
      "INFO:tensorflow:training step 25 | Loss: 2685.40 Examples/sec: 9598.53\n",
      "INFO:tensorflow:training step 26 | Loss: 2664.77 Examples/sec: 10370.99\n",
      "INFO:tensorflow:training step 27 | Loss: 2641.35 Examples/sec: 9968.31\n",
      "INFO:tensorflow:training step 28 | Loss: 2634.11 Examples/sec: 9778.36\n",
      "INFO:tensorflow:training step 29 | Loss: 2605.65 Examples/sec: 9086.13\n",
      "INFO:tensorflow:training step 30 | Loss: 2607.38 Examples/sec: 10165.70 | Hit@1: 0.62 PERR: 0.46 GAP: 0.39\n",
      "INFO:tensorflow:training step 31 | Loss: 2573.77 Examples/sec: 9217.40\n",
      "INFO:tensorflow:training step 32 | Loss: 2549.58 Examples/sec: 10730.44\n",
      "INFO:tensorflow:training step 33 | Loss: 2529.69 Examples/sec: 10217.70\n",
      "INFO:tensorflow:training step 34 | Loss: 2493.31 Examples/sec: 10370.89\n",
      "INFO:tensorflow:training step 35 | Loss: 2477.50 Examples/sec: 10267.57\n",
      "INFO:tensorflow:training step 36 | Loss: 2467.97 Examples/sec: 8928.02\n",
      "INFO:tensorflow:training step 37 | Loss: 2436.56 Examples/sec: 10317.12\n",
      "INFO:tensorflow:training step 38 | Loss: 2412.06 Examples/sec: 9551.63\n",
      "INFO:tensorflow:training step 39 | Loss: 2410.86 Examples/sec: 10370.94\n",
      "INFO:tensorflow:training step 40 | Loss: 2372.21 Examples/sec: 10130.26 | Hit@1: 0.63 PERR: 0.47 GAP: 0.42\n",
      "INFO:tensorflow:training step 41 | Loss: 2370.10 Examples/sec: 9233.11\n",
      "INFO:tensorflow:training step 42 | Loss: 2340.48 Examples/sec: 9981.24\n",
      "INFO:tensorflow:training step 43 | Loss: 2343.67 Examples/sec: 9778.36\n",
      "INFO:tensorflow:training step 44 | Loss: 2306.07 Examples/sec: 9988.92\n",
      "INFO:tensorflow:training step 45 | Loss: 2288.81 Examples/sec: 9595.51\n",
      "INFO:tensorflow:training step 46 | Loss: 2275.69 Examples/sec: 9086.05\n",
      "INFO:tensorflow:training step 47 | Loss: 2241.73 Examples/sec: 9946.59\n",
      "INFO:tensorflow:training step 48 | Loss: 2216.89 Examples/sec: 9968.22\n",
      "INFO:tensorflow:training step 49 | Loss: 2180.50 Examples/sec: 10015.55\n",
      "INFO:tensorflow:training step 50 | Loss: 2177.66 Examples/sec: 11420.96 | Hit@1: 0.68 PERR: 0.51 GAP: 0.47\n",
      "INFO:tensorflow:training step 51 | Loss: 2157.63 Examples/sec: 10134.66\n",
      "INFO:tensorflow:training step 52 | Loss: 2152.06 Examples/sec: 10271.80\n",
      "INFO:tensorflow:training step 53 | Loss: 2131.83 Examples/sec: 9973.08\n",
      "INFO:tensorflow:training step 54 | Loss: 2120.39 Examples/sec: 10857.12\n",
      "INFO:tensorflow:training step 55 | Loss: 2092.67 Examples/sec: 9117.70\n",
      "INFO:tensorflow:training step 56 | Loss: 2076.48 Examples/sec: 9686.31\n",
      "INFO:tensorflow:training step 57 | Loss: 2057.19 Examples/sec: 9595.31\n",
      "INFO:tensorflow:training step 58 | Loss: 2016.89 Examples/sec: 9963.94\n",
      "INFO:tensorflow:training step 59 | Loss: 2010.27 Examples/sec: 9249.70\n",
      "INFO:tensorflow:training step 60 | Loss: 2006.71 Examples/sec: 8556.19 | Hit@1: 0.66 PERR: 0.48 GAP: 0.45\n",
      "INFO:tensorflow:training step 61 | Loss: 1983.72 Examples/sec: 10584.92\n",
      "INFO:tensorflow:training step 62 | Loss: 1949.30 Examples/sec: 8021.32\n",
      "INFO:tensorflow:training step 63 | Loss: 1972.96 Examples/sec: 9782.14\n",
      "INFO:tensorflow:training step 64 | Loss: 1929.58 Examples/sec: 9686.24\n",
      "INFO:tensorflow:training step 65 | Loss: 1920.51 Examples/sec: 9968.29\n",
      "INFO:tensorflow:training step 66 | Loss: 1894.09 Examples/sec: 9968.13\n",
      "INFO:tensorflow:training step 67 | Loss: 1885.40 Examples/sec: 9595.72\n",
      "INFO:tensorflow:training step 68 | Loss: 1886.17 Examples/sec: 10807.53\n",
      "INFO:tensorflow:training step 69 | Loss: 1861.98 Examples/sec: 9419.59\n",
      "INFO:tensorflow:training step 70 | Loss: 1854.22 Examples/sec: 9876.14 | Hit@1: 0.65 PERR: 0.49 GAP: 0.45\n",
      "INFO:tensorflow:training step 71 | Loss: 1833.58 Examples/sec: 9373.75\n",
      "INFO:tensorflow:training step 72 | Loss: 1800.10 Examples/sec: 10267.48\n",
      "INFO:tensorflow:training step 73 | Loss: 1809.50 Examples/sec: 10477.11\n",
      "INFO:tensorflow:training step 74 | Loss: 1791.86 Examples/sec: 9595.61\n",
      "INFO:tensorflow:training step 75 | Loss: 1769.58 Examples/sec: 9780.67\n",
      "INFO:tensorflow:training step 76 | Loss: 1774.32 Examples/sec: 9872.51\n",
      "INFO:tensorflow:training step 77 | Loss: 1737.90 Examples/sec: 10267.21\n",
      "INFO:tensorflow:training step 78 | Loss: 1712.84 Examples/sec: 9686.31\n",
      "INFO:tensorflow:training step 79 | Loss: 1720.34 Examples/sec: 10373.97\n",
      "INFO:tensorflow:training step 80 | Loss: 1683.91 Examples/sec: 10421.01 | Hit@1: 0.66 PERR: 0.50 GAP: 0.48\n",
      "INFO:tensorflow:training step 81 | Loss: 1694.60 Examples/sec: 9546.71\n",
      "INFO:tensorflow:training step 82 | Loss: 1656.93 Examples/sec: 9688.32\n",
      "INFO:tensorflow:training step 83 | Loss: 1656.83 Examples/sec: 9510.30\n",
      "INFO:tensorflow:training step 84 | Loss: 1635.10 Examples/sec: 9872.53\n",
      "INFO:tensorflow:training step 85 | Loss: 1630.74 Examples/sec: 10268.90\n",
      "INFO:tensorflow:training step 86 | Loss: 1635.22 Examples/sec: 9685.65\n",
      "INFO:tensorflow:training step 87 | Loss: 1626.25 Examples/sec: 10807.86\n",
      "INFO:tensorflow:training step 88 | Loss: 1606.56 Examples/sec: 10922.53\n",
      "INFO:tensorflow:training step 89 | Loss: 1572.76 Examples/sec: 10267.55\n",
      "INFO:tensorflow:training step 90 | Loss: 1556.15 Examples/sec: 10375.65 | Hit@1: 0.65 PERR: 0.49 GAP: 0.46\n",
      "INFO:tensorflow:training step 91 | Loss: 1561.14 Examples/sec: 10476.73\n",
      "INFO:tensorflow:training step 92 | Loss: 1529.20 Examples/sec: 10375.87\n",
      "INFO:tensorflow:training step 93 | Loss: 1507.16 Examples/sec: 9872.97\n",
      "INFO:tensorflow:training step 94 | Loss: 1510.95 Examples/sec: 10267.38\n",
      "INFO:tensorflow:training step 95 | Loss: 1486.64 Examples/sec: 9506.70\n",
      "INFO:tensorflow:training step 96 | Loss: 1484.15 Examples/sec: 9778.65\n",
      "INFO:tensorflow:training step 97 | Loss: 1463.08 Examples/sec: 10620.96\n",
      "INFO:tensorflow:training step 98 | Loss: 1454.38 Examples/sec: 10885.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:training step 99 | Loss: 1431.33 Examples/sec: 11672.12\n",
      "INFO:tensorflow:training step 100 | Loss: 1418.40 Examples/sec: 10266.76 | Hit@1: 0.69 PERR: 0.52 GAP: 0.48\n",
      "INFO:tensorflow:training step 101 | Loss: 1419.96 Examples/sec: 12590.15\n",
      "INFO:tensorflow:training step 102 | Loss: 1393.36 Examples/sec: 9001.60\n",
      "INFO:tensorflow:training step 103 | Loss: 1375.68 Examples/sec: 12330.73\n",
      "INFO:tensorflow:training step 104 | Loss: 1369.42 Examples/sec: 10193.76\n",
      "INFO:tensorflow:training step 105 | Loss: 1378.88 Examples/sec: 10319.63\n",
      "INFO:tensorflow:training step 106 | Loss: 1332.38 Examples/sec: 10185.61\n",
      "INFO:tensorflow:training step 107 | Loss: 1344.33 Examples/sec: 10282.72\n",
      "INFO:tensorflow:training step 108 | Loss: 1333.60 Examples/sec: 9142.02\n",
      "INFO:tensorflow:training step 109 | Loss: 1325.02 Examples/sec: 11529.19\n",
      "INFO:tensorflow:training step 110 | Loss: 1312.75 Examples/sec: 9330.29 | Hit@1: 0.69 PERR: 0.53 GAP: 0.51\n",
      "INFO:tensorflow:training step 111 | Loss: 1303.45 Examples/sec: 10036.45\n",
      "INFO:tensorflow:training step 112 | Loss: 1269.24 Examples/sec: 10371.21\n",
      "INFO:tensorflow:training step 113 | Loss: 1289.53 Examples/sec: 10395.69\n",
      "INFO:tensorflow:training step 114 | Loss: 1268.09 Examples/sec: 10429.49\n",
      "INFO:tensorflow:training step 115 | Loss: 1284.21 Examples/sec: 9968.17\n",
      "INFO:tensorflow:training step 116 | Loss: 1227.62 Examples/sec: 13149.09\n",
      "INFO:tensorflow:training step 117 | Loss: 1232.94 Examples/sec: 10366.08\n",
      "INFO:tensorflow:training step 118 | Loss: 1217.02 Examples/sec: 10585.12\n",
      "INFO:tensorflow:training step 119 | Loss: 1205.51 Examples/sec: 8775.04\n",
      "INFO:tensorflow:training step 120 | Loss: 1188.57 Examples/sec: 10924.67 | Hit@1: 0.69 PERR: 0.52 GAP: 0.49\n",
      "INFO:tensorflow:training step 121 | Loss: 1198.04 Examples/sec: 10021.88\n",
      "INFO:tensorflow:training step 122 | Loss: 1175.35 Examples/sec: 11115.71\n",
      "INFO:tensorflow:training step 123 | Loss: 1177.97 Examples/sec: 11147.97\n",
      "INFO:tensorflow:training step 124 | Loss: 1162.80 Examples/sec: 10169.86\n",
      "INFO:tensorflow:training step 125 | Loss: 1127.87 Examples/sec: 10488.73\n",
      "INFO:tensorflow:training step 126 | Loss: 1136.91 Examples/sec: 10203.13\n",
      "INFO:tensorflow:training step 127 | Loss: 1136.71 Examples/sec: 9981.80\n",
      "INFO:tensorflow:training step 128 | Loss: 1130.91 Examples/sec: 12394.47\n",
      "INFO:tensorflow:training step 129 | Loss: 1116.94 Examples/sec: 9763.86\n",
      "INFO:tensorflow:training step 130 | Loss: 1092.07 Examples/sec: 10082.91 | Hit@1: 0.70 PERR: 0.52 GAP: 0.50\n",
      "INFO:tensorflow:training step 131 | Loss: 1081.16 Examples/sec: 10839.31\n",
      "INFO:tensorflow:training step 132 | Loss: 1073.31 Examples/sec: 10168.13\n",
      "INFO:tensorflow:training step 133 | Loss: 1066.48 Examples/sec: 10267.21\n",
      "INFO:tensorflow:training step 134 | Loss: 1077.32 Examples/sec: 11040.08\n",
      "INFO:tensorflow:training step 135 | Loss: 1046.81 Examples/sec: 10828.60\n",
      "INFO:tensorflow:training step 136 | Loss: 1045.01 Examples/sec: 10381.06\n",
      "INFO:tensorflow:training step 137 | Loss: 1017.17 Examples/sec: 12159.92\n",
      "INFO:tensorflow:training step 138 | Loss: 1020.06 Examples/sec: 10251.74\n",
      "INFO:tensorflow:training step 139 | Loss: 1005.65 Examples/sec: 9317.48\n",
      "INFO:tensorflow:training step 140 | Loss: 1017.98 Examples/sec: 9968.41 | Hit@1: 0.68 PERR: 0.51 GAP: 0.52\n",
      "INFO:tensorflow:training step 141 | Loss: 992.66 Examples/sec: 9723.24\n",
      "INFO:tensorflow:training step 142 | Loss: 969.92 Examples/sec: 10747.76\n",
      "INFO:tensorflow:training step 143 | Loss: 967.37 Examples/sec: 11035.74\n",
      "INFO:tensorflow:training step 144 | Loss: 964.37 Examples/sec: 10196.74\n",
      "INFO:tensorflow:training step 145 | Loss: 963.97 Examples/sec: 11445.04\n",
      "INFO:tensorflow:training step 146 | Loss: 953.87 Examples/sec: 12100.89\n",
      "INFO:tensorflow:training step 147 | Loss: 939.53 Examples/sec: 9334.41\n",
      "INFO:tensorflow:training step 148 | Loss: 935.63 Examples/sec: 11036.08\n",
      "INFO:tensorflow:training step 149 | Loss: 923.83 Examples/sec: 9577.15\n",
      "INFO:tensorflow:training step 150 | Loss: 924.38 Examples/sec: 10913.56 | Hit@1: 0.67 PERR: 0.51 GAP: 0.53\n",
      "INFO:tensorflow:training step 151 | Loss: 898.64 Examples/sec: 10074.02\n",
      "INFO:tensorflow:training step 152 | Loss: 907.54 Examples/sec: 9497.79\n",
      "INFO:tensorflow:training step 153 | Loss: 900.42 Examples/sec: 10696.45\n",
      "INFO:tensorflow:training step 154 | Loss: 885.38 Examples/sec: 11040.20\n",
      "INFO:tensorflow:training step 155 | Loss: 877.15 Examples/sec: 10812.51\n",
      "INFO:tensorflow:training step 156 | Loss: 854.76 Examples/sec: 10271.63\n",
      "INFO:tensorflow:training step 157 | Loss: 857.79 Examples/sec: 12337.75\n",
      "INFO:tensorflow:training step 158 | Loss: 839.05 Examples/sec: 10012.56\n",
      "INFO:tensorflow:training step 159 | Loss: 840.93 Examples/sec: 10488.09\n",
      "INFO:tensorflow:training step 160 | Loss: 835.44 Examples/sec: 10093.24 | Hit@1: 0.69 PERR: 0.52 GAP: 0.53\n",
      "INFO:tensorflow:training step 161 | Loss: 821.73 Examples/sec: 10502.09\n",
      "INFO:tensorflow:training step 162 | Loss: 833.23 Examples/sec: 10917.97\n",
      "INFO:tensorflow:training step 163 | Loss: 805.25 Examples/sec: 10229.84\n",
      "INFO:tensorflow:training step 164 | Loss: 807.13 Examples/sec: 12071.26\n",
      "INFO:tensorflow:training step 165 | Loss: 812.29 Examples/sec: 10404.20\n",
      "INFO:tensorflow:training step 166 | Loss: 790.49 Examples/sec: 9589.23\n",
      "INFO:tensorflow:training step 167 | Loss: 794.41 Examples/sec: 10064.81\n",
      "INFO:tensorflow:training step 168 | Loss: 792.97 Examples/sec: 10718.85\n",
      "INFO:tensorflow:training step 169 | Loss: 759.63 Examples/sec: 8580.48\n",
      "INFO:tensorflow:training step 170 | Loss: 761.24 Examples/sec: 9870.99 | Hit@1: 0.69 PERR: 0.52 GAP: 0.52\n",
      "INFO:tensorflow:training step 171 | Loss: 763.10 Examples/sec: 9507.02\n",
      "INFO:tensorflow:training step 172 | Loss: 741.76 Examples/sec: 9685.39\n",
      "INFO:tensorflow:training step 173 | Loss: 760.78 Examples/sec: 9993.62\n",
      "INFO:tensorflow:training step 174 | Loss: 734.19 Examples/sec: 9068.82\n",
      "INFO:tensorflow:training step 175 | Loss: 720.70 Examples/sec: 8701.19\n",
      "INFO:tensorflow:training step 176 | Loss: 733.95 Examples/sec: 7796.29\n",
      "INFO:tensorflow:training step 177 | Loss: 714.98 Examples/sec: 8199.40\n",
      "INFO:tensorflow:training step 178 | Loss: 727.58 Examples/sec: 7662.11\n",
      "INFO:tensorflow:training step 179 | Loss: 701.19 Examples/sec: 8379.67\n",
      "INFO:tensorflow:training step 180 | Loss: 705.14 Examples/sec: 9086.95 | Hit@1: 0.67 PERR: 0.51 GAP: 0.52\n",
      "INFO:tensorflow:training step 181 | Loss: 687.87 Examples/sec: 7911.30\n",
      "INFO:tensorflow:training step 182 | Loss: 670.35 Examples/sec: 7650.99\n",
      "INFO:tensorflow:training step 183 | Loss: 676.70 Examples/sec: 6617.97\n",
      "INFO:tensorflow:training step 184 | Loss: 678.92 Examples/sec: 10066.18\n",
      "INFO:tensorflow:training step 185 | Loss: 660.89 Examples/sec: 9778.36\n",
      "INFO:tensorflow:training step 186 | Loss: 664.01 Examples/sec: 9778.71\n",
      "INFO:tensorflow:training step 187 | Loss: 664.79 Examples/sec: 8213.42\n",
      "INFO:tensorflow:training step 188 | Loss: 642.62 Examples/sec: 9968.27\n",
      "INFO:tensorflow:training step 189 | Loss: 645.34 Examples/sec: 8485.44\n",
      "INFO:tensorflow:training step 190 | Loss: 637.50 Examples/sec: 7281.83 | Hit@1: 0.71 PERR: 0.54 GAP: 0.54\n",
      "INFO:tensorflow:training step 191 | Loss: 635.28 Examples/sec: 10165.70\n",
      "INFO:tensorflow:training step 192 | Loss: 623.59 Examples/sec: 10066.09\n",
      "INFO:tensorflow:training step 193 | Loss: 611.34 Examples/sec: 9777.51\n",
      "INFO:tensorflow:training step 194 | Loss: 612.87 Examples/sec: 9419.04\n",
      "INFO:tensorflow:training step 195 | Loss: 611.16 Examples/sec: 9334.13\n",
      "INFO:tensorflow:training step 196 | Loss: 599.98 Examples/sec: 9550.31\n",
      "INFO:tensorflow:training step 197 | Loss: 597.33 Examples/sec: 9375.90\n",
      "INFO:tensorflow:training step 198 | Loss: 579.44 Examples/sec: 9167.27\n",
      "INFO:tensorflow:training step 199 | Loss: 591.42 Examples/sec: 9595.66\n",
      "INFO:tensorflow:training step 200 | Loss: 589.17 Examples/sec: 9595.89 | Hit@1: 0.69 PERR: 0.53 GAP: 0.55\n",
      "INFO:tensorflow:training step 201 | Loss: 567.67 Examples/sec: 7719.43\n",
      "INFO:tensorflow:training step 202 | Loss: 567.14 Examples/sec: 6819.67\n",
      "INFO:tensorflow:training step 203 | Loss: 563.32 Examples/sec: 9085.51\n",
      "INFO:tensorflow:training step 204 | Loss: 554.98 Examples/sec: 8836.42\n",
      "INFO:tensorflow:training step 205 | Loss: 555.81 Examples/sec: 10326.95\n",
      "INFO:tensorflow:training step 206 | Loss: 556.99 Examples/sec: 8050.65\n",
      "INFO:tensorflow:training step 207 | Loss: 541.54 Examples/sec: 8485.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:training step 208 | Loss: 540.62 Examples/sec: 9417.38\n",
      "INFO:tensorflow:training step 209 | Loss: 530.45 Examples/sec: 10608.34\n",
      "INFO:tensorflow:training step 210 | Loss: 530.12 Examples/sec: 9305.05 | Hit@1: 0.70 PERR: 0.54 GAP: 0.56\n",
      "INFO:tensorflow:training step 211 | Loss: 518.89 Examples/sec: 9544.80\n",
      "INFO:tensorflow:training step 212 | Loss: 509.64 Examples/sec: 10015.90\n",
      "INFO:tensorflow:training step 213 | Loss: 516.47 Examples/sec: 9732.36\n",
      "INFO:tensorflow:training step 214 | Loss: 513.02 Examples/sec: 9778.60\n",
      "INFO:tensorflow:training step 215 | Loss: 510.18 Examples/sec: 9419.78\n",
      "INFO:tensorflow:training step 216 | Loss: 495.41 Examples/sec: 10064.86\n",
      "INFO:tensorflow:training step 217 | Loss: 496.26 Examples/sec: 10269.42\n",
      "INFO:tensorflow:training step 218 | Loss: 486.41 Examples/sec: 9686.02\n",
      "INFO:tensorflow:training step 219 | Loss: 489.20 Examples/sec: 10302.57\n",
      "INFO:tensorflow:training step 220 | Loss: 480.88 Examples/sec: 10562.40 | Hit@1: 0.72 PERR: 0.54 GAP: 0.56\n",
      "INFO:tensorflow:training step 221 | Loss: 477.89 Examples/sec: 10501.45\n",
      "INFO:tensorflow:training step 222 | Loss: 480.65 Examples/sec: 10627.90\n",
      "INFO:tensorflow:training step 223 | Loss: 467.50 Examples/sec: 8463.82\n",
      "INFO:tensorflow:training step 224 | Loss: 460.66 Examples/sec: 7897.98\n",
      "INFO:tensorflow:training step 225 | Loss: 458.88 Examples/sec: 8385.64\n",
      "INFO:tensorflow:training step 226 | Loss: 455.78 Examples/sec: 9533.27\n",
      "INFO:tensorflow:training step 227 | Loss: 446.24 Examples/sec: 8663.61\n",
      "INFO:tensorflow:training step 228 | Loss: 443.34 Examples/sec: 9659.30\n",
      "INFO:tensorflow:training step 229 | Loss: 442.74 Examples/sec: 10066.06\n",
      "INFO:tensorflow:training step 230 | Loss: 436.85 Examples/sec: 9781.27 | Hit@1: 0.71 PERR: 0.53 GAP: 0.56\n",
      "INFO:tensorflow:training step 231 | Loss: 437.55 Examples/sec: 9876.49\n",
      "INFO:tensorflow:training step 232 | Loss: 429.06 Examples/sec: 10275.24\n",
      "INFO:tensorflow:training step 233 | Loss: 421.19 Examples/sec: 10725.43\n",
      "INFO:tensorflow:training step 234 | Loss: 429.49 Examples/sec: 10250.59\n",
      "INFO:tensorflow:training step 235 | Loss: 416.46 Examples/sec: 10873.45\n",
      "INFO:tensorflow:training step 236 | Loss: 418.15 Examples/sec: 11472.52\n",
      "INFO:tensorflow:training step 237 | Loss: 414.13 Examples/sec: 9245.04\n",
      "INFO:tensorflow:training step 238 | Loss: 397.56 Examples/sec: 10336.07\n",
      "INFO:tensorflow:training step 239 | Loss: 398.66 Examples/sec: 9935.13\n",
      "INFO:tensorflow:training step 240 | Loss: 402.92 Examples/sec: 10165.82 | Hit@1: 0.69 PERR: 0.53 GAP: 0.55\n",
      "INFO:tensorflow:training step 241 | Loss: 390.85 Examples/sec: 10370.94\n",
      "INFO:tensorflow:training step 242 | Loss: 396.07 Examples/sec: 7550.18\n",
      "INFO:tensorflow:training step 243 | Loss: 390.83 Examples/sec: 8148.71\n",
      "INFO:tensorflow:training step 244 | Loss: 383.50 Examples/sec: 9002.99\n",
      "INFO:tensorflow:training step 245 | Loss: 376.33 Examples/sec: 9811.30\n",
      "INFO:tensorflow:training step 246 | Loss: 380.32 Examples/sec: 8148.81\n",
      "INFO:tensorflow:training step 247 | Loss: 367.66 Examples/sec: 7838.29\n",
      "INFO:tensorflow:training step 248 | Loss: 370.21 Examples/sec: 10403.82\n",
      "INFO:tensorflow:training step 249 | Loss: 363.42 Examples/sec: 11319.82\n",
      "INFO:tensorflow:training step 250 | Loss: 362.68 Examples/sec: 9255.76 | Hit@1: 0.73 PERR: 0.54 GAP: 0.56\n",
      "INFO:tensorflow:training step 251 | Loss: 355.07 Examples/sec: 10065.83\n",
      "INFO:tensorflow:training step 252 | Loss: 358.20 Examples/sec: 10808.08\n",
      "INFO:tensorflow:training step 253 | Loss: 356.93 Examples/sec: 9968.50\n",
      "INFO:tensorflow:training step 254 | Loss: 350.40 Examples/sec: 10267.30\n",
      "INFO:tensorflow:training step 255 | Loss: 348.54 Examples/sec: 11066.48\n",
      "INFO:tensorflow:training step 256 | Loss: 343.41 Examples/sec: 10227.99\n",
      "INFO:tensorflow:training step 257 | Loss: 341.91 Examples/sec: 9961.91\n",
      "INFO:tensorflow:training step 258 | Loss: 342.24 Examples/sec: 10572.80\n",
      "INFO:tensorflow:training step 259 | Loss: 334.08 Examples/sec: 12020.92\n",
      "INFO:tensorflow:training step 260 | Loss: 329.30 Examples/sec: 9015.73 | Hit@1: 0.71 PERR: 0.53 GAP: 0.56\n",
      "INFO:tensorflow:training step 261 | Loss: 323.59 Examples/sec: 10926.39\n",
      "INFO:tensorflow:training step 262 | Loss: 320.41 Examples/sec: 9778.27\n",
      "INFO:tensorflow:training step 263 | Loss: 320.59 Examples/sec: 10450.96\n",
      "INFO:tensorflow:training step 264 | Loss: 322.01 Examples/sec: 10549.95\n",
      "INFO:tensorflow:training step 265 | Loss: 318.66 Examples/sec: 9885.19\n",
      "INFO:tensorflow:training step 266 | Loss: 312.13 Examples/sec: 10787.01\n",
      "INFO:tensorflow:training step 267 | Loss: 304.91 Examples/sec: 10910.96\n",
      "INFO:tensorflow:training step 268 | Loss: 302.50 Examples/sec: 9738.21\n",
      "INFO:tensorflow:training step 269 | Loss: 305.99 Examples/sec: 7607.33\n",
      "INFO:tensorflow:training step 270 | Loss: 301.76 Examples/sec: 9426.85 | Hit@1: 0.67 PERR: 0.50 GAP: 0.55\n",
      "INFO:tensorflow:training step 271 | Loss: 294.71 Examples/sec: 9963.48\n",
      "INFO:tensorflow:training step 272 | Loss: 294.31 Examples/sec: 9872.49\n",
      "INFO:tensorflow:training step 273 | Loss: 292.01 Examples/sec: 10111.21\n",
      "INFO:tensorflow:training step 274 | Loss: 291.81 Examples/sec: 9419.72\n",
      "INFO:tensorflow:training step 275 | Loss: 287.26 Examples/sec: 10807.67\n",
      "INFO:tensorflow:training step 276 | Loss: 282.53 Examples/sec: 11526.65\n",
      "INFO:tensorflow:training step 277 | Loss: 280.70 Examples/sec: 9795.28\n",
      "INFO:tensorflow:training step 278 | Loss: 280.56 Examples/sec: 11282.77\n",
      "INFO:tensorflow:training step 279 | Loss: 277.44 Examples/sec: 9688.17\n",
      "INFO:tensorflow:training step 280 | Loss: 274.82 Examples/sec: 8415.88 | Hit@1: 0.71 PERR: 0.53 GAP: 0.56\n",
      "INFO:tensorflow:training step 281 | Loss: 268.71 Examples/sec: 9615.94\n",
      "INFO:tensorflow:training step 282 | Loss: 272.13 Examples/sec: 10065.83\n",
      "INFO:tensorflow:training step 283 | Loss: 264.29 Examples/sec: 10889.02\n",
      "INFO:tensorflow:training step 284 | Loss: 261.43 Examples/sec: 8417.56\n",
      "INFO:tensorflow:training step 285 | Loss: 258.98 Examples/sec: 8485.50\n",
      "INFO:tensorflow:training step 286 | Loss: 258.75 Examples/sec: 10249.03\n",
      "INFO:tensorflow:training step 287 | Loss: 256.97 Examples/sec: 10355.78\n",
      "INFO:tensorflow:training step 288 | Loss: 252.40 Examples/sec: 10336.96\n",
      "INFO:tensorflow:training step 289 | Loss: 251.16 Examples/sec: 8701.12\n",
      "INFO:tensorflow:training step 290 | Loss: 248.62 Examples/sec: 8213.73 | Hit@1: 0.70 PERR: 0.53 GAP: 0.55\n",
      "INFO:tensorflow:training step 291 | Loss: 242.13 Examples/sec: 10072.60\n",
      "INFO:tensorflow:training step 292 | Loss: 241.50 Examples/sec: 10066.11\n",
      "INFO:tensorflow:training step 293 | Loss: 247.86 Examples/sec: 9793.36\n",
      "INFO:tensorflow:training step 294 | Loss: 241.59 Examples/sec: 10608.00\n",
      "INFO:tensorflow:training step 295 | Loss: 240.26 Examples/sec: 10123.48\n",
      "INFO:tensorflow:training step 296 | Loss: 233.52 Examples/sec: 8769.28\n",
      "INFO:tensorflow:training step 297 | Loss: 235.33 Examples/sec: 8556.09\n",
      "INFO:tensorflow:training step 298 | Loss: 231.31 Examples/sec: 8348.03\n",
      "INFO:tensorflow:training step 299 | Loss: 229.83 Examples/sec: 9086.19\n",
      "INFO:tensorflow:training step 300 | Loss: 226.62 Examples/sec: 9652.33 | Hit@1: 0.68 PERR: 0.51 GAP: 0.57\n",
      "INFO:tensorflow:training step 301 | Loss: 225.61 Examples/sec: 10823.57\n",
      "INFO:tensorflow:training step 302 | Loss: 224.11 Examples/sec: 10394.03\n",
      "INFO:tensorflow:training step 303 | Loss: 220.17 Examples/sec: 9849.85\n",
      "INFO:tensorflow:training step 304 | Loss: 215.11 Examples/sec: 10302.77\n",
      "INFO:tensorflow:training step 305 | Loss: 214.61 Examples/sec: 10020.01\n",
      "INFO:tensorflow:training step 306 | Loss: 215.43 Examples/sec: 10249.81\n",
      "INFO:tensorflow:training step 307 | Loss: 212.65 Examples/sec: 10412.09\n",
      "INFO:tensorflow:training step 308 | Loss: 211.35 Examples/sec: 10317.55\n",
      "INFO:tensorflow:training step 309 | Loss: 207.73 Examples/sec: 9538.97\n",
      "INFO:tensorflow:training step 310 | Loss: 204.79 Examples/sec: 7958.67 | Hit@1: 0.70 PERR: 0.54 GAP: 0.57\n",
      "INFO:tensorflow:training step 311 | Loss: 199.84 Examples/sec: 10504.17\n",
      "INFO:tensorflow:training step 312 | Loss: 202.89 Examples/sec: 9639.91\n",
      "INFO:tensorflow:training step 313 | Loss: 197.22 Examples/sec: 9778.25\n",
      "INFO:tensorflow:training step 314 | Loss: 200.72 Examples/sec: 10371.41\n",
      "INFO:tensorflow:training step 315 | Loss: 195.60 Examples/sec: 10495.78\n",
      "INFO:tensorflow:training step 316 | Loss: 193.49 Examples/sec: 10404.02\n",
      "INFO:tensorflow:training step 317 | Loss: 193.83 Examples/sec: 10584.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:training step 318 | Loss: 189.65 Examples/sec: 11181.43\n",
      "INFO:tensorflow:training step 319 | Loss: 188.70 Examples/sec: 8942.54\n",
      "INFO:tensorflow:training step 320 | Loss: 189.78 Examples/sec: 10477.27 | Hit@1: 0.70 PERR: 0.53 GAP: 0.57\n",
      "INFO:tensorflow:training step 321 | Loss: 184.94 Examples/sec: 11158.66\n",
      "INFO:tensorflow:training step 322 | Loss: 183.03 Examples/sec: 11081.44\n",
      "INFO:tensorflow:training step 323 | Loss: 182.49 Examples/sec: 10437.29\n",
      "INFO:tensorflow:training step 324 | Loss: 181.01 Examples/sec: 9836.36\n",
      "INFO:tensorflow:training step 325 | Loss: 177.71 Examples/sec: 10371.26\n",
      "INFO:tensorflow:training step 326 | Loss: 177.53 Examples/sec: 10274.45\n",
      "INFO:tensorflow:training step 327 | Loss: 174.55 Examples/sec: 10166.28\n",
      "INFO:tensorflow:training step 328 | Loss: 173.14 Examples/sec: 8701.06\n",
      "INFO:tensorflow:training step 329 | Loss: 172.22 Examples/sec: 8628.07\n",
      "INFO:tensorflow:training step 330 | Loss: 169.09 Examples/sec: 9229.62 | Hit@1: 0.70 PERR: 0.54 GAP: 0.58\n",
      "INFO:tensorflow:training step 331 | Loss: 169.74 Examples/sec: 10163.73\n",
      "INFO:tensorflow:training step 332 | Loss: 168.78 Examples/sec: 10164.47\n",
      "INFO:tensorflow:training step 333 | Loss: 164.74 Examples/sec: 10267.30\n",
      "INFO:tensorflow:training step 334 | Loss: 162.47 Examples/sec: 10267.38\n",
      "INFO:tensorflow:training step 335 | Loss: 163.22 Examples/sec: 10165.92\n",
      "INFO:tensorflow:training step 336 | Loss: 162.08 Examples/sec: 3926.46\n",
      "INFO:tensorflow:training step 337 | Loss: 158.90 Examples/sec: 4542.99\n",
      "INFO:tensorflow:training step 338 | Loss: 158.81 Examples/sec: 9370.05\n",
      "INFO:tensorflow:training step 339 | Loss: 158.31 Examples/sec: 10373.34\n",
      "INFO:tensorflow:training step 340 | Loss: 156.08 Examples/sec: 8915.18 | Hit@1: 0.68 PERR: 0.52 GAP: 0.57\n",
      "INFO:tensorflow:training step 341 | Loss: 152.08 Examples/sec: 10568.30\n",
      "INFO:tensorflow:training step 342 | Loss: 152.03 Examples/sec: 10275.34\n",
      "INFO:tensorflow:training step 343 | Loss: 149.24 Examples/sec: 9643.10\n",
      "INFO:tensorflow:training step 344 | Loss: 149.12 Examples/sec: 10375.50\n",
      "INFO:tensorflow:training step 345 | Loss: 148.17 Examples/sec: 5672.57\n",
      "INFO:tensorflow:training step 346 | Loss: 146.74 Examples/sec: 5704.07\n",
      "INFO:tensorflow:training step 347 | Loss: 146.86 Examples/sec: 8485.48\n",
      "INFO:tensorflow:training step 348 | Loss: 142.30 Examples/sec: 10466.52\n",
      "INFO:tensorflow:training step 349 | Loss: 141.40 Examples/sec: 9829.65\n",
      "INFO:tensorflow:training step 350 | Loss: 141.18 Examples/sec: 10797.80 | Hit@1: 0.71 PERR: 0.54 GAP: 0.57\n",
      "INFO:tensorflow:training step 351 | Loss: 140.13 Examples/sec: 10938.30\n",
      "INFO:tensorflow:training step 352 | Loss: 138.35 Examples/sec: 9439.74\n",
      "INFO:tensorflow:training step 353 | Loss: 137.70 Examples/sec: 10786.98\n",
      "INFO:tensorflow:training step 354 | Loss: 135.45 Examples/sec: 8414.92\n",
      "INFO:tensorflow:training step 355 | Loss: 136.61 Examples/sec: 8485.44\n",
      "INFO:tensorflow:training step 356 | Loss: 133.77 Examples/sec: 8556.09\n",
      "INFO:tensorflow:training step 357 | Loss: 133.45 Examples/sec: 10158.87\n",
      "INFO:tensorflow:training step 358 | Loss: 132.31 Examples/sec: 9968.43\n",
      "INFO:tensorflow:training step 359 | Loss: 128.84 Examples/sec: 8627.98\n",
      "INFO:tensorflow:training step 360 | Loss: 127.16 Examples/sec: 7838.18 | Hit@1: 0.70 PERR: 0.54 GAP: 0.59\n",
      "INFO:tensorflow:training step 361 | Loss: 128.33 Examples/sec: 10029.02\n",
      "INFO:tensorflow:training step 362 | Loss: 126.94 Examples/sec: 9708.14\n",
      "INFO:tensorflow:training step 363 | Loss: 124.15 Examples/sec: 10066.30\n",
      "INFO:tensorflow:training step 364 | Loss: 126.29 Examples/sec: 10168.18\n",
      "INFO:tensorflow:training step 365 | Loss: 121.41 Examples/sec: 9967.16\n",
      "INFO:tensorflow:training step 366 | Loss: 122.28 Examples/sec: 9804.63\n",
      "INFO:tensorflow:training step 367 | Loss: 120.53 Examples/sec: 10165.77\n",
      "INFO:tensorflow:training step 368 | Loss: 119.76 Examples/sec: 9686.07\n",
      "INFO:tensorflow:training step 369 | Loss: 118.42 Examples/sec: 9731.94\n",
      "INFO:tensorflow:training step 370 | Loss: 118.32 Examples/sec: 8872.19 | Hit@1: 0.69 PERR: 0.50 GAP: 0.55\n",
      "INFO:tensorflow:training step 371 | Loss: 115.47 Examples/sec: 8774.62\n",
      "INFO:tensorflow:training step 372 | Loss: 114.69 Examples/sec: 3576.16\n",
      "INFO:tensorflow:training step 373 | Loss: 113.99 Examples/sec: 4451.56\n",
      "INFO:tensorflow:training step 374 | Loss: 114.33 Examples/sec: 3964.64\n",
      "INFO:tensorflow:training step 375 | Loss: 110.88 Examples/sec: 7081.31\n",
      "INFO:tensorflow:training step 376 | Loss: 111.52 Examples/sec: 9484.03\n",
      "INFO:tensorflow:training step 377 | Loss: 109.54 Examples/sec: 8566.67\n",
      "INFO:tensorflow:training step 378 | Loss: 109.78 Examples/sec: 8893.60\n",
      "INFO:tensorflow:training step 379 | Loss: 108.49 Examples/sec: 8417.06\n",
      "INFO:tensorflow:training step 380 | Loss: 109.68 Examples/sec: 8084.34 | Hit@1: 0.70 PERR: 0.53 GAP: 0.58\n",
      "INFO:tensorflow:training step 381 | Loss: 105.21 Examples/sec: 9974.91\n",
      "INFO:tensorflow:training step 382 | Loss: 105.67 Examples/sec: 10065.90\n",
      "INFO:tensorflow:training step 383 | Loss: 105.49 Examples/sec: 9688.49\n",
      "INFO:tensorflow:training step 384 | Loss: 104.19 Examples/sec: 9872.47\n",
      "INFO:tensorflow:training step 385 | Loss: 102.31 Examples/sec: 10648.34\n",
      "INFO:tensorflow:training step 386 | Loss: 101.45 Examples/sec: 8591.17\n",
      "INFO:tensorflow:training step 387 | Loss: 100.37 Examples/sec: 9968.38\n",
      "INFO:tensorflow:training step 388 | Loss: 100.76 Examples/sec: 9872.65\n",
      "INFO:tensorflow:training step 389 | Loss: 98.71 Examples/sec: 9970.33\n",
      "INFO:tensorflow:training step 390 | Loss: 97.88 Examples/sec: 12036.35 | Hit@1: 0.69 PERR: 0.53 GAP: 0.58\n",
      "INFO:tensorflow:training step 391 | Loss: 98.07 Examples/sec: 10165.65\n",
      "INFO:tensorflow:training step 392 | Loss: 95.22 Examples/sec: 10272.36\n",
      "INFO:tensorflow:training step 393 | Loss: 93.58 Examples/sec: 9800.78\n",
      "INFO:tensorflow:training step 394 | Loss: 92.88 Examples/sec: 8839.35\n",
      "INFO:tensorflow:training step 395 | Loss: 92.87 Examples/sec: 9778.47\n",
      "INFO:tensorflow:training step 396 | Loss: 92.86 Examples/sec: 9789.10\n",
      "INFO:tensorflow:training step 397 | Loss: 90.90 Examples/sec: 9506.81\n",
      "INFO:tensorflow:training step 398 | Loss: 91.67 Examples/sec: 10502.14\n",
      "INFO:tensorflow:training step 399 | Loss: 90.72 Examples/sec: 10110.59\n",
      "INFO:tensorflow:training step 400 | Loss: 88.23 Examples/sec: 5754.15 | Hit@1: 0.71 PERR: 0.54 GAP: 0.58\n",
      "INFO:tensorflow:training step 401 | Loss: 88.05 Examples/sec: 11125.59\n",
      "INFO:tensorflow:training step 402 | Loss: 87.47 Examples/sec: 5832.82\n",
      "INFO:tensorflow:training step 403 | Loss: 87.94 Examples/sec: 5999.24\n",
      "INFO:tensorflow:training step 404 | Loss: 86.97 Examples/sec: 6286.54\n",
      "INFO:tensorflow:training step 405 | Loss: 85.41 Examples/sec: 7814.59\n",
      "INFO:tensorflow:training step 406 | Loss: 85.53 Examples/sec: 5549.20\n",
      "INFO:tensorflow:training step 407 | Loss: 84.94 Examples/sec: 6488.81\n",
      "INFO:tensorflow:training step 408 | Loss: 82.68 Examples/sec: 5960.59\n",
      "INFO:tensorflow:training step 409 | Loss: 81.14 Examples/sec: 7945.70\n",
      "INFO:tensorflow:training step 410 | Loss: 82.13 Examples/sec: 5965.52 | Hit@1: 0.72 PERR: 0.54 GAP: 0.57\n",
      "INFO:tensorflow:training step 411 | Loss: 80.14 Examples/sec: 9983.51\n",
      "INFO:tensorflow:training step 412 | Loss: 79.51 Examples/sec: 8516.72\n",
      "INFO:tensorflow:training step 413 | Loss: 79.71 Examples/sec: 5692.11\n",
      "INFO:tensorflow:training step 414 | Loss: 78.86 Examples/sec: 7462.15\n",
      "INFO:tensorflow:training step 415 | Loss: 77.03 Examples/sec: 5702.21\n",
      "INFO:tensorflow:training step 416 | Loss: 77.36 Examples/sec: 6576.13\n",
      "INFO:tensorflow:training step 417 | Loss: 76.59 Examples/sec: 6655.20\n",
      "INFO:tensorflow:training step 418 | Loss: 76.53 Examples/sec: 5655.60\n",
      "INFO:tensorflow:training step 419 | Loss: 75.41 Examples/sec: 6289.32\n",
      "INFO:tensorflow:training step 420 | Loss: 75.17 Examples/sec: 7425.51 | Hit@1: 0.68 PERR: 0.52 GAP: 0.57\n",
      "INFO:tensorflow:training step 421 | Loss: 73.94 Examples/sec: 10593.35\n",
      "INFO:tensorflow:training step 422 | Loss: 73.93 Examples/sec: 6318.14\n",
      "INFO:tensorflow:training step 423 | Loss: 73.28 Examples/sec: 6909.64\n",
      "INFO:tensorflow:training step 424 | Loss: 72.57 Examples/sec: 6228.11\n",
      "INFO:tensorflow:training step 425 | Loss: 71.11 Examples/sec: 5914.83\n",
      "INFO:tensorflow:training step 426 | Loss: 70.46 Examples/sec: 6166.98\n",
      "INFO:tensorflow:training step 427 | Loss: 71.71 Examples/sec: 7649.35\n",
      "INFO:tensorflow:training step 428 | Loss: 69.31 Examples/sec: 6023.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:training step 429 | Loss: 69.52 Examples/sec: 5806.47\n",
      "INFO:tensorflow:training step 430 | Loss: 69.30 Examples/sec: 6311.65 | Hit@1: 0.71 PERR: 0.52 GAP: 0.58\n",
      "INFO:tensorflow:training step 431 | Loss: 68.85 Examples/sec: 10392.97\n",
      "INFO:tensorflow:training step 432 | Loss: 66.81 Examples/sec: 4142.95\n",
      "INFO:tensorflow:training step 433 | Loss: 67.95 Examples/sec: 9305.25\n",
      "INFO:tensorflow:training step 434 | Loss: 66.22 Examples/sec: 6667.54\n",
      "INFO:tensorflow:training step 435 | Loss: 64.96 Examples/sec: 7230.39\n",
      "INFO:tensorflow:training step 436 | Loss: 65.91 Examples/sec: 8703.06\n",
      "INFO:tensorflow:training step 437 | Loss: 65.62 Examples/sec: 5900.75\n",
      "INFO:tensorflow:training step 438 | Loss: 65.20 Examples/sec: 7440.11\n",
      "INFO:tensorflow:training step 439 | Loss: 63.89 Examples/sec: 5885.51\n",
      "INFO:tensorflow:training step 440 | Loss: 63.07 Examples/sec: 7055.60 | Hit@1: 0.70 PERR: 0.53 GAP: 0.58\n",
      "INFO:tensorflow:training step 441 | Loss: 62.78 Examples/sec: 9979.94\n",
      "INFO:tensorflow:training step 442 | Loss: 61.58 Examples/sec: 6135.31\n",
      "INFO:tensorflow:training step 443 | Loss: 62.13 Examples/sec: 5959.07\n",
      "INFO:tensorflow:training step 444 | Loss: 62.25 Examples/sec: 6024.14\n",
      "INFO:tensorflow:training step 445 | Loss: 61.66 Examples/sec: 7231.23\n",
      "INFO:tensorflow:training step 446 | Loss: 59.84 Examples/sec: 6075.10\n",
      "INFO:tensorflow:training step 447 | Loss: 59.96 Examples/sec: 6844.56\n",
      "INFO:tensorflow:training step 448 | Loss: 59.04 Examples/sec: 5936.68\n",
      "INFO:tensorflow:training step 449 | Loss: 59.28 Examples/sec: 7778.38\n",
      "INFO:tensorflow:training step 450 | Loss: 59.04 Examples/sec: 6079.81 | Hit@1: 0.68 PERR: 0.53 GAP: 0.58\n",
      "INFO:tensorflow:training step 451 | Loss: 59.54 Examples/sec: 9323.02\n",
      "INFO:tensorflow:training step 452 | Loss: 58.23 Examples/sec: 6320.05\n",
      "INFO:tensorflow:training step 453 | Loss: 57.69 Examples/sec: 5714.80\n",
      "INFO:tensorflow:training step 454 | Loss: 57.93 Examples/sec: 6977.27\n",
      "INFO:tensorflow:training step 455 | Loss: 56.58 Examples/sec: 7866.31\n",
      "INFO:tensorflow:training step 456 | Loss: 57.30 Examples/sec: 6624.18\n",
      "INFO:tensorflow:training step 457 | Loss: 57.44 Examples/sec: 5549.89\n",
      "INFO:tensorflow:training step 458 | Loss: 56.94 Examples/sec: 8286.87\n",
      "INFO:tensorflow:training step 459 | Loss: 56.01 Examples/sec: 6299.26\n",
      "INFO:tensorflow:training step 460 | Loss: 55.21 Examples/sec: 7416.18 | Hit@1: 0.70 PERR: 0.54 GAP: 0.59\n",
      "INFO:tensorflow:training step 461 | Loss: 55.28 Examples/sec: 9876.64\n",
      "INFO:tensorflow:training step 462 | Loss: 54.35 Examples/sec: 6040.66\n",
      "INFO:tensorflow:training step 463 | Loss: 54.46 Examples/sec: 7390.55\n",
      "INFO:tensorflow:training step 464 | Loss: 55.05 Examples/sec: 6938.02\n",
      "INFO:tensorflow:training step 465 | Loss: 53.73 Examples/sec: 8275.16\n",
      "INFO:tensorflow:training step 466 | Loss: 52.15 Examples/sec: 9145.43\n",
      "INFO:tensorflow:training step 467 | Loss: 53.12 Examples/sec: 6120.01\n",
      "INFO:tensorflow:training step 468 | Loss: 52.72 Examples/sec: 7246.20\n",
      "INFO:tensorflow:training step 469 | Loss: 52.58 Examples/sec: 6526.69\n",
      "INFO:tensorflow:training step 470 | Loss: 52.23 Examples/sec: 5748.06 | Hit@1: 0.71 PERR: 0.54 GAP: 0.59\n",
      "INFO:tensorflow:training step 471 | Loss: 51.83 Examples/sec: 10923.75\n",
      "INFO:tensorflow:training step 472 | Loss: 51.30 Examples/sec: 6645.90\n",
      "INFO:tensorflow:training step 473 | Loss: 51.74 Examples/sec: 6805.49\n",
      "INFO:tensorflow:training step 474 | Loss: 50.84 Examples/sec: 5873.39\n",
      "INFO:tensorflow:training step 475 | Loss: 50.79 Examples/sec: 6278.00\n",
      "INFO:tensorflow:training step 476 | Loss: 49.57 Examples/sec: 5897.77\n",
      "INFO:tensorflow:training step 477 | Loss: 49.13 Examples/sec: 6305.31\n",
      "INFO:tensorflow:training step 478 | Loss: 50.32 Examples/sec: 6308.21\n",
      "INFO:tensorflow:training step 479 | Loss: 49.19 Examples/sec: 6899.63\n",
      "INFO:tensorflow:training step 480 | Loss: 49.55 Examples/sec: 6650.47 | Hit@1: 0.70 PERR: 0.53 GAP: 0.57\n",
      "INFO:tensorflow:training step 481 | Loss: 49.60 Examples/sec: 13202.37\n",
      "INFO:tensorflow:training step 482 | Loss: 49.22 Examples/sec: 5597.65\n",
      "INFO:tensorflow:%s: Done training -- epoch limit reached.\n",
      "INFO:tensorflow:/job:master/task:0: Exited training loop.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"%s: Starting managed session.\", task_as_string(task))\n",
    "\n",
    "with sv.managed_session(target, config=config) as sess:\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"%s: Entering training loop.\", task_as_string(task))\n",
    "        while (not sv.should_stop()) and (not max_steps_reached):\n",
    "            batch_start_time = time.time()\n",
    "            _, global_step_val, loss_val, predictions_val, labels_val = sess.run(\n",
    "                [train_op, global_step, loss, predictions, labels])\n",
    "            seconds_per_batch = time.time() - batch_start_time\n",
    "            examples_per_second = labels_val.shape[0] / seconds_per_batch\n",
    "\n",
    "            if FLAGS.max_steps and FLAGS.max_steps <= global_step_val:\n",
    "                max_steps_reached = True\n",
    "\n",
    "            if is_master and global_step_val % 10 == 0 and FLAGS.train_dir:\n",
    "                eval_start_time = time.time()\n",
    "                hit_at_one = eval_util.calculate_hit_at_one(predictions_val, labels_val)\n",
    "                perr = eval_util.calculate_precision_at_equal_recall_rate(predictions_val,\n",
    "                                                                  labels_val)\n",
    "                gap = eval_util.calculate_gap(predictions_val, labels_val)\n",
    "                eval_end_time = time.time()\n",
    "                eval_time = eval_end_time - eval_start_time\n",
    "\n",
    "                logging.info(\"training step \" + str(global_step_val) + \" | Loss: \" + (\"%.2f\" % loss_val) +\n",
    "                             \" Examples/sec: \" + (\"%.2f\" % examples_per_second) + \" | Hit@1: \" +\n",
    "                            (\"%.2f\" % hit_at_one) + \" PERR: \" + (\"%.2f\" % perr) +\n",
    "                             \" GAP: \" + (\"%.2f\" % gap))\n",
    "\n",
    "                sv.summary_writer.add_summary(\n",
    "                    utils.MakeSummary(\"model/Training_Hit@1\", hit_at_one),\n",
    "                    global_step_val)\n",
    "                sv.summary_writer.add_summary(\n",
    "                    utils.MakeSummary(\"model/Training_Perr\", perr), global_step_val)\n",
    "                sv.summary_writer.add_summary(\n",
    "                    utils.MakeSummary(\"model/Training_GAP\", gap), global_step_val)\n",
    "                sv.summary_writer.add_summary(\n",
    "                    utils.MakeSummary(\"global_step/Examples/Second\",\n",
    "                                      examples_per_second), global_step_val)\n",
    "                sv.summary_writer.flush()\n",
    "\n",
    "                # Exporting the model every x steps\n",
    "                time_to_export = ((last_model_export_step == 0) or\n",
    "                    (global_step_val - last_model_export_step\n",
    "                     >= FLAGS.export_model_steps))\n",
    "\n",
    "                if is_master and time_to_export:\n",
    "                    export_model(global_step_val, sv.saver, sv.save_path, sess)\n",
    "                    last_model_export_step = global_step_val\n",
    "            else:\n",
    "                logging.info(\"training step \" + str(global_step_val) + \" | Loss: \" +\n",
    "                            (\"%.2f\" % loss_val) + \" Examples/sec: \" + (\"%.2f\" % examples_per_second))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        logging.info(\"%s: Done training -- epoch limit reached.\")\n",
    "\n",
    "logging.info(\"%s: Exited training loop.\", task_as_string(task))\n",
    "sv.Stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models\\model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path models\\model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 10.\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "with sv.managed_session(target, config=config) as sess:\n",
    "    while (not sv.should_stop()) and (not max_steps_reached):\n",
    "        batch_start_time = time.time()\n",
    "        _, global_step_val, loss_val, predictions_val, labels_val = sess.run(\n",
    "        [train_op, global_step, loss, predictions, labels])\n",
    "        print(labels_val[0][0])\n",
    "        #print(predictions_val[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
