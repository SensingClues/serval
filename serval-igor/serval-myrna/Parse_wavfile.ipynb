{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "## Import packages\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import vggish_input\n",
    "import vggish_postprocess\n",
    "import vggish_params\n",
    "import vggish_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'wav_file', 'gunshots/shot distance9mm.06.wav',\n",
    "    'Path to a wav file. Should contain signed 16-bit PCM samples.')\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'pca_params', 'yt8m/vggish_pca_params.npz',\n",
    "    'Path to the VGGish PCA parameters file.')\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'checkpoint', 'yt8m/vggish_model.ckpt',\n",
    "    'Path to the VGGish checkpoint file.')\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    'labels_csv', 'csv_files/class_labels_indices_amsterdam.csv',\n",
    "    'Path to the VGGish checkpoint file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ik verdeel het parsen van een wav-file naar embeddings in stappen:\n",
    "# Stap 1a: lezen van wav-file, input is array met samples die db aanduiden. Ook sample rate (per sec) wordt gelezen\n",
    "# Stap 1b: Bij 2d array (stereo, ipv mono) bereken gemiddelde, daarna normaliseren (delen door 32.768)\n",
    "# Stap 2: Bepaal examples in vorm [batch size, num frames, num bands].\n",
    "    # Hierbij worden voor verschillende batches (omdat alles tegelijk niet in 1x in NN kan),\n",
    "    # een log mel spectrogram gemaakt (in vorm [num_frames, num_bands])\n",
    "# Stap 3: Bepaal features: nu wordt de embedding laag gemaakt (PCA-components, discreet maken etc)\n",
    "    # Hiervoor worden model-parameters opgehaald die eerder zijn opgeslagen\n",
    "# Stap 4: Maken van predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 96, 64)\n"
     ]
    }
   ],
   "source": [
    "## Stap 1 en 2\n",
    "## This function reads the wav file and converts the samples into np arrays of [batch size, num frames, num bands]\n",
    "examples_batch = vggish_input.wavfile_to_examples(FLAGS.wav_file)\n",
    "print(examples_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read csv-file with labels\n",
    "class_map = {}\n",
    "with open(FLAGS.labels_csv) as f:\n",
    "    next(f)  # skip header\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        class_map[int(row[0])] = row[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from yt8m/vggish_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/model.ckpt-10\n"
     ]
    }
   ],
   "source": [
    "## Stap 3\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    # Define the model: load the checkpoint and locate input and output tensors\n",
    "    # Input: [batch_size, num_frames, num_bands] \n",
    "    # where [num_frames, num_bands] represents log-mel-scale spectrogram\n",
    "    # Output: embeddings\n",
    "    vggish_slim.define_vggish_slim(training=False)\n",
    "    vggish_slim.load_vggish_slim_checkpoint(sess, FLAGS.checkpoint)\n",
    "    \n",
    "    pca_params = np.load(vggish_params.VGGISH_PCA_PARAMS)\n",
    "    pca_matrix = pca_params[vggish_params.PCA_EIGEN_VECTORS_NAME]\n",
    "    pca_means = pca_params[vggish_params.PCA_MEANS_NAME].reshape(-1, 1)\n",
    "    \n",
    "    features_tensor = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.VGGISH_INPUT_TENSOR_NAME)\n",
    "    embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.VGGISH_OUTPUT_TENSOR_NAME)\n",
    "    vggish_slim.load_youtube_model(sess, vggish_params.YOUTUBE_CHECKPOINT_FILE)\n",
    "    \n",
    "    # Run inference and postprocessing\n",
    "    [embedding_batch] = sess.run([embedding_tensor],\n",
    "                                 feed_dict={features_tensor: examples_batch})\n",
    "    \n",
    "    postprocessed_batch = np.dot(\n",
    "            pca_matrix, (embedding_batch.T - pca_means)\n",
    "        ).T\n",
    "    #print(postprocessed_batch)\n",
    "    \n",
    "    num_frames = np.minimum(postprocessed_batch.shape[0], vggish_params.MAX_FRAMES)\n",
    "    data = vggish_postprocess.resize(postprocessed_batch, 0, vggish_params.MAX_FRAMES)\n",
    "    data = np.expand_dims(data, 0)\n",
    "    num_frames = np.expand_dims(num_frames, 0)\n",
    "    \n",
    "    input_tensor = sess.graph.get_collection(\"input_batch_raw\")[0]\n",
    "    num_frames_tensor = sess.graph.get_collection(\"num_frames\")[0]\n",
    "    predictions_tensor = sess.graph.get_collection(\"predictions\")[0]\n",
    "    \n",
    "    ## Stap 4\n",
    "    predictions_val, = sess.run(\n",
    "        [predictions_tensor],\n",
    "        feed_dict={\n",
    "            input_tensor: data,\n",
    "            num_frames_tensor: num_frames\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter predictions (give top 20 where p>0.1)\n",
    "count = vggish_params.PREDICTIONS_COUNT_LIMIT\n",
    "hit = vggish_params.PREDICTIONS_HIT_LIMIT\n",
    "top_indices = np.argpartition(predictions_val[0], -count)[-count:]\n",
    "line = ((class_map[i], float(predictions_val[0][i])) for i in top_indices if predictions_val[0][i] > hit)\n",
    "predictions = sorted(line, key=lambda p: -p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Speech', 0.5116356611251831), ('Vehicle', 0.4994502067565918), ('Chainsaw', 0.49377644062042236), ('Fire engine, fire truck (siren)', 0.4823319911956787), ('Emergency vehicle', 0.4716338515281677), ('Gunshot, gunfire', 0.46738359332084656), ('Conversation', 0.46571311354637146), ('Bus', 0.45601096749305725), ('Music', 0.45590341091156006), ('Musical instrument', 0.4550531804561615), ('Machine gun', 0.4535888135433197), ('Animal', 0.4528081715106964), ('Rail transport', 0.4503600597381592), ('Boat, Water vehicle', 0.44966498017311096), ('Ambulance (siren)', 0.4442861080169678), ('Heavy engine (low frequency)', 0.44366976618766785), ('Traffic noise, roadway noise', 0.4432307779788971), ('Motor vehicle (road)', 0.44180065393447876), ('Tools', 0.4417493939399719), ('Power tool', 0.4417246878147125)]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
