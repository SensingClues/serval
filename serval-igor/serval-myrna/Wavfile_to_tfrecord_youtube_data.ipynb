{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "## Import packages\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import gfile\n",
    "from tensorflow import logging\n",
    "\n",
    "import vggish_input\n",
    "import vggish_postprocess\n",
    "import vggish_params\n",
    "import vggish_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters voor het maken van tf-records\n",
    "audio_embedding_feature_name = 'audio_embedding'\n",
    "pca_params = 'models/vggish_pca_params.npz'\n",
    "checkpoint = 'models/vggish_model.ckpt'\n",
    "yt_checkpoint = 'models/youtube_model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lees alle csv-files in\n",
    "bal_labels = pd.read_csv('csv_files/balanced_train_segments.csv', skiprows=3, \n",
    "                         quotechar='\"', skipinitialspace = True, header=None, \n",
    "                         names = [\"YTID\", \"start_seconds\", \"end_seconds\", \"positive_labels\"])\n",
    "\n",
    "unbal_labels = pd.read_csv('csv_files/unbalanced_train_segments.csv', skiprows=3, \n",
    "                         quotechar='\"', skipinitialspace = True, header=None, \n",
    "                         names = [\"YTID\", \"start_seconds\", \"end_seconds\", \"positive_labels\"])\n",
    "\n",
    "eval_labels = pd.read_csv('csv_files/eval_segments.csv', skiprows=3, \n",
    "                         quotechar='\"', skipinitialspace = True, header=None, \n",
    "                         names = [\"YTID\", \"start_seconds\", \"end_seconds\", \"positive_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map waarin yt-wavjes staan\n",
    "wavfile_path = \"wav_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Geef aan of de tf-records voor jungle of urban moeten worden gedownload (ik neem aan dat we alleen jungle doen)\n",
    "target = \"jungle\" #\"urban\"\n",
    "mid_to_label = pd.read_csv(\"csv_files/class_labels_indices_\" + target + \"_prop.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## embeddings komen nu in 1 groot tf-record te staan\n",
    "## We kunnen ook een counter maken: na elke 1000, maak nieuwe tf-record\n",
    "tfrecord_path = \"tfrecords/added_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Houd aantal samples bij\n",
    "nr_samples = 0\n",
    "\n",
    "## Lijst van alle labels (nieuwe) en alle combi's\n",
    "all_labels = []\n",
    "\n",
    "## Proportie train/test\n",
    "pct_train = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Voor alle wav-files in een map, gebeurt het volgende:\n",
    "\n",
    "## Eerst wordt het wav-file ingelezen en de bijbehorende label(s) opgezocht in een csv-bestand\n",
    "## Als video-id wordt een willekeurig id'tje gegeven (in dit geval allemaal dezelfde)\n",
    "\n",
    "## Dan parsen we wav-file naar embeddings: \n",
    "# (dit gebeurt door vggish_input.wavfile_to_example aan te roepen)\n",
    "# Stap 1a: lezen van wav-file, input is array met samples die db aanduiden. Ook sample rate (per sec) wordt gelezen\n",
    "# Stap 1b: Bij 2d array (stereo, ipv mono) bereken gemiddelde, daarna normaliseren (delen door 32.768)\n",
    "# Stap 2: Bepaal examples in vorm [batch size, num frames, num bands].\n",
    "    # Hierbij worden voor verschillende batches (omdat alles tegelijk niet in 1x in NN kan),\n",
    "    # een log mel spectrogram gemaakt (in vorm [num_frames, num_bands])\n",
    "# Stap 3: Bepaal features: nu wordt de embedding laag gemaakt (PCA-components, discreet maken etc)\n",
    "    # Hiervoor worden model-parameters opgehaald die eerder zijn opgeslagen\n",
    "    \n",
    "## Daarna wordt een sequence example gemaakt (in getSequenceExample) en het als tf-records weggeschreven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Function that takes examples from wav-file as input and returns a sequence example\n",
    "\n",
    "def getSequenceExample(examples_batch, labels, video_id=[b'-1LrH01Ei1w']):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "\n",
    "        # Prepare a postprocessor to munge the model embeddings.\n",
    "        pproc = vggish_postprocess.Postprocessor(pca_params)\n",
    "    \n",
    "        # Define the model: load the checkpoint and locate input and output tensors\n",
    "        # Input: [batch_size, num_frames, num_bands] \n",
    "        # where [num_frames, num_bands] represents log-mel-scale spectrogram\n",
    "        # Output: embeddings\n",
    "        vggish_slim.define_vggish_slim(training=False)\n",
    "        vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint)\n",
    "\n",
    "        features_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.VGGISH_INPUT_TENSOR_NAME)\n",
    "        embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.VGGISH_OUTPUT_TENSOR_NAME)\n",
    "        \n",
    "        # Run inference and postprocessing.\n",
    "        [embedding_batch] = sess.run([embedding_tensor],\n",
    "                                     feed_dict={features_tensor: examples_batch})\n",
    "        print(embedding_batch.shape)\n",
    "        \n",
    "        postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "        #print(postprocessed_batch)\n",
    "\n",
    "\n",
    "        ## Maak labels en video-id voor in de example\n",
    "        label_feat = tf.train.Feature(int64_list=tf.train.Int64List(value=labels))\n",
    "        videoid_feat = tf.train.Feature(bytes_list=tf.train.BytesList(value=video_id))\n",
    "        \n",
    "        ## Maak sequence example\n",
    "        seq_example = tf.train.SequenceExample(\n",
    "            context = tf.train.Features(feature={\"labels\": label_feat, \"video_id\": videoid_feat}),\n",
    "            feature_lists = tf.train.FeatureLists(\n",
    "                feature_list={\n",
    "                    audio_embedding_feature_name:\n",
    "                        tf.train.FeatureList(\n",
    "                            feature=[\n",
    "                                tf.train.Feature(\n",
    "                                    bytes_list=tf.train.BytesList(\n",
    "                                        value=[embedding.tobytes()]))\n",
    "                                for embedding in postprocessed_batch\n",
    "                            ]\n",
    "                        )\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return(seq_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deze functie checkt of een example wordt gemaakt (downsamplen)\n",
    "def checkIfNewExample(labels):\n",
    "    \n",
    "    ## Alleen bij 1 label worden er examples overgeslagen (of bij write_all_examples)\n",
    "    if(len(labels)>1):\n",
    "        return True\n",
    "    else:\n",
    "        label = list(labels)[0]\n",
    "        prop = mid_to_label.loc[mid_to_label['index']==np.int(label), \"target_ind\"].values[0]\n",
    "        rand = random.random()\n",
    "        ## Als random niet proportie overschrijdt, return true\n",
    "        if rand <= prop:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deze functie checkt of er nog een example moet worden gemaakt (upsamplen)\n",
    "## Momenteel kan het aantal enkel verdubbeld worden\n",
    "\n",
    "def checkIfExtraExample(labels):\n",
    "    \n",
    "    ## Alleen bij 1 label worden er examples gekopieerd (of als er niet (up)gesampled wordt)\n",
    "    if(len(labels)>1):\n",
    "        return False\n",
    "    else:\n",
    "        label = list(labels)[0]\n",
    "        prop = mid_to_label.loc[mid_to_label['index']==np.int(label), \"target_ind\"].values[0]-1\n",
    "        rand = random.random()\n",
    "        ## Als random niet proportie overschrijdt, return true\n",
    "        if rand <= prop:    \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(mid_str):\n",
    "    ## Maak lijst van m-id's\n",
    "    mid_list = mid_str.split(',')\n",
    "    labels = []\n",
    "    \n",
    "    ## Voor elk m-id, vind labels, (if any labels: add to label list)\n",
    "    for mid in mid_list:\n",
    "        if (mid_to_label.loc[mid_to_label[\"mid\"] == mid, \"mid\"].any()):\n",
    "            labels.append(mid_to_label.loc[mid_to_label[\"mid\"] == mid, \"index\"].values[0])\n",
    "    \n",
    "    ## Return unique set of labels\n",
    "    return set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readWav(vid_to_mid, dataset):\n",
    "    \n",
    "    train_tfrecord = str(tfrecord_path + dataset + '_train.tfrecord')\n",
    "    test_tfrecord = str(tfrecord_path + dataset + '_test.tfrecord')\n",
    "    \n",
    "    train_writer = tf.python_io.TFRecordWriter(train_tfrecord)\n",
    "    test_writer = tf.python_io.TFRecordWriter(test_tfrecord)\n",
    "    \n",
    "    ## Read and rewrite all test files\n",
    "    files = gfile.Glob(str(wavfile_path + \"/\" + dataset + \"/*.wav\"))\n",
    "  \n",
    "    count=0\n",
    "    for file in files:\n",
    "    \n",
    "        count+=1\n",
    "        print(\"file nr: \" + str(count))\n",
    "        filename = file.split(\"\\\\\")[-1]\n",
    "        print(\"Filename: \" + filename)\n",
    "        filename = filename[0:-4]\n",
    "        ytid = filename.split(\"_^_\")[0]\n",
    "        print(\"ytid: \" + str(ytid))\n",
    "        start = filename.split(\"_^_\")[1]\n",
    "        print(\"start: \" + str(start))\n",
    "        \n",
    "        ## Vind bijbehorende m-ids\n",
    "        mids = vid_to_mid.loc[vid_to_mid[\"YTID\"] == ytid, \"positive_labels\"].values[0]\n",
    "        print(mids)\n",
    "        new_labels = getLabels(mids)\n",
    "        print(new_labels)\n",
    "        print('SFASFASF')\n",
    "        ## This function reads the wav file and converts the samples into np arrays of [batch size, num frames, num bands]\n",
    "        #examples_batch = vggish_input.wavfile_to_examples(str(wavfile_path + wav_file))\n",
    "        examples_batch = vggish_input.wavfile_to_examples(file)\n",
    "\n",
    "        ## Bij meer dan 10 sec: neem middelste 10 sec\n",
    "        print(\"check te veel sec\")\n",
    "        if(examples_batch.shape[0]>10):\n",
    "            nr_sec = examples_batch.shape[0]\n",
    "            start = int(math.floor((nr_sec-10)/2))\n",
    "            end = int(nr_sec-math.ceil((nr_sec-10)/2))\n",
    "            examples_batch = examples_batch[start:end, :, :]\n",
    "\n",
    "        ## Schrijf alleen bij meer dan 5 sec\n",
    "        ## Check if new example: voor downsamplen\n",
    "        print(\"check if write example\")\n",
    "        if(examples_batch.shape[0]>5 and checkIfNewExample(new_labels)):\n",
    "\n",
    "            all_labels.extend(new_labels)\n",
    "            \n",
    "            seq_example = getSequenceExample(examples_batch, new_labels)\n",
    "\n",
    "            rand = random.random()\n",
    "            if rand <= pct_train:\n",
    "                train_writer.write(seq_example.SerializeToString())\n",
    "            else:\n",
    "                test_writer.write(seq_example.SerializeToString())\n",
    "\n",
    "            ## Voor upsamplen\n",
    "            print(\"upsamplen\")\n",
    "            if(checkIfExtraExample(new_labels)):\n",
    "                rand = random.random()\n",
    "                if rand <= pct_train:\n",
    "                    train_writer.write(seq_example.SerializeToString())\n",
    "                else:\n",
    "                    eval_writer.write(seq_example.SerializeToString())\n",
    "                \n",
    "                all_labels.extend(new_labels)\n",
    "                \n",
    "        train_writer.close()\n",
    "    test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file nr: 1\n",
      "Filename: --aaILOrkII_^_200.000.wav\n",
      "ytid: --aaILOrkII\n",
      "start: 200.000\n",
      "/m/032s66,/m/073cg4\n",
      "{3}\n",
      "check te veel sec\n",
      "check if write example\n",
      "A\n",
      "INFO:tensorflow:Restoring parameters from models/vggish_model.ckpt\n",
      "B\n",
      "C\n",
      "(10, 128)\n",
      "*****************************************************************\n",
      "D\n",
      "upsamplen\n",
      "file nr: 2\n",
      "Filename: --aO5cdqSAg_^_30.000.wav\n",
      "ytid: --aO5cdqSAg\n",
      "start: 30.000\n",
      "/t/dd00003,/t/dd00005\n",
      "{5}\n"
     ]
    }
   ],
   "source": [
    "readWav(bal_labels, \"bal\")\n",
    "#readWav(unbal_labels, \"unbal\")\n",
    "#readWav(eval_labels, \"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"nr samples: \" + str(nr_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Print voor alle labels het aantal voorkomens in de nieuwe tf-records\n",
    "\n",
    "sum_occur = 0\n",
    "cnt_labels = Counter(all_labels)\n",
    "\n",
    "for i in cnt_labels.most_common(100):\n",
    "    sum_occur = sum_occur + i[1]\n",
    "    print(label_proportions.loc[label_proportions['index']==i[0]]['display_name'].values[0], ' : ', str(i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
