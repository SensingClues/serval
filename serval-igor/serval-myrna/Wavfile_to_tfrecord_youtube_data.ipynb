{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "## Import packages\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import gfile\n",
    "from tensorflow import logging\n",
    "\n",
    "import vggish_input\n",
    "import vggish_postprocess\n",
    "import vggish_params\n",
    "import vggish_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp imports\n",
    "#import resampy\n",
    "import samplerate\n",
    "import mel_features\n",
    "import vggish_params\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavfile_to_examples(wav_file):\n",
    "  \"\"\"Convenience wrapper around waveform_to_examples() for a common WAV format.\n",
    "  Args:\n",
    "    wav_file: String path to a file, or a file-like object. The file\n",
    "    is assumed to contain WAV audio data with signed 16-bit PCM samples.\n",
    "  Returns:\n",
    "    See waveform_to_examples.\n",
    "  \"\"\"\n",
    "  sr, wav_data = wavfile.read(wav_file)\n",
    "  print(\"wavfile gelezen\")\n",
    "  assert wav_data.dtype == np.int16, 'Bad sample type: %r' % wav_data.dtype\n",
    "  samples = wav_data / 32768.0  # Convert to [-1.0, +1.0]\n",
    "  log_mel_examples = waveform_to_examples(samples, sr)\n",
    "  return log_mel_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveform_to_examples(data, sample_rate):\n",
    "  \"\"\"Converts audio waveform into an array of examples for VGGish.\n",
    "  Args:\n",
    "    data: np.array of either one dimension (mono) or two dimensions\n",
    "      (multi-channel, with the outer dimension representing channels).\n",
    "      Each sample is generally expected to lie in the range [-1.0, +1.0],\n",
    "      although this is not required.\n",
    "    sample_rate: Sample rate of data.\n",
    "  Returns:\n",
    "    3-D np.array of shape [num_examples, num_frames, num_bands] which represents\n",
    "    a sequence of examples, each of which contains a patch of log mel\n",
    "    spectrogram, covering num_frames frames of audio and num_bands mel frequency\n",
    "    bands, where the frame length is vggish_params.STFT_HOP_LENGTH_SECONDS.\n",
    "  \"\"\"\n",
    "  print(\"sr: \" + str(sample_rate))\n",
    "  # Convert to mono.\n",
    "  if len(data.shape) > 1:\n",
    "    data = np.mean(data, axis=1)\n",
    "  print(\"shape = 1\")\n",
    "  # Resample to the rate assumed by VGGish.\n",
    "  if sample_rate != vggish_params.SAMPLE_RATE:\n",
    "    #data = resampy.resample(data, sample_rate, vggish_params.SAMPLE_RATE)\n",
    "    ratio=vggish_params.SAMPLE_RATE/sample_rate #output/input rate\n",
    "    converter = 'sinc_best' # 'sinc_best' or 'sinc_fastest'\n",
    "    data = samplerate.resample(data, ratio, converter, False)\n",
    "    \n",
    "  print(\"sample rate klopt\")\n",
    "  # Compute log mel spectrogram features.\n",
    "  log_mel = mel_features.log_mel_spectrogram(\n",
    "      data,\n",
    "      audio_sample_rate=vggish_params.SAMPLE_RATE,\n",
    "      log_offset=vggish_params.LOG_OFFSET,\n",
    "      window_length_secs=vggish_params.STFT_WINDOW_LENGTH_SECONDS,\n",
    "      hop_length_secs=vggish_params.STFT_HOP_LENGTH_SECONDS,\n",
    "      num_mel_bins=vggish_params.NUM_MEL_BINS,\n",
    "      lower_edge_hertz=vggish_params.MEL_MIN_HZ,\n",
    "      upper_edge_hertz=vggish_params.MEL_MAX_HZ)\n",
    "\n",
    "  # Frame features into examples.\n",
    "  features_sample_rate = 1.0 / vggish_params.STFT_HOP_LENGTH_SECONDS\n",
    "  example_window_length = int(round(\n",
    "      vggish_params.EXAMPLE_WINDOW_SECONDS * features_sample_rate))\n",
    "  example_hop_length = int(round(\n",
    "      vggish_params.EXAMPLE_HOP_SECONDS * features_sample_rate))\n",
    "  log_mel_examples = mel_features.frame(\n",
    "      log_mel,\n",
    "      window_length=example_window_length,\n",
    "      hop_length=example_hop_length)\n",
    "  return log_mel_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters voor het maken van tf-records\n",
    "audio_embedding_feature_name = 'audio_embedding'\n",
    "pca_params = 'models/vggish_pca_params.npz'\n",
    "checkpoint = 'models/vggish_model.ckpt'\n",
    "yt_checkpoint = 'models/youtube_model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lees alle csv-files in\n",
    "bal_labels = pd.read_csv('csv_files/balanced_train_segments.csv', skiprows=3, \n",
    "                         quotechar='\"', skipinitialspace = True, header=None, \n",
    "                         names = [\"YTID\", \"start_seconds\", \"end_seconds\", \"positive_labels\"])\n",
    "\n",
    "unbal_labels = pd.read_csv('csv_files/unbalanced_train_segments.csv', skiprows=3, \n",
    "                         quotechar='\"', skipinitialspace = True, header=None, \n",
    "                         names = [\"YTID\", \"start_seconds\", \"end_seconds\", \"positive_labels\"])\n",
    "\n",
    "eval_labels = pd.read_csv('csv_files/eval_segments.csv', skiprows=3, \n",
    "                         quotechar='\"', skipinitialspace = True, header=None, \n",
    "                         names = [\"YTID\", \"start_seconds\", \"end_seconds\", \"positive_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map waarin yt-wavjes staan\n",
    "wavfile_path = \"wav_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Geef aan of de tf-records voor jungle of urban moeten worden gedownload (ik neem aan dat we alleen jungle doen)\n",
    "target = \"jungle\" #\"urban\"\n",
    "mid_to_label = pd.read_csv(\"csv_files/class_labels_indices_\" + target + \"_prop.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## embeddings komen nu in 1 groot tf-record te staan\n",
    "## We kunnen ook een counter maken: na elke 1000, maak nieuwe tf-record\n",
    "tfrecord_path = \"tfrecords/added_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Houd aantal samples bij\n",
    "nr_samples = 0\n",
    "\n",
    "## Lijst van alle labels (nieuwe) en alle combi's\n",
    "all_labels = []\n",
    "\n",
    "## Proportie train/test\n",
    "pct_train = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Voor alle wav-files in een map, gebeurt het volgende:\n",
    "\n",
    "## Eerst wordt het wav-file ingelezen en de bijbehorende label(s) opgezocht in een csv-bestand\n",
    "## Als video-id wordt een willekeurig id'tje gegeven (in dit geval allemaal dezelfde)\n",
    "\n",
    "## Dan parsen we wav-file naar embeddings: \n",
    "# (dit gebeurt door vggish_input.wavfile_to_example aan te roepen)\n",
    "# Stap 1a: lezen van wav-file, input is array met samples die db aanduiden. Ook sample rate (per sec) wordt gelezen\n",
    "# Stap 1b: Bij 2d array (stereo, ipv mono) bereken gemiddelde, daarna normaliseren (delen door 32.768)\n",
    "# Stap 2: Bepaal examples in vorm [batch size, num frames, num bands].\n",
    "    # Hierbij worden voor verschillende batches (omdat alles tegelijk niet in 1x in NN kan),\n",
    "    # een log mel spectrogram gemaakt (in vorm [num_frames, num_bands])\n",
    "# Stap 3: Bepaal features: nu wordt de embedding laag gemaakt (PCA-components, discreet maken etc)\n",
    "    # Hiervoor worden model-parameters opgehaald die eerder zijn opgeslagen\n",
    "    \n",
    "## Daarna wordt een sequence example gemaakt (in getSequenceExample) en het als tf-records weggeschreven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Function that takes examples from wav-file as input and returns a sequence example\n",
    "\n",
    "def getSequenceExample(examples_batch, labels, video_id=[b'-1LrH01Ei1w']):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "\n",
    "        # Prepare a postprocessor to munge the model embeddings.\n",
    "        pproc = vggish_postprocess.Postprocessor(pca_params)\n",
    "    \n",
    "        # Define the model: load the checkpoint and locate input and output tensors\n",
    "        # Input: [batch_size, num_frames, num_bands] \n",
    "        # where [num_frames, num_bands] represents log-mel-scale spectrogram\n",
    "        # Output: embeddings\n",
    "        vggish_slim.define_vggish_slim(training=False)\n",
    "        vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint)\n",
    "\n",
    "        features_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.VGGISH_INPUT_TENSOR_NAME)\n",
    "        embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "            vggish_params.VGGISH_OUTPUT_TENSOR_NAME)\n",
    "        \n",
    "        # Run inference and postprocessing.\n",
    "        [embedding_batch] = sess.run([embedding_tensor],\n",
    "                                     feed_dict={features_tensor: examples_batch})\n",
    "        print(embedding_batch.shape)\n",
    "        \n",
    "        postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "        #print(postprocessed_batch)\n",
    "\n",
    "\n",
    "        ## Maak labels en video-id voor in de example\n",
    "        label_feat = tf.train.Feature(int64_list=tf.train.Int64List(value=labels))\n",
    "        videoid_feat = tf.train.Feature(bytes_list=tf.train.BytesList(value=video_id))\n",
    "        \n",
    "        ## Maak sequence example\n",
    "        seq_example = tf.train.SequenceExample(\n",
    "            context = tf.train.Features(feature={\"labels\": label_feat, \"video_id\": videoid_feat}),\n",
    "            feature_lists = tf.train.FeatureLists(\n",
    "                feature_list={\n",
    "                    audio_embedding_feature_name:\n",
    "                        tf.train.FeatureList(\n",
    "                            feature=[\n",
    "                                tf.train.Feature(\n",
    "                                    bytes_list=tf.train.BytesList(\n",
    "                                        value=[embedding.tobytes()]))\n",
    "                                for embedding in postprocessed_batch\n",
    "                            ]\n",
    "                        )\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return(seq_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deze functie checkt of een example wordt gemaakt (downsamplen)\n",
    "def checkIfNewExample(labels):\n",
    "    \n",
    "    ## Alleen bij 1 label worden er examples overgeslagen (of bij write_all_examples)\n",
    "    if(len(labels)>1):\n",
    "        return True\n",
    "    else:\n",
    "        label = list(labels)[0]\n",
    "        prop = mid_to_label.loc[mid_to_label['index']==np.int(label), \"target_ind\"].values[0]\n",
    "        rand = random.random()\n",
    "        ## Als random niet proportie overschrijdt, return true\n",
    "        if rand <= prop:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deze functie checkt of er nog een example moet worden gemaakt (upsamplen)\n",
    "## Momenteel kan het aantal enkel verdubbeld worden\n",
    "\n",
    "def checkIfExtraExample(labels):\n",
    "    \n",
    "    ## Alleen bij 1 label worden er examples gekopieerd (of als er niet (up)gesampled wordt)\n",
    "    if(len(labels)>1):\n",
    "        return False\n",
    "    else:\n",
    "        label = list(labels)[0]\n",
    "        prop = mid_to_label.loc[mid_to_label['index']==np.int(label), \"target_ind\"].values[0]-1\n",
    "        rand = random.random()\n",
    "        ## Als random niet proportie overschrijdt, return true\n",
    "        if rand <= prop:    \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(mid_str):\n",
    "    ## Maak lijst van m-id's\n",
    "    mid_list = mid_str.split(',')\n",
    "    labels = []\n",
    "    \n",
    "    ## Voor elk m-id, vind labels, (if any labels: add to label list)\n",
    "    for mid in mid_list:\n",
    "        if (mid_to_label.loc[mid_to_label[\"mid\"] == mid, \"mid\"].any()):\n",
    "            labels.append(mid_to_label.loc[mid_to_label[\"mid\"] == mid, \"index\"].values[0])\n",
    "    \n",
    "    ## Return unique set of labels\n",
    "    return set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readWav(vid_to_mid, dataset):\n",
    "    \n",
    "    train_tfrecord = str(tfrecord_path + dataset + '_train.tfrecord')\n",
    "    test_tfrecord = str(tfrecord_path + dataset + '_test.tfrecord')\n",
    "    \n",
    "    train_writer = tf.python_io.TFRecordWriter(train_tfrecord)\n",
    "    test_writer = tf.python_io.TFRecordWriter(test_tfrecord)\n",
    "    \n",
    "    ## Read and rewrite all test files\n",
    "    files = gfile.Glob(str(wavfile_path + \"/\" + dataset + \"/*.wav\"))\n",
    "  \n",
    "    count=0\n",
    "    for file in files:\n",
    "    \n",
    "        count+=1\n",
    "        print(\"\\nfile nr: \" + str(count))\n",
    "        filename = file.split(\"\\\\\")[-1]\n",
    "        print(\"Filename: \" + filename)\n",
    "        filename = filename[0:-4]\n",
    "        ytid = filename.split(\"_^_\")[0]\n",
    "        print(\"ytid: \" + str(ytid))\n",
    "        start = filename.split(\"_^_\")[1]\n",
    "        print(\"start: \" + str(start))\n",
    "        \n",
    "        ## Vind bijbehorende m-ids\n",
    "        mids = vid_to_mid.loc[vid_to_mid[\"YTID\"] == ytid, \"positive_labels\"].values[0]\n",
    "        print('test - mids: ' + str(mids))\n",
    "        new_labels = getLabels(mids)\n",
    "        print('test - labels:' + str(new_labels))\n",
    "        \n",
    "        # check duration>0\n",
    "        f = wave.open(file)\n",
    "        frames = f.getnframes()\n",
    "        rate = f.getframerate()\n",
    "        duration = frames / float(rate)\n",
    "        print('test - duration: ' + str(duration))\n",
    "        f.close()\n",
    "        \n",
    "        if(duration>0):\n",
    "            ## This function reads the wav file and converts the samples into np arrays of [batch size, num frames, num bands]\n",
    "            #examples_batch = vggish_input.wavfile_to_examples(str(wavfile_path + wav_file))\n",
    "            #examples_batch = vggish_input.wavfile_to_examples(file)\n",
    "            examples_batch = wavfile_to_examples(file)\n",
    "\n",
    "            ## Bij meer dan 10 sec: neem middelste 10 sec\n",
    "            print(\"test - check: seconds\")\n",
    "            if(examples_batch.shape[0]>10):\n",
    "                nr_sec = examples_batch.shape[0]\n",
    "                start = int(math.floor((nr_sec-10)/2))\n",
    "                end = int(nr_sec-math.ceil((nr_sec-10)/2))\n",
    "                examples_batch = examples_batch[start:end, :, :]\n",
    "\n",
    "            ## Schrijf alleen bij meer dan 5 sec\n",
    "            ## Check if new example: voor downsamplen\n",
    "            print(\"check: write example\")\n",
    "            if(examples_batch.shape[0]>5 and checkIfNewExample(new_labels)):\n",
    "\n",
    "                all_labels.extend(new_labels)\n",
    "\n",
    "                seq_example = getSequenceExample(examples_batch, new_labels)\n",
    "\n",
    "                rand = random.random()\n",
    "                if rand <= pct_train:\n",
    "                    train_writer.write(seq_example.SerializeToString())\n",
    "                else:\n",
    "                    test_writer.write(seq_example.SerializeToString())\n",
    "\n",
    "                ## Voor upsamplen\n",
    "                print(\"check: upsamplen\")\n",
    "                if(checkIfExtraExample(new_labels)):\n",
    "                    rand = random.random()\n",
    "                    if rand <= pct_train:\n",
    "                        train_writer.write(seq_example.SerializeToString())\n",
    "                    else:\n",
    "                        test_writer.write(seq_example.SerializeToString())\n",
    "\n",
    "                    all_labels.extend(new_labels)\n",
    "                \n",
    "    train_writer.close()\n",
    "    test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "file nr: 1\n",
      "Filename: --aaILOrkII_^_200.000.wav\n",
      "ytid: --aaILOrkII\n",
      "start: 200.000\n",
      "test - mids: /m/032s66,/m/073cg4\n",
      "test - labels:{3}\n",
      "test - duration: 10.0\n",
      "wavfile gelezen\n",
      "sr: 44100\n",
      "shape = 1\n",
      "sample rate klopt\n",
      "test - check: seconds\n",
      "check: write example\n",
      "\n",
      "file nr: 2\n",
      "Filename: --aO5cdqSAg_^_30.000.wav\n",
      "ytid: --aO5cdqSAg\n",
      "start: 30.000\n",
      "test - mids: /t/dd00003,/t/dd00005\n",
      "test - labels:{5}\n",
      "test - duration: 10.0\n",
      "wavfile gelezen\n",
      "sr: 44100\n",
      "shape = 1\n",
      "sample rate klopt\n",
      "test - check: seconds\n",
      "check: write example\n",
      "\n",
      "file nr: 3\n",
      "Filename: -24dqQM_rDk_^_30.000.wav\n",
      "ytid: -24dqQM_rDk\n",
      "start: 30.000\n",
      "test - mids: /m/04rlf,/t/dd00003\n",
      "test - labels:{5}\n",
      "test - duration: 10.0\n",
      "wavfile gelezen\n",
      "sr: 44100\n",
      "shape = 1\n",
      "sample rate klopt\n",
      "test - check: seconds\n",
      "check: write example\n",
      "\n",
      "file nr: 4\n",
      "Filename: -3IGxVTJvgI_^_30.000.wav\n",
      "ytid: -3IGxVTJvgI\n",
      "start: 30.000\n",
      "test - mids: /m/06bz3,/m/09x0r\n",
      "test - labels:{7}\n",
      "test - duration: 0.0\n",
      "\n",
      "file nr: 5\n",
      "Filename: -60XojQWWoc_^_30.000.wav\n",
      "ytid: -60XojQWWoc\n",
      "start: 30.000\n",
      "test - mids: /m/02rhddq,/m/07r04,/m/07yv9\n",
      "test - labels:{0}\n",
      "test - duration: 10.0\n",
      "wavfile gelezen\n",
      "sr: 48000\n",
      "shape = 1\n",
      "sample rate klopt\n",
      "test - check: seconds\n",
      "check: write example\n",
      "\n",
      "file nr: 6\n",
      "Filename: -8n2NqDFRko_^_30.000.wav\n",
      "ytid: -8n2NqDFRko\n",
      "start: 30.000\n",
      "test - mids: /m/02rhddq,/m/07r04,/m/07yv9,/m/09x0r\n",
      "test - labels:{0}\n",
      "test - duration: 10.0\n",
      "wavfile gelezen\n",
      "sr: 48000\n",
      "shape = 1\n",
      "sample rate klopt\n",
      "test - check: seconds\n",
      "check: write example\n",
      "\n",
      "file nr: 7\n",
      "Filename: -99daJhXYJY_^_30.000.wav\n",
      "ytid: -99daJhXYJY\n",
      "start: 30.000\n",
      "test - mids: /m/019jd,/m/02rlv9,/m/03m9d0z,/t/dd00092\n",
      "test - labels:{0, 10}\n",
      "test - duration: 0.0\n",
      "\n",
      "file nr: 8\n",
      "Filename: -9ME9qMgkeY_^_270.000.wav\n",
      "ytid: -9ME9qMgkeY\n",
      "start: 270.000\n",
      "test - mids: /m/08j51y,/m/09ct_\n",
      "test - labels:{4}\n",
      "test - duration: 0.0\n",
      "\n",
      "file nr: 9\n",
      "Filename: -A0MTi2NMGI_^_30.000.wav\n",
      "ytid: -A0MTi2NMGI\n",
      "start: 30.000\n",
      "test - mids: /t/dd00134\n",
      "test - labels:{0}\n",
      "test - duration: 10.0\n",
      "wavfile gelezen\n",
      "sr: 48000\n",
      "shape = 1\n",
      "sample rate klopt\n",
      "test - check: seconds\n",
      "check: write example\n",
      "INFO:tensorflow:Restoring parameters from models/vggish_model.ckpt\n",
      "(10, 128)\n",
      "check: upsamplen\n",
      "\n",
      "file nr: 10\n",
      "Filename: -AIrHVeCgtM_^_30.000.wav\n",
      "ytid: -AIrHVeCgtM\n",
      "start: 30.000\n",
      "test - mids: /m/02rhddq,/m/07r04,/m/07yv9,/m/09x0r\n",
      "test - labels:{0}\n",
      "test - duration: 10.0\n",
      "wavfile gelezen\n",
      "sr: 48000\n",
      "shape = 1\n",
      "sample rate klopt\n",
      "test - check: seconds\n",
      "check: write example\n"
     ]
    }
   ],
   "source": [
    "readWav(bal_labels, \"bal\")\n",
    "#readWav(unbal_labels, \"unbal\")\n",
    "#readWav(eval_labels, \"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr samples: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"nr samples: \" + str(nr_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-7849d2ec7421>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msum_occur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcnt_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcnt_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "## Print voor alle labels het aantal voorkomens in de nieuwe tf-records\n",
    "\n",
    "sum_occur = 0\n",
    "cnt_labels = Counter(all_labels)\n",
    "\n",
    "for i in cnt_labels.most_common(100):\n",
    "    sum_occur = sum_occur + i[1]\n",
    "    print(label_proportions.loc[label_proportions['index']==i[0]]['display_name'].values[0], ' : ', str(i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
